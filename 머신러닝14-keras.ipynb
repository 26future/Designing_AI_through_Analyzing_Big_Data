{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 데이터셋 생성하기\n",
    "(xTrain,yTrain),(xTest,yTest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = xTrain.reshape(60000,784).astype('float32')/255.0\n",
    "xTest = xTest.reshape(10000,784).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain\n",
    "yTrain = np_utils.to_categorical(yTrain) #원핫인코딩\n",
    "yTest = np_utils.to_categorical(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
      "  warnings.warn('`Sequential.model` is deprecated. '\n"
     ]
    }
   ],
   "source": [
    "#2. 모델구성\n",
    "model = Sequential()\n",
    "model.model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 모델 학습과정 설정\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.6684 - accuracy: 0.8253\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3468 - accuracy: 0.9020\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3002 - accuracy: 0.9145\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2712 - accuracy: 0.9226\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2498 - accuracy: 0.9288\n"
     ]
    }
   ],
   "source": [
    "#4. 모델 학습\n",
    "hist = model.fit(xTrain, yTrain, epochs=5, batch_size=32)\n",
    "#batch_size: 몇 개의 샘플로 가중치를 갱신할 것인가(얼마나 빈번하게 업데이트 되는지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6683644861777623, 0.34676237959861755, 0.30020022093256316, 0.27120461085836095, 0.2497716275791327]\n",
      "[0.82531667, 0.9020333, 0.9145, 0.92256665, 0.9288]\n"
     ]
    }
   ],
   "source": [
    "#5. cost, 정확도 확인\n",
    "print(hist.history['loss'])\n",
    "print(hist.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 17us/step\n",
      "[0.23305894895493984, 0.9312999844551086]\n"
     ]
    }
   ],
   "source": [
    "#6. 모델 평가\n",
    "res = model.evaluate(xTest, yTest, batch_size=32)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.44443766e-04 8.79309496e-08 8.14641244e-04 3.29171331e-03\n",
      "  2.02963815e-06 1.10893568e-04 1.16152684e-07 9.94709373e-01\n",
      "  1.39497588e-05 9.12675576e-04]]\n"
     ]
    }
   ],
   "source": [
    "# 모델 예측\n",
    "xhat = xTest[0:1]\n",
    "yhat = model.predict(xhat)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xTrain,yTrain),(xTest,yTest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xVal = xTrain[50000:]\n",
    "yVal = yTrain[50000:]\n",
    "xTrain = xTrain[:50000]\n",
    "yTrain = yTrain[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = xTrain.reshape(50000,784).astype('float32')/255.0\n",
    "xVal = xVal.reshape(10000,784).astype('float32')/255.0\n",
    "xTest = xTest.reshape(10000,784).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련, 검증 데이터 선택\n",
    "tri = np.random.choice(50000,700) #0~49999 중에 700개 랜덤 중복 추출\n",
    "vri = np.random.choice(10000,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = xTrain[tri] #700건\n",
    "yTrain = yTrain[tri]\n",
    "xVal = xVal[vri] #300건\n",
    "yVal = yVal[vri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#카테고리 형태로 변환\n",
    "yTrain = np_utils.to_categorical(yTrain) \n",
    "yVal = np_utils.to_categorical(yVal)\n",
    "yTest = np_utils.to_categorical(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=28*28, units=2, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 2.2576 - accuracy: 0.1643 - val_loss: 2.2272 - val_accuracy: 0.1633\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 2.2072 - accuracy: 0.1657 - val_loss: 2.1908 - val_accuracy: 0.1800\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 2.1730 - accuracy: 0.1729 - val_loss: 2.1631 - val_accuracy: 0.1867\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 2.1441 - accuracy: 0.1786 - val_loss: 2.1372 - val_accuracy: 0.1867\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 2.1177 - accuracy: 0.1900 - val_loss: 2.1141 - val_accuracy: 0.1867\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 2.0940 - accuracy: 0.2029 - val_loss: 2.0931 - val_accuracy: 0.2033\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 2.0721 - accuracy: 0.2071 - val_loss: 2.0727 - val_accuracy: 0.2067\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 2.0520 - accuracy: 0.2129 - val_loss: 2.0564 - val_accuracy: 0.2067\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 2.0342 - accuracy: 0.2157 - val_loss: 2.0410 - val_accuracy: 0.2033\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 2.0190 - accuracy: 0.2143 - val_loss: 2.0269 - val_accuracy: 0.2067\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 2.0041 - accuracy: 0.2186 - val_loss: 2.0125 - val_accuracy: 0.2100\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.9911 - accuracy: 0.2200 - val_loss: 2.0037 - val_accuracy: 0.2100\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 1.9789 - accuracy: 0.2286 - val_loss: 1.9955 - val_accuracy: 0.2100\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.9685 - accuracy: 0.2329 - val_loss: 1.9833 - val_accuracy: 0.2067\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.9582 - accuracy: 0.2214 - val_loss: 1.9753 - val_accuracy: 0.2100\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.9484 - accuracy: 0.2357 - val_loss: 1.9686 - val_accuracy: 0.2000\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.9393 - accuracy: 0.2343 - val_loss: 1.9612 - val_accuracy: 0.2033\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.9309 - accuracy: 0.2314 - val_loss: 1.9537 - val_accuracy: 0.2100\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.9232 - accuracy: 0.2286 - val_loss: 1.9452 - val_accuracy: 0.2100\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.9156 - accuracy: 0.2386 - val_loss: 1.9392 - val_accuracy: 0.2100\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.9085 - accuracy: 0.2343 - val_loss: 1.9363 - val_accuracy: 0.2100\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.9011 - accuracy: 0.2386 - val_loss: 1.9289 - val_accuracy: 0.2033\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.8954 - accuracy: 0.2357 - val_loss: 1.9234 - val_accuracy: 0.2100\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.8895 - accuracy: 0.2314 - val_loss: 1.9201 - val_accuracy: 0.2067\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.8830 - accuracy: 0.2343 - val_loss: 1.9178 - val_accuracy: 0.2167\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.8769 - accuracy: 0.2300 - val_loss: 1.9105 - val_accuracy: 0.2167\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.8715 - accuracy: 0.2357 - val_loss: 1.9098 - val_accuracy: 0.2167\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.8662 - accuracy: 0.2400 - val_loss: 1.9094 - val_accuracy: 0.2000\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.8615 - accuracy: 0.2400 - val_loss: 1.9041 - val_accuracy: 0.1900\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.8565 - accuracy: 0.2243 - val_loss: 1.8976 - val_accuracy: 0.2167\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.8513 - accuracy: 0.2471 - val_loss: 1.8971 - val_accuracy: 0.1933\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.8463 - accuracy: 0.2371 - val_loss: 1.8925 - val_accuracy: 0.1900\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.8423 - accuracy: 0.2229 - val_loss: 1.8874 - val_accuracy: 0.2067\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.8382 - accuracy: 0.2371 - val_loss: 1.8808 - val_accuracy: 0.1933\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.8335 - accuracy: 0.2471 - val_loss: 1.8836 - val_accuracy: 0.1900\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.8299 - accuracy: 0.2343 - val_loss: 1.8756 - val_accuracy: 0.1967\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.8257 - accuracy: 0.2486 - val_loss: 1.8745 - val_accuracy: 0.1800\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.8220 - accuracy: 0.2371 - val_loss: 1.8700 - val_accuracy: 0.1933\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.8184 - accuracy: 0.2457 - val_loss: 1.8706 - val_accuracy: 0.1767\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.8144 - accuracy: 0.2314 - val_loss: 1.8677 - val_accuracy: 0.2000\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.8105 - accuracy: 0.2400 - val_loss: 1.8668 - val_accuracy: 0.1833\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.8075 - accuracy: 0.2471 - val_loss: 1.8635 - val_accuracy: 0.1800\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.8046 - accuracy: 0.2429 - val_loss: 1.8611 - val_accuracy: 0.1700\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.8001 - accuracy: 0.2371 - val_loss: 1.8566 - val_accuracy: 0.1967\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.7970 - accuracy: 0.2429 - val_loss: 1.8564 - val_accuracy: 0.1700\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.7939 - accuracy: 0.2271 - val_loss: 1.8528 - val_accuracy: 0.1933\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.7913 - accuracy: 0.2600 - val_loss: 1.8551 - val_accuracy: 0.1833\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.7886 - accuracy: 0.2471 - val_loss: 1.8543 - val_accuracy: 0.1867\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7858 - accuracy: 0.2486 - val_loss: 1.8504 - val_accuracy: 0.1867\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.7819 - accuracy: 0.2471 - val_loss: 1.8443 - val_accuracy: 0.2267\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.7794 - accuracy: 0.2643 - val_loss: 1.8468 - val_accuracy: 0.1900\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.7762 - accuracy: 0.2486 - val_loss: 1.8411 - val_accuracy: 0.1933\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.7744 - accuracy: 0.2514 - val_loss: 1.8486 - val_accuracy: 0.2000\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 1.7716 - accuracy: 0.2700 - val_loss: 1.8472 - val_accuracy: 0.1800\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.7687 - accuracy: 0.2500 - val_loss: 1.8364 - val_accuracy: 0.2033\n",
      "Epoch 56/3000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 1.7672 - accuracy: 0.2543 - val_loss: 1.8430 - val_accuracy: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.7641 - accuracy: 0.2714 - val_loss: 1.8390 - val_accuracy: 0.2167\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.7616 - accuracy: 0.2557 - val_loss: 1.8347 - val_accuracy: 0.2267\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.7590 - accuracy: 0.2671 - val_loss: 1.8329 - val_accuracy: 0.2233\n",
      "Epoch 60/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.7552 - accuracy: 0.2614 - val_loss: 1.8256 - val_accuracy: 0.2500\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.7566 - accuracy: 0.2814 - val_loss: 1.8336 - val_accuracy: 0.2400\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.7531 - accuracy: 0.2729 - val_loss: 1.8312 - val_accuracy: 0.2267\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.7505 - accuracy: 0.2857 - val_loss: 1.8299 - val_accuracy: 0.2000\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7484 - accuracy: 0.2800 - val_loss: 1.8268 - val_accuracy: 0.2200\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7457 - accuracy: 0.2814 - val_loss: 1.8298 - val_accuracy: 0.2033\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.7439 - accuracy: 0.2786 - val_loss: 1.8296 - val_accuracy: 0.2067\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.7419 - accuracy: 0.2700 - val_loss: 1.8299 - val_accuracy: 0.2067\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7405 - accuracy: 0.2729 - val_loss: 1.8238 - val_accuracy: 0.2000\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.7376 - accuracy: 0.2814 - val_loss: 1.8298 - val_accuracy: 0.2167\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.7356 - accuracy: 0.2857 - val_loss: 1.8269 - val_accuracy: 0.2433\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.7345 - accuracy: 0.2800 - val_loss: 1.8214 - val_accuracy: 0.2167\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.7328 - accuracy: 0.2857 - val_loss: 1.8226 - val_accuracy: 0.2133\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7298 - accuracy: 0.2800 - val_loss: 1.8252 - val_accuracy: 0.2467\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7283 - accuracy: 0.2857 - val_loss: 1.8257 - val_accuracy: 0.1967\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.7268 - accuracy: 0.2786 - val_loss: 1.8190 - val_accuracy: 0.2267\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.7255 - accuracy: 0.2857 - val_loss: 1.8196 - val_accuracy: 0.2233\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.7228 - accuracy: 0.3057 - val_loss: 1.8232 - val_accuracy: 0.2033\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.7212 - accuracy: 0.2857 - val_loss: 1.8187 - val_accuracy: 0.1933\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.7199 - accuracy: 0.2829 - val_loss: 1.8203 - val_accuracy: 0.2433\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.7188 - accuracy: 0.2929 - val_loss: 1.8197 - val_accuracy: 0.2067\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.7165 - accuracy: 0.2843 - val_loss: 1.8256 - val_accuracy: 0.2067\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 1.7142 - accuracy: 0.2829 - val_loss: 1.8144 - val_accuracy: 0.2667\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 1.7132 - accuracy: 0.2857 - val_loss: 1.8190 - val_accuracy: 0.2400\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.7127 - accuracy: 0.2986 - val_loss: 1.8220 - val_accuracy: 0.2167\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7097 - accuracy: 0.2971 - val_loss: 1.8159 - val_accuracy: 0.2267\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7082 - accuracy: 0.2800 - val_loss: 1.8136 - val_accuracy: 0.2633\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.7051 - accuracy: 0.3100 - val_loss: 1.8191 - val_accuracy: 0.2733\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7062 - accuracy: 0.3043 - val_loss: 1.8125 - val_accuracy: 0.2433\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.7043 - accuracy: 0.3043 - val_loss: 1.8167 - val_accuracy: 0.2167\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 260us/step - loss: 1.7027 - accuracy: 0.2843 - val_loss: 1.8151 - val_accuracy: 0.2233\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.7017 - accuracy: 0.3086 - val_loss: 1.8185 - val_accuracy: 0.2167\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6987 - accuracy: 0.3129 - val_loss: 1.8215 - val_accuracy: 0.2067\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6980 - accuracy: 0.3071 - val_loss: 1.8173 - val_accuracy: 0.2767\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.6970 - accuracy: 0.3157 - val_loss: 1.8176 - val_accuracy: 0.2100\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.6943 - accuracy: 0.2986 - val_loss: 1.8194 - val_accuracy: 0.2833\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6948 - accuracy: 0.3014 - val_loss: 1.8095 - val_accuracy: 0.2233\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6930 - accuracy: 0.3057 - val_loss: 1.8228 - val_accuracy: 0.2300\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6921 - accuracy: 0.3043 - val_loss: 1.8117 - val_accuracy: 0.2200\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6901 - accuracy: 0.3129 - val_loss: 1.8252 - val_accuracy: 0.2233\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6890 - accuracy: 0.3129 - val_loss: 1.8210 - val_accuracy: 0.2267\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6878 - accuracy: 0.3143 - val_loss: 1.8190 - val_accuracy: 0.2200\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.6877 - accuracy: 0.3014 - val_loss: 1.8219 - val_accuracy: 0.2300\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6843 - accuracy: 0.3000 - val_loss: 1.8102 - val_accuracy: 0.2500\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6842 - accuracy: 0.3200 - val_loss: 1.8122 - val_accuracy: 0.2200\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6821 - accuracy: 0.3071 - val_loss: 1.8063 - val_accuracy: 0.2067\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6814 - accuracy: 0.3114 - val_loss: 1.8173 - val_accuracy: 0.2200\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6805 - accuracy: 0.3071 - val_loss: 1.8228 - val_accuracy: 0.2367\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6784 - accuracy: 0.3071 - val_loss: 1.8167 - val_accuracy: 0.2767\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6782 - accuracy: 0.3143 - val_loss: 1.8178 - val_accuracy: 0.2300\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.6775 - accuracy: 0.3171 - val_loss: 1.8147 - val_accuracy: 0.2133\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6775 - accuracy: 0.3043 - val_loss: 1.8173 - val_accuracy: 0.2233\n",
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6745 - accuracy: 0.3129 - val_loss: 1.8193 - val_accuracy: 0.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.6737 - accuracy: 0.3100 - val_loss: 1.8196 - val_accuracy: 0.2300\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6724 - accuracy: 0.3014 - val_loss: 1.8221 - val_accuracy: 0.2300\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6711 - accuracy: 0.3071 - val_loss: 1.8128 - val_accuracy: 0.2333\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6703 - accuracy: 0.3157 - val_loss: 1.8255 - val_accuracy: 0.2300\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6694 - accuracy: 0.3100 - val_loss: 1.8228 - val_accuracy: 0.2333\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6682 - accuracy: 0.3114 - val_loss: 1.8262 - val_accuracy: 0.2333\n",
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.6670 - accuracy: 0.3257 - val_loss: 1.8216 - val_accuracy: 0.2200\n",
      "Epoch 120/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.6661 - accuracy: 0.3129 - val_loss: 1.8219 - val_accuracy: 0.2200\n",
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.6646 - accuracy: 0.3071 - val_loss: 1.8132 - val_accuracy: 0.2233\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6637 - accuracy: 0.3229 - val_loss: 1.8194 - val_accuracy: 0.2200\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6629 - accuracy: 0.3100 - val_loss: 1.8139 - val_accuracy: 0.2200\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6619 - accuracy: 0.3143 - val_loss: 1.8187 - val_accuracy: 0.2267\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6606 - accuracy: 0.3257 - val_loss: 1.8212 - val_accuracy: 0.2333\n",
      "Epoch 126/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6592 - accuracy: 0.3143 - val_loss: 1.8245 - val_accuracy: 0.2233\n",
      "Epoch 127/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6583 - accuracy: 0.3129 - val_loss: 1.8147 - val_accuracy: 0.2333\n",
      "Epoch 128/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6565 - accuracy: 0.3300 - val_loss: 1.8280 - val_accuracy: 0.2300\n",
      "Epoch 129/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6570 - accuracy: 0.3143 - val_loss: 1.8193 - val_accuracy: 0.2200\n",
      "Epoch 130/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6548 - accuracy: 0.3214 - val_loss: 1.8124 - val_accuracy: 0.2533\n",
      "Epoch 131/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6547 - accuracy: 0.3229 - val_loss: 1.8202 - val_accuracy: 0.2500\n",
      "Epoch 132/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6545 - accuracy: 0.3200 - val_loss: 1.8133 - val_accuracy: 0.2267\n",
      "Epoch 133/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.6524 - accuracy: 0.3143 - val_loss: 1.8317 - val_accuracy: 0.2400\n",
      "Epoch 134/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6514 - accuracy: 0.3214 - val_loss: 1.8226 - val_accuracy: 0.2733\n",
      "Epoch 135/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6512 - accuracy: 0.3314 - val_loss: 1.8233 - val_accuracy: 0.2267\n",
      "Epoch 136/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6493 - accuracy: 0.3186 - val_loss: 1.8168 - val_accuracy: 0.2200\n",
      "Epoch 137/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6483 - accuracy: 0.3214 - val_loss: 1.8191 - val_accuracy: 0.2200\n",
      "Epoch 138/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6488 - accuracy: 0.3257 - val_loss: 1.8199 - val_accuracy: 0.2167\n",
      "Epoch 139/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6466 - accuracy: 0.3257 - val_loss: 1.8512 - val_accuracy: 0.2433\n",
      "Epoch 140/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6465 - accuracy: 0.3214 - val_loss: 1.8168 - val_accuracy: 0.2200\n",
      "Epoch 141/3000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.6446 - accuracy: 0.3229 - val_loss: 1.8284 - val_accuracy: 0.2267\n",
      "Epoch 142/3000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.6437 - accuracy: 0.3243 - val_loss: 1.8154 - val_accuracy: 0.2633\n",
      "Epoch 143/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.6437 - accuracy: 0.3329 - val_loss: 1.8292 - val_accuracy: 0.2433\n",
      "Epoch 144/3000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.6431 - accuracy: 0.3329 - val_loss: 1.8273 - val_accuracy: 0.2300\n",
      "Epoch 145/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.6419 - accuracy: 0.3271 - val_loss: 1.8197 - val_accuracy: 0.2200\n",
      "Epoch 146/3000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.6392 - accuracy: 0.3343 - val_loss: 1.8324 - val_accuracy: 0.2233\n",
      "Epoch 147/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6412 - accuracy: 0.3100 - val_loss: 1.8328 - val_accuracy: 0.2333\n",
      "Epoch 148/3000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.6390 - accuracy: 0.3243 - val_loss: 1.8306 - val_accuracy: 0.2500\n",
      "Epoch 149/3000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.6375 - accuracy: 0.3271 - val_loss: 1.8189 - val_accuracy: 0.2133\n",
      "Epoch 150/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.6367 - accuracy: 0.3229 - val_loss: 1.8276 - val_accuracy: 0.2233\n",
      "Epoch 151/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.6364 - accuracy: 0.3257 - val_loss: 1.8245 - val_accuracy: 0.2267\n",
      "Epoch 152/3000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 1.6350 - accuracy: 0.3214 - val_loss: 1.8290 - val_accuracy: 0.2233\n",
      "Epoch 153/3000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 1.6340 - accuracy: 0.3400 - val_loss: 1.8270 - val_accuracy: 0.2300\n",
      "Epoch 154/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.6319 - accuracy: 0.3457 - val_loss: 1.8343 - val_accuracy: 0.2233\n",
      "Epoch 155/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.6316 - accuracy: 0.3243 - val_loss: 1.8183 - val_accuracy: 0.2367\n",
      "Epoch 156/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6326 - accuracy: 0.3329 - val_loss: 1.8309 - val_accuracy: 0.2200\n",
      "Epoch 157/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.6308 - accuracy: 0.3300 - val_loss: 1.8241 - val_accuracy: 0.2200\n",
      "Epoch 158/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6308 - accuracy: 0.3343 - val_loss: 1.8329 - val_accuracy: 0.2300\n",
      "Epoch 159/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6285 - accuracy: 0.3257 - val_loss: 1.8336 - val_accuracy: 0.2433\n",
      "Epoch 160/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6278 - accuracy: 0.3300 - val_loss: 1.8304 - val_accuracy: 0.2233\n",
      "Epoch 161/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6271 - accuracy: 0.3257 - val_loss: 1.8406 - val_accuracy: 0.2300\n",
      "Epoch 162/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.6265 - accuracy: 0.3271 - val_loss: 1.8350 - val_accuracy: 0.2267\n",
      "Epoch 163/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.6254 - accuracy: 0.3371 - val_loss: 1.8365 - val_accuracy: 0.2300\n",
      "Epoch 164/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6239 - accuracy: 0.3314 - val_loss: 1.8264 - val_accuracy: 0.2100\n",
      "Epoch 165/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.6236 - accuracy: 0.3200 - val_loss: 1.8396 - val_accuracy: 0.2367\n",
      "Epoch 166/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6230 - accuracy: 0.3286 - val_loss: 1.8344 - val_accuracy: 0.2233\n",
      "Epoch 167/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6221 - accuracy: 0.3314 - val_loss: 1.8389 - val_accuracy: 0.2633\n",
      "Epoch 168/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6208 - accuracy: 0.3386 - val_loss: 1.8444 - val_accuracy: 0.2200\n",
      "Epoch 169/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6198 - accuracy: 0.3386 - val_loss: 1.8525 - val_accuracy: 0.2233\n",
      "Epoch 170/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.6191 - accuracy: 0.3371 - val_loss: 1.8369 - val_accuracy: 0.2233\n",
      "Epoch 171/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6170 - accuracy: 0.3271 - val_loss: 1.8517 - val_accuracy: 0.2600\n",
      "Epoch 172/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6164 - accuracy: 0.3386 - val_loss: 1.8397 - val_accuracy: 0.2133\n",
      "Epoch 173/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6182 - accuracy: 0.3386 - val_loss: 1.8392 - val_accuracy: 0.2367\n",
      "Epoch 174/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6167 - accuracy: 0.3300 - val_loss: 1.8420 - val_accuracy: 0.2200\n",
      "Epoch 175/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6166 - accuracy: 0.3357 - val_loss: 1.8406 - val_accuracy: 0.2200\n",
      "Epoch 176/3000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.6143 - accuracy: 0.3229 - val_loss: 1.8437 - val_accuracy: 0.2600\n",
      "Epoch 177/3000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 1.6134 - accuracy: 0.3371 - val_loss: 1.8384 - val_accuracy: 0.2167\n",
      "Epoch 178/3000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 1.6139 - accuracy: 0.3371 - val_loss: 1.8446 - val_accuracy: 0.2267\n",
      "Epoch 179/3000\n",
      "700/700 [==============================] - 0s 171us/step - loss: 1.6134 - accuracy: 0.3400 - val_loss: 1.8376 - val_accuracy: 0.2233\n",
      "Epoch 180/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.6110 - accuracy: 0.3371 - val_loss: 1.8415 - val_accuracy: 0.2667\n",
      "Epoch 181/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6115 - accuracy: 0.3457 - val_loss: 1.8339 - val_accuracy: 0.2567\n",
      "Epoch 182/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.6106 - accuracy: 0.3471 - val_loss: 1.8365 - val_accuracy: 0.2167\n",
      "Epoch 183/3000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 1.6115 - accuracy: 0.3300 - val_loss: 1.8411 - val_accuracy: 0.2333\n",
      "Epoch 184/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6093 - accuracy: 0.3443 - val_loss: 1.8453 - val_accuracy: 0.2267\n",
      "Epoch 185/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6076 - accuracy: 0.3386 - val_loss: 1.8641 - val_accuracy: 0.2200\n",
      "Epoch 186/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6086 - accuracy: 0.3443 - val_loss: 1.8449 - val_accuracy: 0.2233\n",
      "Epoch 187/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6065 - accuracy: 0.3543 - val_loss: 1.8442 - val_accuracy: 0.2167\n",
      "Epoch 188/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6075 - accuracy: 0.3386 - val_loss: 1.8412 - val_accuracy: 0.2133\n",
      "Epoch 189/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6045 - accuracy: 0.3529 - val_loss: 1.8517 - val_accuracy: 0.2233\n",
      "Epoch 190/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.6065 - accuracy: 0.3314 - val_loss: 1.8401 - val_accuracy: 0.2300\n",
      "Epoch 191/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6042 - accuracy: 0.3529 - val_loss: 1.8564 - val_accuracy: 0.2233\n",
      "Epoch 192/3000\n",
      "700/700 [==============================] - 0s 166us/step - loss: 1.6044 - accuracy: 0.3500 - val_loss: 1.8503 - val_accuracy: 0.2200\n",
      "Epoch 193/3000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.6029 - accuracy: 0.3357 - val_loss: 1.8539 - val_accuracy: 0.2267\n",
      "Epoch 194/3000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.6025 - accuracy: 0.3414 - val_loss: 1.8470 - val_accuracy: 0.2267\n",
      "Epoch 195/3000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 1.6019 - accuracy: 0.3457 - val_loss: 1.8453 - val_accuracy: 0.2467\n",
      "Epoch 196/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.6016 - accuracy: 0.3514 - val_loss: 1.8472 - val_accuracy: 0.2167\n",
      "Epoch 197/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6002 - accuracy: 0.3443 - val_loss: 1.8488 - val_accuracy: 0.2300\n",
      "Epoch 198/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6005 - accuracy: 0.3386 - val_loss: 1.8591 - val_accuracy: 0.2200\n",
      "Epoch 199/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6003 - accuracy: 0.3429 - val_loss: 1.8558 - val_accuracy: 0.2200\n",
      "Epoch 200/3000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.5975 - accuracy: 0.3457 - val_loss: 1.8604 - val_accuracy: 0.2633\n",
      "Epoch 201/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5986 - accuracy: 0.3457 - val_loss: 1.8469 - val_accuracy: 0.2167\n",
      "Epoch 202/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5979 - accuracy: 0.3414 - val_loss: 1.8478 - val_accuracy: 0.2100\n",
      "Epoch 203/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5965 - accuracy: 0.3343 - val_loss: 1.8562 - val_accuracy: 0.2267\n",
      "Epoch 204/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.5953 - accuracy: 0.3557 - val_loss: 1.8461 - val_accuracy: 0.2067\n",
      "Epoch 205/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5953 - accuracy: 0.3429 - val_loss: 1.8508 - val_accuracy: 0.2200\n",
      "Epoch 206/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5946 - accuracy: 0.3500 - val_loss: 1.8463 - val_accuracy: 0.2133\n",
      "Epoch 207/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5947 - accuracy: 0.3543 - val_loss: 1.8537 - val_accuracy: 0.2233\n",
      "Epoch 208/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5920 - accuracy: 0.3414 - val_loss: 1.8557 - val_accuracy: 0.2233\n",
      "Epoch 209/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5919 - accuracy: 0.3514 - val_loss: 1.8521 - val_accuracy: 0.2300\n",
      "Epoch 210/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5915 - accuracy: 0.3443 - val_loss: 1.8523 - val_accuracy: 0.2267\n",
      "Epoch 211/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5903 - accuracy: 0.3371 - val_loss: 1.8456 - val_accuracy: 0.2567\n",
      "Epoch 212/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5913 - accuracy: 0.3471 - val_loss: 1.8593 - val_accuracy: 0.2200\n",
      "Epoch 213/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5894 - accuracy: 0.3500 - val_loss: 1.8519 - val_accuracy: 0.2233\n",
      "Epoch 214/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5905 - accuracy: 0.3457 - val_loss: 1.8541 - val_accuracy: 0.2267\n",
      "Epoch 215/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5886 - accuracy: 0.3514 - val_loss: 1.8602 - val_accuracy: 0.2667\n",
      "Epoch 216/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5895 - accuracy: 0.3486 - val_loss: 1.8624 - val_accuracy: 0.2267\n",
      "Epoch 217/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5881 - accuracy: 0.3471 - val_loss: 1.8638 - val_accuracy: 0.2300\n",
      "Epoch 218/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5876 - accuracy: 0.3486 - val_loss: 1.8600 - val_accuracy: 0.2300\n",
      "Epoch 219/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5865 - accuracy: 0.3500 - val_loss: 1.8659 - val_accuracy: 0.2267\n",
      "Epoch 220/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5855 - accuracy: 0.3514 - val_loss: 1.8581 - val_accuracy: 0.2267\n",
      "Epoch 221/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5855 - accuracy: 0.3471 - val_loss: 1.8621 - val_accuracy: 0.2267\n",
      "Epoch 222/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5845 - accuracy: 0.3514 - val_loss: 1.8751 - val_accuracy: 0.2500\n",
      "Epoch 223/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 90us/step - loss: 1.5844 - accuracy: 0.3443 - val_loss: 1.8615 - val_accuracy: 0.2600\n",
      "Epoch 224/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5845 - accuracy: 0.3529 - val_loss: 1.8766 - val_accuracy: 0.2467\n",
      "Epoch 225/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5833 - accuracy: 0.3457 - val_loss: 1.8572 - val_accuracy: 0.2167\n",
      "Epoch 226/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5835 - accuracy: 0.3486 - val_loss: 1.8686 - val_accuracy: 0.2233\n",
      "Epoch 227/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5825 - accuracy: 0.3486 - val_loss: 1.8611 - val_accuracy: 0.2133\n",
      "Epoch 228/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5825 - accuracy: 0.3443 - val_loss: 1.8693 - val_accuracy: 0.2267\n",
      "Epoch 229/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5801 - accuracy: 0.3471 - val_loss: 1.8688 - val_accuracy: 0.2233\n",
      "Epoch 230/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5818 - accuracy: 0.3471 - val_loss: 1.8635 - val_accuracy: 0.2133\n",
      "Epoch 231/3000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 1.5797 - accuracy: 0.3529 - val_loss: 1.8605 - val_accuracy: 0.2200\n",
      "Epoch 232/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5809 - accuracy: 0.3514 - val_loss: 1.8730 - val_accuracy: 0.2133\n",
      "Epoch 233/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5796 - accuracy: 0.3486 - val_loss: 1.8781 - val_accuracy: 0.2200\n",
      "Epoch 234/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5791 - accuracy: 0.3457 - val_loss: 1.8666 - val_accuracy: 0.2133\n",
      "Epoch 235/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5777 - accuracy: 0.3571 - val_loss: 1.8693 - val_accuracy: 0.2100\n",
      "Epoch 236/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5778 - accuracy: 0.3443 - val_loss: 1.8664 - val_accuracy: 0.2133\n",
      "Epoch 237/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5770 - accuracy: 0.3429 - val_loss: 1.8718 - val_accuracy: 0.2300\n",
      "Epoch 238/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5774 - accuracy: 0.3471 - val_loss: 1.8613 - val_accuracy: 0.2200\n",
      "Epoch 239/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5770 - accuracy: 0.3571 - val_loss: 1.8682 - val_accuracy: 0.2267\n",
      "Epoch 240/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5749 - accuracy: 0.3571 - val_loss: 1.8719 - val_accuracy: 0.2500\n",
      "Epoch 241/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5749 - accuracy: 0.3571 - val_loss: 1.8738 - val_accuracy: 0.2433\n",
      "Epoch 242/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5743 - accuracy: 0.3514 - val_loss: 1.8733 - val_accuracy: 0.2100\n",
      "Epoch 243/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5743 - accuracy: 0.3629 - val_loss: 1.8806 - val_accuracy: 0.2200\n",
      "Epoch 244/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5713 - accuracy: 0.3557 - val_loss: 1.8724 - val_accuracy: 0.2200\n",
      "Epoch 245/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5715 - accuracy: 0.3586 - val_loss: 1.8838 - val_accuracy: 0.2233\n",
      "Epoch 246/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5712 - accuracy: 0.3543 - val_loss: 1.8710 - val_accuracy: 0.2533\n",
      "Epoch 247/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5722 - accuracy: 0.3557 - val_loss: 1.8631 - val_accuracy: 0.2167\n",
      "Epoch 248/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5716 - accuracy: 0.3557 - val_loss: 1.8700 - val_accuracy: 0.2233\n",
      "Epoch 249/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5712 - accuracy: 0.3471 - val_loss: 1.8840 - val_accuracy: 0.2233\n",
      "Epoch 250/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5680 - accuracy: 0.3657 - val_loss: 1.8981 - val_accuracy: 0.2167\n",
      "Epoch 251/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5704 - accuracy: 0.3486 - val_loss: 1.8793 - val_accuracy: 0.2400\n",
      "Epoch 252/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5682 - accuracy: 0.3643 - val_loss: 1.8744 - val_accuracy: 0.2200\n",
      "Epoch 253/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5689 - accuracy: 0.3586 - val_loss: 1.8820 - val_accuracy: 0.2133\n",
      "Epoch 254/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5677 - accuracy: 0.3571 - val_loss: 1.8835 - val_accuracy: 0.2267\n",
      "Epoch 255/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5681 - accuracy: 0.3457 - val_loss: 1.8713 - val_accuracy: 0.2267\n",
      "Epoch 256/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5657 - accuracy: 0.3571 - val_loss: 1.8761 - val_accuracy: 0.2533\n",
      "Epoch 257/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.5667 - accuracy: 0.3514 - val_loss: 1.8912 - val_accuracy: 0.2467\n",
      "Epoch 258/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5649 - accuracy: 0.3614 - val_loss: 1.8946 - val_accuracy: 0.2567\n",
      "Epoch 259/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5648 - accuracy: 0.3643 - val_loss: 1.8911 - val_accuracy: 0.2167\n",
      "Epoch 260/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5657 - accuracy: 0.3600 - val_loss: 1.8989 - val_accuracy: 0.2200\n",
      "Epoch 261/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.5637 - accuracy: 0.3571 - val_loss: 1.8751 - val_accuracy: 0.2167\n",
      "Epoch 262/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5638 - accuracy: 0.3614 - val_loss: 1.8836 - val_accuracy: 0.2100\n",
      "Epoch 263/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5631 - accuracy: 0.3629 - val_loss: 1.8858 - val_accuracy: 0.2100\n",
      "Epoch 264/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5640 - accuracy: 0.3571 - val_loss: 1.8812 - val_accuracy: 0.2133\n",
      "Epoch 265/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5638 - accuracy: 0.3686 - val_loss: 1.8902 - val_accuracy: 0.2200\n",
      "Epoch 266/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5614 - accuracy: 0.3614 - val_loss: 1.8968 - val_accuracy: 0.2500\n",
      "Epoch 267/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5612 - accuracy: 0.3629 - val_loss: 1.8918 - val_accuracy: 0.2300\n",
      "Epoch 268/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5613 - accuracy: 0.3614 - val_loss: 1.8757 - val_accuracy: 0.2100\n",
      "Epoch 269/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5601 - accuracy: 0.3643 - val_loss: 1.8854 - val_accuracy: 0.2133\n",
      "Epoch 270/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5594 - accuracy: 0.3671 - val_loss: 1.8674 - val_accuracy: 0.2333\n",
      "Epoch 271/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5610 - accuracy: 0.3657 - val_loss: 1.8914 - val_accuracy: 0.2333\n",
      "Epoch 272/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5595 - accuracy: 0.3600 - val_loss: 1.9030 - val_accuracy: 0.2267\n",
      "Epoch 273/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5591 - accuracy: 0.3571 - val_loss: 1.8964 - val_accuracy: 0.2200\n",
      "Epoch 274/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5589 - accuracy: 0.3457 - val_loss: 1.8841 - val_accuracy: 0.2233\n",
      "Epoch 275/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5589 - accuracy: 0.3629 - val_loss: 1.8914 - val_accuracy: 0.2200\n",
      "Epoch 276/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5579 - accuracy: 0.3529 - val_loss: 1.8967 - val_accuracy: 0.2533\n",
      "Epoch 277/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5581 - accuracy: 0.3714 - val_loss: 1.8909 - val_accuracy: 0.2167\n",
      "Epoch 278/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5578 - accuracy: 0.3600 - val_loss: 1.9032 - val_accuracy: 0.2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5559 - accuracy: 0.3571 - val_loss: 1.8859 - val_accuracy: 0.2167\n",
      "Epoch 280/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5559 - accuracy: 0.3700 - val_loss: 1.8876 - val_accuracy: 0.2167\n",
      "Epoch 281/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5541 - accuracy: 0.3586 - val_loss: 1.8906 - val_accuracy: 0.2333\n",
      "Epoch 282/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5553 - accuracy: 0.3671 - val_loss: 1.8840 - val_accuracy: 0.2133\n",
      "Epoch 283/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5543 - accuracy: 0.3557 - val_loss: 1.8927 - val_accuracy: 0.2167\n",
      "Epoch 284/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5542 - accuracy: 0.3614 - val_loss: 1.8936 - val_accuracy: 0.2567\n",
      "Epoch 285/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5535 - accuracy: 0.3557 - val_loss: 1.8887 - val_accuracy: 0.2200\n",
      "Epoch 286/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5536 - accuracy: 0.3586 - val_loss: 1.8989 - val_accuracy: 0.2233\n",
      "Epoch 287/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5527 - accuracy: 0.3686 - val_loss: 1.9019 - val_accuracy: 0.2133\n",
      "Epoch 288/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5525 - accuracy: 0.3600 - val_loss: 1.8930 - val_accuracy: 0.2133\n",
      "Epoch 289/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5519 - accuracy: 0.3600 - val_loss: 1.9014 - val_accuracy: 0.2167\n",
      "Epoch 290/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5514 - accuracy: 0.3657 - val_loss: 1.9032 - val_accuracy: 0.2200\n",
      "Epoch 291/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5513 - accuracy: 0.3586 - val_loss: 1.9037 - val_accuracy: 0.2167\n",
      "Epoch 292/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5509 - accuracy: 0.3543 - val_loss: 1.8995 - val_accuracy: 0.2433\n",
      "Epoch 293/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5507 - accuracy: 0.3543 - val_loss: 1.9011 - val_accuracy: 0.2300\n",
      "Epoch 294/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5497 - accuracy: 0.3543 - val_loss: 1.9002 - val_accuracy: 0.2567\n",
      "Epoch 295/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5499 - accuracy: 0.3657 - val_loss: 1.9120 - val_accuracy: 0.2200\n",
      "Epoch 296/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5495 - accuracy: 0.3571 - val_loss: 1.9104 - val_accuracy: 0.2133\n",
      "Epoch 297/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5479 - accuracy: 0.3571 - val_loss: 1.9128 - val_accuracy: 0.2167\n",
      "Epoch 298/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5477 - accuracy: 0.3486 - val_loss: 1.8958 - val_accuracy: 0.2267\n",
      "Epoch 299/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5485 - accuracy: 0.3686 - val_loss: 1.9145 - val_accuracy: 0.2267\n",
      "Epoch 300/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5472 - accuracy: 0.3629 - val_loss: 1.9031 - val_accuracy: 0.2300\n",
      "Epoch 301/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5469 - accuracy: 0.3629 - val_loss: 1.8934 - val_accuracy: 0.2200\n",
      "Epoch 302/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5479 - accuracy: 0.3657 - val_loss: 1.9081 - val_accuracy: 0.2167\n",
      "Epoch 303/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5464 - accuracy: 0.3529 - val_loss: 1.9016 - val_accuracy: 0.2333\n",
      "Epoch 304/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5452 - accuracy: 0.3671 - val_loss: 1.9066 - val_accuracy: 0.2200\n",
      "Epoch 305/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5432 - accuracy: 0.3643 - val_loss: 1.9140 - val_accuracy: 0.2267\n",
      "Epoch 306/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5458 - accuracy: 0.3600 - val_loss: 1.9100 - val_accuracy: 0.2233\n",
      "Epoch 307/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5436 - accuracy: 0.3671 - val_loss: 1.9064 - val_accuracy: 0.2267\n",
      "Epoch 308/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5453 - accuracy: 0.3600 - val_loss: 1.9129 - val_accuracy: 0.2333\n",
      "Epoch 309/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.5435 - accuracy: 0.3643 - val_loss: 1.9120 - val_accuracy: 0.2367\n",
      "Epoch 310/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5448 - accuracy: 0.3671 - val_loss: 1.9110 - val_accuracy: 0.2167\n",
      "Epoch 311/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5426 - accuracy: 0.3586 - val_loss: 1.9058 - val_accuracy: 0.2300\n",
      "Epoch 312/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5423 - accuracy: 0.3729 - val_loss: 1.9273 - val_accuracy: 0.2367\n",
      "Epoch 313/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5387 - accuracy: 0.3657 - val_loss: 1.9056 - val_accuracy: 0.2633\n",
      "Epoch 314/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5433 - accuracy: 0.3686 - val_loss: 1.9131 - val_accuracy: 0.2300\n",
      "Epoch 315/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5406 - accuracy: 0.3657 - val_loss: 1.9118 - val_accuracy: 0.2233\n",
      "Epoch 316/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5404 - accuracy: 0.3614 - val_loss: 1.9141 - val_accuracy: 0.2233\n",
      "Epoch 317/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5412 - accuracy: 0.3614 - val_loss: 1.9213 - val_accuracy: 0.2333\n",
      "Epoch 318/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5408 - accuracy: 0.3614 - val_loss: 1.9096 - val_accuracy: 0.2300\n",
      "Epoch 319/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5390 - accuracy: 0.3614 - val_loss: 1.9092 - val_accuracy: 0.2300\n",
      "Epoch 320/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.5392 - accuracy: 0.3629 - val_loss: 1.9278 - val_accuracy: 0.2233\n",
      "Epoch 321/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5392 - accuracy: 0.3686 - val_loss: 1.9258 - val_accuracy: 0.2300\n",
      "Epoch 322/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5375 - accuracy: 0.3671 - val_loss: 1.9181 - val_accuracy: 0.2533\n",
      "Epoch 323/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5383 - accuracy: 0.3714 - val_loss: 1.9197 - val_accuracy: 0.2300\n",
      "Epoch 324/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5373 - accuracy: 0.3657 - val_loss: 1.9227 - val_accuracy: 0.2200\n",
      "Epoch 325/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5387 - accuracy: 0.3600 - val_loss: 1.9178 - val_accuracy: 0.2133\n",
      "Epoch 326/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5365 - accuracy: 0.3614 - val_loss: 1.9227 - val_accuracy: 0.2200\n",
      "Epoch 327/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5359 - accuracy: 0.3743 - val_loss: 1.9378 - val_accuracy: 0.2333\n",
      "Epoch 328/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5366 - accuracy: 0.3657 - val_loss: 1.9307 - val_accuracy: 0.2233\n",
      "Epoch 329/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5354 - accuracy: 0.3714 - val_loss: 1.9147 - val_accuracy: 0.2300\n",
      "Epoch 330/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5351 - accuracy: 0.3600 - val_loss: 1.9222 - val_accuracy: 0.2333\n",
      "Epoch 331/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5338 - accuracy: 0.3714 - val_loss: 1.9155 - val_accuracy: 0.2200\n",
      "Epoch 332/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5346 - accuracy: 0.3571 - val_loss: 1.9340 - val_accuracy: 0.2500\n",
      "Epoch 333/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5358 - accuracy: 0.3671 - val_loss: 1.9234 - val_accuracy: 0.2233\n",
      "Epoch 334/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5349 - accuracy: 0.3629 - val_loss: 1.9289 - val_accuracy: 0.2233\n",
      "Epoch 335/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5327 - accuracy: 0.3757 - val_loss: 1.9246 - val_accuracy: 0.2567\n",
      "Epoch 336/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5335 - accuracy: 0.3786 - val_loss: 1.9184 - val_accuracy: 0.2300\n",
      "Epoch 337/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5330 - accuracy: 0.3757 - val_loss: 1.9324 - val_accuracy: 0.2300\n",
      "Epoch 338/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5320 - accuracy: 0.3743 - val_loss: 1.9238 - val_accuracy: 0.2133\n",
      "Epoch 339/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5314 - accuracy: 0.3700 - val_loss: 1.9157 - val_accuracy: 0.2167\n",
      "Epoch 340/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5328 - accuracy: 0.3729 - val_loss: 1.9403 - val_accuracy: 0.2267\n",
      "Epoch 341/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5317 - accuracy: 0.3757 - val_loss: 1.9258 - val_accuracy: 0.2267\n",
      "Epoch 342/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5313 - accuracy: 0.3600 - val_loss: 1.9441 - val_accuracy: 0.2167\n",
      "Epoch 343/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5310 - accuracy: 0.3686 - val_loss: 1.9333 - val_accuracy: 0.2267\n",
      "Epoch 344/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5308 - accuracy: 0.3671 - val_loss: 1.9431 - val_accuracy: 0.2300\n",
      "Epoch 345/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5291 - accuracy: 0.3686 - val_loss: 1.9443 - val_accuracy: 0.2567\n",
      "Epoch 346/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5301 - accuracy: 0.3700 - val_loss: 1.9314 - val_accuracy: 0.2267\n",
      "Epoch 347/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5277 - accuracy: 0.3800 - val_loss: 1.9199 - val_accuracy: 0.2200\n",
      "Epoch 348/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5284 - accuracy: 0.3643 - val_loss: 1.9294 - val_accuracy: 0.2167\n",
      "Epoch 349/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5281 - accuracy: 0.3700 - val_loss: 1.9273 - val_accuracy: 0.2133\n",
      "Epoch 350/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5282 - accuracy: 0.3657 - val_loss: 1.9311 - val_accuracy: 0.2300\n",
      "Epoch 351/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5264 - accuracy: 0.3757 - val_loss: 1.9309 - val_accuracy: 0.2333\n",
      "Epoch 352/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5283 - accuracy: 0.3729 - val_loss: 1.9282 - val_accuracy: 0.2300\n",
      "Epoch 353/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.5256 - accuracy: 0.3657 - val_loss: 1.9422 - val_accuracy: 0.2300\n",
      "Epoch 354/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5279 - accuracy: 0.3700 - val_loss: 1.9350 - val_accuracy: 0.2167\n",
      "Epoch 355/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5261 - accuracy: 0.3600 - val_loss: 1.9553 - val_accuracy: 0.2267\n",
      "Epoch 356/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5260 - accuracy: 0.3700 - val_loss: 1.9442 - val_accuracy: 0.2433\n",
      "Epoch 357/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5259 - accuracy: 0.3743 - val_loss: 1.9355 - val_accuracy: 0.2267\n",
      "Epoch 358/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5251 - accuracy: 0.3729 - val_loss: 1.9494 - val_accuracy: 0.2233\n",
      "Epoch 359/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5251 - accuracy: 0.3729 - val_loss: 1.9450 - val_accuracy: 0.2133\n",
      "Epoch 360/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5232 - accuracy: 0.3743 - val_loss: 1.9454 - val_accuracy: 0.2233\n",
      "Epoch 361/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5232 - accuracy: 0.3686 - val_loss: 1.9485 - val_accuracy: 0.2300\n",
      "Epoch 362/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5240 - accuracy: 0.3643 - val_loss: 1.9508 - val_accuracy: 0.2267\n",
      "Epoch 363/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5215 - accuracy: 0.3757 - val_loss: 1.9527 - val_accuracy: 0.2333\n",
      "Epoch 364/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5230 - accuracy: 0.3643 - val_loss: 1.9381 - val_accuracy: 0.2300\n",
      "Epoch 365/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5224 - accuracy: 0.3771 - val_loss: 1.9524 - val_accuracy: 0.2267\n",
      "Epoch 366/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5222 - accuracy: 0.3686 - val_loss: 1.9406 - val_accuracy: 0.2133\n",
      "Epoch 367/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5221 - accuracy: 0.3757 - val_loss: 1.9567 - val_accuracy: 0.2300\n",
      "Epoch 368/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5206 - accuracy: 0.3786 - val_loss: 1.9551 - val_accuracy: 0.2367\n",
      "Epoch 369/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5207 - accuracy: 0.3629 - val_loss: 1.9321 - val_accuracy: 0.2367\n",
      "Epoch 370/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5200 - accuracy: 0.3757 - val_loss: 1.9534 - val_accuracy: 0.2400\n",
      "Epoch 371/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5209 - accuracy: 0.3671 - val_loss: 1.9508 - val_accuracy: 0.2233\n",
      "Epoch 372/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5195 - accuracy: 0.3729 - val_loss: 1.9590 - val_accuracy: 0.2333\n",
      "Epoch 373/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5205 - accuracy: 0.3757 - val_loss: 1.9453 - val_accuracy: 0.2133\n",
      "Epoch 374/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5197 - accuracy: 0.3686 - val_loss: 1.9514 - val_accuracy: 0.2267\n",
      "Epoch 375/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5181 - accuracy: 0.3843 - val_loss: 1.9386 - val_accuracy: 0.2267\n",
      "Epoch 376/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5182 - accuracy: 0.3800 - val_loss: 1.9487 - val_accuracy: 0.2167\n",
      "Epoch 377/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5170 - accuracy: 0.3743 - val_loss: 1.9760 - val_accuracy: 0.2267\n",
      "Epoch 378/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5182 - accuracy: 0.3743 - val_loss: 1.9761 - val_accuracy: 0.2367\n",
      "Epoch 379/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5188 - accuracy: 0.3700 - val_loss: 1.9516 - val_accuracy: 0.2367\n",
      "Epoch 380/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5166 - accuracy: 0.3671 - val_loss: 1.9602 - val_accuracy: 0.2567\n",
      "Epoch 381/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5180 - accuracy: 0.3786 - val_loss: 1.9711 - val_accuracy: 0.2167\n",
      "Epoch 382/3000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5161 - accuracy: 0.3743 - val_loss: 1.9585 - val_accuracy: 0.2267\n",
      "Epoch 383/3000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 1.5155 - accuracy: 0.3700 - val_loss: 1.9714 - val_accuracy: 0.2433\n",
      "Epoch 384/3000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 1.5164 - accuracy: 0.3771 - val_loss: 1.9509 - val_accuracy: 0.2233\n",
      "Epoch 385/3000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 1.5163 - accuracy: 0.3743 - val_loss: 1.9579 - val_accuracy: 0.2267\n",
      "Epoch 386/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5156 - accuracy: 0.3714 - val_loss: 1.9502 - val_accuracy: 0.2333\n",
      "Epoch 387/3000\n",
      "700/700 [==============================] - 0s 171us/step - loss: 1.5153 - accuracy: 0.3743 - val_loss: 1.9578 - val_accuracy: 0.2300\n",
      "Epoch 388/3000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 1.5143 - accuracy: 0.3714 - val_loss: 1.9668 - val_accuracy: 0.2467\n",
      "Epoch 389/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5158 - accuracy: 0.3800 - val_loss: 1.9490 - val_accuracy: 0.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5125 - accuracy: 0.3671 - val_loss: 1.9572 - val_accuracy: 0.2400\n",
      "Epoch 391/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5132 - accuracy: 0.3757 - val_loss: 1.9539 - val_accuracy: 0.2367\n",
      "Epoch 392/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5137 - accuracy: 0.3714 - val_loss: 1.9599 - val_accuracy: 0.2233\n",
      "Epoch 393/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5137 - accuracy: 0.3757 - val_loss: 1.9730 - val_accuracy: 0.2233\n",
      "Epoch 394/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5136 - accuracy: 0.3757 - val_loss: 1.9565 - val_accuracy: 0.2267\n",
      "Epoch 395/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5132 - accuracy: 0.3771 - val_loss: 1.9565 - val_accuracy: 0.2167\n",
      "Epoch 396/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5124 - accuracy: 0.3771 - val_loss: 1.9619 - val_accuracy: 0.2167\n",
      "Epoch 397/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5111 - accuracy: 0.3857 - val_loss: 1.9755 - val_accuracy: 0.2367\n",
      "Epoch 398/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5124 - accuracy: 0.3643 - val_loss: 1.9588 - val_accuracy: 0.2200\n",
      "Epoch 399/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5107 - accuracy: 0.3743 - val_loss: 1.9904 - val_accuracy: 0.2333\n",
      "Epoch 400/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5113 - accuracy: 0.3643 - val_loss: 1.9599 - val_accuracy: 0.2167\n",
      "Epoch 401/3000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5109 - accuracy: 0.3657 - val_loss: 1.9595 - val_accuracy: 0.2267\n",
      "Epoch 402/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5086 - accuracy: 0.3771 - val_loss: 1.9650 - val_accuracy: 0.2233\n",
      "Epoch 403/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5068 - accuracy: 0.3843 - val_loss: 1.9968 - val_accuracy: 0.2200\n",
      "Epoch 404/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5085 - accuracy: 0.3743 - val_loss: 1.9680 - val_accuracy: 0.2333\n",
      "Epoch 405/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.5074 - accuracy: 0.3800 - val_loss: 1.9833 - val_accuracy: 0.2300\n",
      "Epoch 406/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5085 - accuracy: 0.3771 - val_loss: 1.9756 - val_accuracy: 0.2200\n",
      "Epoch 407/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5080 - accuracy: 0.3714 - val_loss: 1.9815 - val_accuracy: 0.2267\n",
      "Epoch 408/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5077 - accuracy: 0.3757 - val_loss: 1.9711 - val_accuracy: 0.2267\n",
      "Epoch 409/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5040 - accuracy: 0.3700 - val_loss: 1.9807 - val_accuracy: 0.2367\n",
      "Epoch 410/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5058 - accuracy: 0.3771 - val_loss: 1.9611 - val_accuracy: 0.2267\n",
      "Epoch 411/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5056 - accuracy: 0.3714 - val_loss: 1.9846 - val_accuracy: 0.2300\n",
      "Epoch 412/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5048 - accuracy: 0.3843 - val_loss: 1.9728 - val_accuracy: 0.2233\n",
      "Epoch 413/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5033 - accuracy: 0.3771 - val_loss: 1.9781 - val_accuracy: 0.2333\n",
      "Epoch 414/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5043 - accuracy: 0.3786 - val_loss: 1.9881 - val_accuracy: 0.2333\n",
      "Epoch 415/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5015 - accuracy: 0.3786 - val_loss: 1.9798 - val_accuracy: 0.2333\n",
      "Epoch 416/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5031 - accuracy: 0.3843 - val_loss: 1.9929 - val_accuracy: 0.2267\n",
      "Epoch 417/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5032 - accuracy: 0.3786 - val_loss: 1.9828 - val_accuracy: 0.2200\n",
      "Epoch 418/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.5016 - accuracy: 0.3871 - val_loss: 1.9756 - val_accuracy: 0.2333\n",
      "Epoch 419/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5019 - accuracy: 0.3786 - val_loss: 1.9663 - val_accuracy: 0.2200\n",
      "Epoch 420/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5015 - accuracy: 0.3800 - val_loss: 1.9912 - val_accuracy: 0.2300\n",
      "Epoch 421/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5011 - accuracy: 0.3829 - val_loss: 1.9693 - val_accuracy: 0.2433\n",
      "Epoch 422/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5004 - accuracy: 0.3743 - val_loss: 1.9759 - val_accuracy: 0.2433\n",
      "Epoch 423/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5003 - accuracy: 0.3814 - val_loss: 1.9815 - val_accuracy: 0.2333\n",
      "Epoch 424/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5001 - accuracy: 0.3757 - val_loss: 1.9681 - val_accuracy: 0.2200\n",
      "Epoch 425/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4991 - accuracy: 0.3886 - val_loss: 1.9619 - val_accuracy: 0.2400\n",
      "Epoch 426/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4984 - accuracy: 0.3914 - val_loss: 1.9803 - val_accuracy: 0.2167\n",
      "Epoch 427/3000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.4983 - accuracy: 0.3814 - val_loss: 1.9858 - val_accuracy: 0.2533\n",
      "Epoch 428/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4984 - accuracy: 0.3843 - val_loss: 2.0113 - val_accuracy: 0.2300\n",
      "Epoch 429/3000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4982 - accuracy: 0.3771 - val_loss: 1.9701 - val_accuracy: 0.2300\n",
      "Epoch 430/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4977 - accuracy: 0.3814 - val_loss: 1.9836 - val_accuracy: 0.2467\n",
      "Epoch 431/3000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.4990 - accuracy: 0.3786 - val_loss: 1.9920 - val_accuracy: 0.2333\n",
      "Epoch 432/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4974 - accuracy: 0.3843 - val_loss: 1.9780 - val_accuracy: 0.2233\n",
      "Epoch 433/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4967 - accuracy: 0.3814 - val_loss: 1.9880 - val_accuracy: 0.2367\n",
      "Epoch 434/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4976 - accuracy: 0.3743 - val_loss: 1.9917 - val_accuracy: 0.2233\n",
      "Epoch 435/3000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 1.4957 - accuracy: 0.3900 - val_loss: 1.9837 - val_accuracy: 0.2267\n",
      "Epoch 436/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4975 - accuracy: 0.3843 - val_loss: 1.9691 - val_accuracy: 0.2233\n",
      "Epoch 437/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4957 - accuracy: 0.3943 - val_loss: 1.9995 - val_accuracy: 0.2200\n",
      "Epoch 438/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4948 - accuracy: 0.3857 - val_loss: 1.9635 - val_accuracy: 0.2300\n",
      "Epoch 439/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4946 - accuracy: 0.3771 - val_loss: 1.9794 - val_accuracy: 0.2233\n",
      "Epoch 440/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4960 - accuracy: 0.3800 - val_loss: 1.9815 - val_accuracy: 0.2300\n",
      "Epoch 441/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4951 - accuracy: 0.3886 - val_loss: 1.9841 - val_accuracy: 0.2300\n",
      "Epoch 442/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4944 - accuracy: 0.3829 - val_loss: 1.9982 - val_accuracy: 0.2233\n",
      "Epoch 443/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4937 - accuracy: 0.3857 - val_loss: 1.9936 - val_accuracy: 0.2400\n",
      "Epoch 444/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.4855 - accuracy: 0.38 - 0s 210us/step - loss: 1.4946 - accuracy: 0.3829 - val_loss: 1.9965 - val_accuracy: 0.2233\n",
      "Epoch 445/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4942 - accuracy: 0.3829 - val_loss: 2.0001 - val_accuracy: 0.2300\n",
      "Epoch 446/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4931 - accuracy: 0.3886 - val_loss: 2.0088 - val_accuracy: 0.2267\n",
      "Epoch 447/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4926 - accuracy: 0.3800 - val_loss: 2.0223 - val_accuracy: 0.2300\n",
      "Epoch 448/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4927 - accuracy: 0.3843 - val_loss: 1.9971 - val_accuracy: 0.2267\n",
      "Epoch 449/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4918 - accuracy: 0.3886 - val_loss: 2.0059 - val_accuracy: 0.2333\n",
      "Epoch 450/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4929 - accuracy: 0.3843 - val_loss: 1.9975 - val_accuracy: 0.2233\n",
      "Epoch 451/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4919 - accuracy: 0.3843 - val_loss: 2.0043 - val_accuracy: 0.2233\n",
      "Epoch 452/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4908 - accuracy: 0.3857 - val_loss: 1.9997 - val_accuracy: 0.2300\n",
      "Epoch 453/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4910 - accuracy: 0.3871 - val_loss: 1.9943 - val_accuracy: 0.2333\n",
      "Epoch 454/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4908 - accuracy: 0.3871 - val_loss: 2.0016 - val_accuracy: 0.2333\n",
      "Epoch 455/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4907 - accuracy: 0.3843 - val_loss: 1.9913 - val_accuracy: 0.2233\n",
      "Epoch 456/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4898 - accuracy: 0.3786 - val_loss: 1.9959 - val_accuracy: 0.2467\n",
      "Epoch 457/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4899 - accuracy: 0.3871 - val_loss: 2.0019 - val_accuracy: 0.2333\n",
      "Epoch 458/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4902 - accuracy: 0.3857 - val_loss: 1.9970 - val_accuracy: 0.2267\n",
      "Epoch 459/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4881 - accuracy: 0.3943 - val_loss: 1.9948 - val_accuracy: 0.2433\n",
      "Epoch 460/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4900 - accuracy: 0.3886 - val_loss: 2.0062 - val_accuracy: 0.2300\n",
      "Epoch 461/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4883 - accuracy: 0.3957 - val_loss: 2.0089 - val_accuracy: 0.2300\n",
      "Epoch 462/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4883 - accuracy: 0.3900 - val_loss: 1.9980 - val_accuracy: 0.2267\n",
      "Epoch 463/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4872 - accuracy: 0.3857 - val_loss: 2.0059 - val_accuracy: 0.2467\n",
      "Epoch 464/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4871 - accuracy: 0.3871 - val_loss: 1.9923 - val_accuracy: 0.2333\n",
      "Epoch 465/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4877 - accuracy: 0.3900 - val_loss: 2.0023 - val_accuracy: 0.2233\n",
      "Epoch 466/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4871 - accuracy: 0.3757 - val_loss: 2.0065 - val_accuracy: 0.2267\n",
      "Epoch 467/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4873 - accuracy: 0.3871 - val_loss: 2.0133 - val_accuracy: 0.2300\n",
      "Epoch 468/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4865 - accuracy: 0.3829 - val_loss: 1.9941 - val_accuracy: 0.2267\n",
      "Epoch 469/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4859 - accuracy: 0.3871 - val_loss: 2.0429 - val_accuracy: 0.2333\n",
      "Epoch 470/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4871 - accuracy: 0.3871 - val_loss: 2.0173 - val_accuracy: 0.2233\n",
      "Epoch 471/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4859 - accuracy: 0.3957 - val_loss: 2.0124 - val_accuracy: 0.2267\n",
      "Epoch 472/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4845 - accuracy: 0.3971 - val_loss: 2.0157 - val_accuracy: 0.2367\n",
      "Epoch 473/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4850 - accuracy: 0.3914 - val_loss: 2.0205 - val_accuracy: 0.2367\n",
      "Epoch 474/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4838 - accuracy: 0.3900 - val_loss: 2.0030 - val_accuracy: 0.2267\n",
      "Epoch 475/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4842 - accuracy: 0.3900 - val_loss: 2.0116 - val_accuracy: 0.2233\n",
      "Epoch 476/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4835 - accuracy: 0.3900 - val_loss: 2.0127 - val_accuracy: 0.2267\n",
      "Epoch 477/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4839 - accuracy: 0.3900 - val_loss: 2.0173 - val_accuracy: 0.2267\n",
      "Epoch 478/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4838 - accuracy: 0.3929 - val_loss: 2.0124 - val_accuracy: 0.2333\n",
      "Epoch 479/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4833 - accuracy: 0.3900 - val_loss: 2.0080 - val_accuracy: 0.2300\n",
      "Epoch 480/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4824 - accuracy: 0.3957 - val_loss: 2.0183 - val_accuracy: 0.2367\n",
      "Epoch 481/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4821 - accuracy: 0.3871 - val_loss: 2.0288 - val_accuracy: 0.2400\n",
      "Epoch 482/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4810 - accuracy: 0.3986 - val_loss: 2.0248 - val_accuracy: 0.2300\n",
      "Epoch 483/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4821 - accuracy: 0.4000 - val_loss: 2.0233 - val_accuracy: 0.2367\n",
      "Epoch 484/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4815 - accuracy: 0.3986 - val_loss: 2.0255 - val_accuracy: 0.2400\n",
      "Epoch 485/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4811 - accuracy: 0.4029 - val_loss: 2.0243 - val_accuracy: 0.2300\n",
      "Epoch 486/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4808 - accuracy: 0.3857 - val_loss: 2.0156 - val_accuracy: 0.2467\n",
      "Epoch 487/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4811 - accuracy: 0.3957 - val_loss: 2.0159 - val_accuracy: 0.2500\n",
      "Epoch 488/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4808 - accuracy: 0.3914 - val_loss: 2.0247 - val_accuracy: 0.2500\n",
      "Epoch 489/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4804 - accuracy: 0.3886 - val_loss: 2.0107 - val_accuracy: 0.2267\n",
      "Epoch 490/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4809 - accuracy: 0.3900 - val_loss: 2.0066 - val_accuracy: 0.2333\n",
      "Epoch 491/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4808 - accuracy: 0.3871 - val_loss: 2.0321 - val_accuracy: 0.2300\n",
      "Epoch 492/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4800 - accuracy: 0.3914 - val_loss: 2.0072 - val_accuracy: 0.2267\n",
      "Epoch 493/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4799 - accuracy: 0.4014 - val_loss: 2.0164 - val_accuracy: 0.2333\n",
      "Epoch 494/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4802 - accuracy: 0.3900 - val_loss: 2.0155 - val_accuracy: 0.2233\n",
      "Epoch 495/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4792 - accuracy: 0.4029 - val_loss: 2.0383 - val_accuracy: 0.2333\n",
      "Epoch 496/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4786 - accuracy: 0.3857 - val_loss: 2.0199 - val_accuracy: 0.2433\n",
      "Epoch 497/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4773 - accuracy: 0.3929 - val_loss: 2.0210 - val_accuracy: 0.2467\n",
      "Epoch 498/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4763 - accuracy: 0.3886 - val_loss: 2.0652 - val_accuracy: 0.2367\n",
      "Epoch 499/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4775 - accuracy: 0.4014 - val_loss: 2.0415 - val_accuracy: 0.2367\n",
      "Epoch 500/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4780 - accuracy: 0.3929 - val_loss: 2.0389 - val_accuracy: 0.2367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4782 - accuracy: 0.4000 - val_loss: 2.0378 - val_accuracy: 0.2300\n",
      "Epoch 502/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4760 - accuracy: 0.3943 - val_loss: 2.0391 - val_accuracy: 0.2267\n",
      "Epoch 503/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4766 - accuracy: 0.3957 - val_loss: 2.0315 - val_accuracy: 0.2267\n",
      "Epoch 504/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4757 - accuracy: 0.3971 - val_loss: 2.0373 - val_accuracy: 0.2267\n",
      "Epoch 505/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4754 - accuracy: 0.3957 - val_loss: 2.0319 - val_accuracy: 0.2400\n",
      "Epoch 506/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4754 - accuracy: 0.3986 - val_loss: 2.0256 - val_accuracy: 0.2300\n",
      "Epoch 507/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4769 - accuracy: 0.3986 - val_loss: 2.0355 - val_accuracy: 0.2233\n",
      "Epoch 508/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4750 - accuracy: 0.3900 - val_loss: 2.0376 - val_accuracy: 0.2267\n",
      "Epoch 509/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4744 - accuracy: 0.3943 - val_loss: 2.0544 - val_accuracy: 0.2333\n",
      "Epoch 510/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4745 - accuracy: 0.3914 - val_loss: 2.0370 - val_accuracy: 0.2233\n",
      "Epoch 511/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4737 - accuracy: 0.4029 - val_loss: 2.0263 - val_accuracy: 0.2267\n",
      "Epoch 512/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4739 - accuracy: 0.3971 - val_loss: 2.0206 - val_accuracy: 0.2467\n",
      "Epoch 513/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4732 - accuracy: 0.3986 - val_loss: 2.0255 - val_accuracy: 0.2433\n",
      "Epoch 514/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4727 - accuracy: 0.4000 - val_loss: 2.0425 - val_accuracy: 0.2267\n",
      "Epoch 515/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4734 - accuracy: 0.4014 - val_loss: 2.0394 - val_accuracy: 0.2300\n",
      "Epoch 516/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4741 - accuracy: 0.3957 - val_loss: 2.0433 - val_accuracy: 0.2267\n",
      "Epoch 517/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4706 - accuracy: 0.3929 - val_loss: 2.0516 - val_accuracy: 0.2500\n",
      "Epoch 518/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4740 - accuracy: 0.4000 - val_loss: 2.0528 - val_accuracy: 0.2267\n",
      "Epoch 519/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4727 - accuracy: 0.4043 - val_loss: 2.0387 - val_accuracy: 0.2300\n",
      "Epoch 520/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4718 - accuracy: 0.3957 - val_loss: 2.0482 - val_accuracy: 0.2400\n",
      "Epoch 521/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4713 - accuracy: 0.4129 - val_loss: 2.0242 - val_accuracy: 0.2333\n",
      "Epoch 522/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4725 - accuracy: 0.3986 - val_loss: 2.0523 - val_accuracy: 0.2267\n",
      "Epoch 523/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4721 - accuracy: 0.3929 - val_loss: 2.0464 - val_accuracy: 0.2267\n",
      "Epoch 524/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4711 - accuracy: 0.3986 - val_loss: 2.0381 - val_accuracy: 0.2333\n",
      "Epoch 525/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4696 - accuracy: 0.4000 - val_loss: 2.0453 - val_accuracy: 0.2467\n",
      "Epoch 526/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4711 - accuracy: 0.4029 - val_loss: 2.0409 - val_accuracy: 0.2267\n",
      "Epoch 527/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4702 - accuracy: 0.3929 - val_loss: 2.0426 - val_accuracy: 0.2300\n",
      "Epoch 528/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4694 - accuracy: 0.4029 - val_loss: 2.0468 - val_accuracy: 0.2267\n",
      "Epoch 529/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4681 - accuracy: 0.3943 - val_loss: 2.0523 - val_accuracy: 0.2267\n",
      "Epoch 530/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4686 - accuracy: 0.4000 - val_loss: 2.0623 - val_accuracy: 0.2267\n",
      "Epoch 531/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4689 - accuracy: 0.3957 - val_loss: 2.0410 - val_accuracy: 0.2433\n",
      "Epoch 532/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4690 - accuracy: 0.4014 - val_loss: 2.0542 - val_accuracy: 0.2433\n",
      "Epoch 533/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4685 - accuracy: 0.4000 - val_loss: 2.0491 - val_accuracy: 0.2300\n",
      "Epoch 534/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4688 - accuracy: 0.3971 - val_loss: 2.0431 - val_accuracy: 0.2300\n",
      "Epoch 535/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4673 - accuracy: 0.4043 - val_loss: 2.0739 - val_accuracy: 0.2433\n",
      "Epoch 536/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4671 - accuracy: 0.4043 - val_loss: 2.0705 - val_accuracy: 0.2267\n",
      "Epoch 537/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4676 - accuracy: 0.4029 - val_loss: 2.0477 - val_accuracy: 0.2300\n",
      "Epoch 538/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4672 - accuracy: 0.3957 - val_loss: 2.0574 - val_accuracy: 0.2367\n",
      "Epoch 539/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4691 - accuracy: 0.3943 - val_loss: 2.0508 - val_accuracy: 0.2267\n",
      "Epoch 540/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4678 - accuracy: 0.4014 - val_loss: 2.0620 - val_accuracy: 0.2267\n",
      "Epoch 541/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4667 - accuracy: 0.4014 - val_loss: 2.0590 - val_accuracy: 0.2267\n",
      "Epoch 542/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4665 - accuracy: 0.4057 - val_loss: 2.0668 - val_accuracy: 0.2433\n",
      "Epoch 543/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4670 - accuracy: 0.4000 - val_loss: 2.0490 - val_accuracy: 0.2333\n",
      "Epoch 544/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4657 - accuracy: 0.3943 - val_loss: 2.0425 - val_accuracy: 0.2367\n",
      "Epoch 545/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4665 - accuracy: 0.4014 - val_loss: 2.0537 - val_accuracy: 0.2300\n",
      "Epoch 546/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4635 - accuracy: 0.4000 - val_loss: 2.0713 - val_accuracy: 0.2533\n",
      "Epoch 547/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4657 - accuracy: 0.4000 - val_loss: 2.0779 - val_accuracy: 0.2400\n",
      "Epoch 548/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4643 - accuracy: 0.3971 - val_loss: 2.0494 - val_accuracy: 0.2300\n",
      "Epoch 549/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4647 - accuracy: 0.4043 - val_loss: 2.0443 - val_accuracy: 0.2333\n",
      "Epoch 550/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4638 - accuracy: 0.4000 - val_loss: 2.0608 - val_accuracy: 0.2300\n",
      "Epoch 551/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4647 - accuracy: 0.4000 - val_loss: 2.0584 - val_accuracy: 0.2300\n",
      "Epoch 552/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4632 - accuracy: 0.4086 - val_loss: 2.0582 - val_accuracy: 0.2333\n",
      "Epoch 553/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4654 - accuracy: 0.4000 - val_loss: 2.0563 - val_accuracy: 0.2300\n",
      "Epoch 554/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4630 - accuracy: 0.3986 - val_loss: 2.0678 - val_accuracy: 0.2300\n",
      "Epoch 555/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4637 - accuracy: 0.4057 - val_loss: 2.0700 - val_accuracy: 0.2400\n",
      "Epoch 556/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4621 - accuracy: 0.4000 - val_loss: 2.0621 - val_accuracy: 0.2467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 557/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4614 - accuracy: 0.4114 - val_loss: 2.0831 - val_accuracy: 0.2500\n",
      "Epoch 558/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4631 - accuracy: 0.4029 - val_loss: 2.0614 - val_accuracy: 0.2333\n",
      "Epoch 559/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4614 - accuracy: 0.4029 - val_loss: 2.0657 - val_accuracy: 0.2533\n",
      "Epoch 560/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4612 - accuracy: 0.4014 - val_loss: 2.0698 - val_accuracy: 0.2567\n",
      "Epoch 561/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4623 - accuracy: 0.4100 - val_loss: 2.0637 - val_accuracy: 0.2267\n",
      "Epoch 562/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4619 - accuracy: 0.4029 - val_loss: 2.0546 - val_accuracy: 0.2300\n",
      "Epoch 563/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4613 - accuracy: 0.4000 - val_loss: 2.0600 - val_accuracy: 0.2267\n",
      "Epoch 564/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4611 - accuracy: 0.4071 - val_loss: 2.0795 - val_accuracy: 0.2300\n",
      "Epoch 565/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4603 - accuracy: 0.4043 - val_loss: 2.0619 - val_accuracy: 0.2333\n",
      "Epoch 566/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4620 - accuracy: 0.4100 - val_loss: 2.0743 - val_accuracy: 0.2300\n",
      "Epoch 567/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4599 - accuracy: 0.4171 - val_loss: 2.0782 - val_accuracy: 0.2300\n",
      "Epoch 568/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4598 - accuracy: 0.4057 - val_loss: 2.0765 - val_accuracy: 0.2433\n",
      "Epoch 569/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4594 - accuracy: 0.4057 - val_loss: 2.0700 - val_accuracy: 0.2533\n",
      "Epoch 570/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4586 - accuracy: 0.4114 - val_loss: 2.0794 - val_accuracy: 0.2333\n",
      "Epoch 571/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4588 - accuracy: 0.4043 - val_loss: 2.0763 - val_accuracy: 0.2300\n",
      "Epoch 572/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4580 - accuracy: 0.4014 - val_loss: 2.0652 - val_accuracy: 0.2333\n",
      "Epoch 573/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4573 - accuracy: 0.4114 - val_loss: 2.0851 - val_accuracy: 0.2533\n",
      "Epoch 574/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4597 - accuracy: 0.4043 - val_loss: 2.0670 - val_accuracy: 0.2500\n",
      "Epoch 575/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4597 - accuracy: 0.4114 - val_loss: 2.0723 - val_accuracy: 0.2267\n",
      "Epoch 576/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4586 - accuracy: 0.3957 - val_loss: 2.0748 - val_accuracy: 0.2300\n",
      "Epoch 577/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4583 - accuracy: 0.4014 - val_loss: 2.0725 - val_accuracy: 0.2300\n",
      "Epoch 578/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4577 - accuracy: 0.4071 - val_loss: 2.0727 - val_accuracy: 0.2367\n",
      "Epoch 579/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4584 - accuracy: 0.4057 - val_loss: 2.0700 - val_accuracy: 0.2267\n",
      "Epoch 580/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4574 - accuracy: 0.4086 - val_loss: 2.0834 - val_accuracy: 0.2367\n",
      "Epoch 581/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4570 - accuracy: 0.4071 - val_loss: 2.0783 - val_accuracy: 0.2567\n",
      "Epoch 582/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4569 - accuracy: 0.4071 - val_loss: 2.0819 - val_accuracy: 0.2267\n",
      "Epoch 583/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4563 - accuracy: 0.4014 - val_loss: 2.0840 - val_accuracy: 0.2267\n",
      "Epoch 584/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4571 - accuracy: 0.4071 - val_loss: 2.0817 - val_accuracy: 0.2267\n",
      "Epoch 585/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4558 - accuracy: 0.4100 - val_loss: 2.0865 - val_accuracy: 0.2300\n",
      "Epoch 586/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4549 - accuracy: 0.4043 - val_loss: 2.0878 - val_accuracy: 0.2500\n",
      "Epoch 587/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4573 - accuracy: 0.4114 - val_loss: 2.0871 - val_accuracy: 0.2333\n",
      "Epoch 588/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4560 - accuracy: 0.4043 - val_loss: 2.0902 - val_accuracy: 0.2300\n",
      "Epoch 589/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4553 - accuracy: 0.4057 - val_loss: 2.0906 - val_accuracy: 0.2267\n",
      "Epoch 590/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4553 - accuracy: 0.4014 - val_loss: 2.0836 - val_accuracy: 0.2300\n",
      "Epoch 591/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4554 - accuracy: 0.4086 - val_loss: 2.0946 - val_accuracy: 0.2267\n",
      "Epoch 592/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4544 - accuracy: 0.4086 - val_loss: 2.0885 - val_accuracy: 0.2333\n",
      "Epoch 593/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4546 - accuracy: 0.4057 - val_loss: 2.0817 - val_accuracy: 0.2267\n",
      "Epoch 594/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4540 - accuracy: 0.4129 - val_loss: 2.0828 - val_accuracy: 0.2333\n",
      "Epoch 595/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4543 - accuracy: 0.4057 - val_loss: 2.0905 - val_accuracy: 0.2433\n",
      "Epoch 596/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4537 - accuracy: 0.4129 - val_loss: 2.0782 - val_accuracy: 0.2300\n",
      "Epoch 597/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4525 - accuracy: 0.4143 - val_loss: 2.0808 - val_accuracy: 0.2500\n",
      "Epoch 598/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4537 - accuracy: 0.3986 - val_loss: 2.0903 - val_accuracy: 0.2267\n",
      "Epoch 599/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4541 - accuracy: 0.4043 - val_loss: 2.0796 - val_accuracy: 0.2333\n",
      "Epoch 600/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4525 - accuracy: 0.4143 - val_loss: 2.0989 - val_accuracy: 0.2300\n",
      "Epoch 601/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4523 - accuracy: 0.4129 - val_loss: 2.0981 - val_accuracy: 0.2433\n",
      "Epoch 602/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4526 - accuracy: 0.4029 - val_loss: 2.0933 - val_accuracy: 0.2333\n",
      "Epoch 603/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4527 - accuracy: 0.4114 - val_loss: 2.0824 - val_accuracy: 0.2400\n",
      "Epoch 604/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4525 - accuracy: 0.4029 - val_loss: 2.0809 - val_accuracy: 0.2433\n",
      "Epoch 605/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4516 - accuracy: 0.4057 - val_loss: 2.0888 - val_accuracy: 0.2367\n",
      "Epoch 606/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4517 - accuracy: 0.4100 - val_loss: 2.0793 - val_accuracy: 0.2333\n",
      "Epoch 607/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4518 - accuracy: 0.4100 - val_loss: 2.0931 - val_accuracy: 0.2300\n",
      "Epoch 608/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4515 - accuracy: 0.4071 - val_loss: 2.0832 - val_accuracy: 0.2367\n",
      "Epoch 609/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4500 - accuracy: 0.4157 - val_loss: 2.0998 - val_accuracy: 0.2567\n",
      "Epoch 610/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4507 - accuracy: 0.4129 - val_loss: 2.1012 - val_accuracy: 0.2333\n",
      "Epoch 611/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4508 - accuracy: 0.4129 - val_loss: 2.0975 - val_accuracy: 0.2367\n",
      "Epoch 612/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4506 - accuracy: 0.4086 - val_loss: 2.0951 - val_accuracy: 0.2433\n",
      "Epoch 613/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4505 - accuracy: 0.4086 - val_loss: 2.0964 - val_accuracy: 0.2300\n",
      "Epoch 614/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4496 - accuracy: 0.4129 - val_loss: 2.1080 - val_accuracy: 0.2500\n",
      "Epoch 615/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4502 - accuracy: 0.4129 - val_loss: 2.0887 - val_accuracy: 0.2533\n",
      "Epoch 616/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4495 - accuracy: 0.4129 - val_loss: 2.1144 - val_accuracy: 0.2333\n",
      "Epoch 617/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4480 - accuracy: 0.4157 - val_loss: 2.1039 - val_accuracy: 0.2533\n",
      "Epoch 618/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4491 - accuracy: 0.4014 - val_loss: 2.0963 - val_accuracy: 0.2400\n",
      "Epoch 619/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4479 - accuracy: 0.4114 - val_loss: 2.1056 - val_accuracy: 0.2333\n",
      "Epoch 620/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4488 - accuracy: 0.4171 - val_loss: 2.0924 - val_accuracy: 0.2300\n",
      "Epoch 621/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4487 - accuracy: 0.4129 - val_loss: 2.1158 - val_accuracy: 0.2333\n",
      "Epoch 622/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4476 - accuracy: 0.4114 - val_loss: 2.1155 - val_accuracy: 0.2367\n",
      "Epoch 623/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4471 - accuracy: 0.4186 - val_loss: 2.1097 - val_accuracy: 0.2267\n",
      "Epoch 624/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4480 - accuracy: 0.4171 - val_loss: 2.1088 - val_accuracy: 0.2367\n",
      "Epoch 625/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4479 - accuracy: 0.4029 - val_loss: 2.1142 - val_accuracy: 0.2367\n",
      "Epoch 626/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4471 - accuracy: 0.4086 - val_loss: 2.0894 - val_accuracy: 0.2367\n",
      "Epoch 627/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4478 - accuracy: 0.4257 - val_loss: 2.1022 - val_accuracy: 0.2333\n",
      "Epoch 628/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4459 - accuracy: 0.4157 - val_loss: 2.0855 - val_accuracy: 0.2400\n",
      "Epoch 629/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4475 - accuracy: 0.4100 - val_loss: 2.1012 - val_accuracy: 0.2333\n",
      "Epoch 630/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4460 - accuracy: 0.4114 - val_loss: 2.0909 - val_accuracy: 0.2333\n",
      "Epoch 631/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4468 - accuracy: 0.4114 - val_loss: 2.1271 - val_accuracy: 0.2400\n",
      "Epoch 632/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4467 - accuracy: 0.4086 - val_loss: 2.1177 - val_accuracy: 0.2400\n",
      "Epoch 633/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4455 - accuracy: 0.4143 - val_loss: 2.1269 - val_accuracy: 0.2367\n",
      "Epoch 634/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4457 - accuracy: 0.4129 - val_loss: 2.1139 - val_accuracy: 0.2333\n",
      "Epoch 635/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4444 - accuracy: 0.4071 - val_loss: 2.1061 - val_accuracy: 0.2567\n",
      "Epoch 636/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4463 - accuracy: 0.4129 - val_loss: 2.1088 - val_accuracy: 0.2333\n",
      "Epoch 637/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4451 - accuracy: 0.4114 - val_loss: 2.1212 - val_accuracy: 0.2367\n",
      "Epoch 638/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4452 - accuracy: 0.4114 - val_loss: 2.1277 - val_accuracy: 0.2300\n",
      "Epoch 639/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4449 - accuracy: 0.4086 - val_loss: 2.1286 - val_accuracy: 0.2233\n",
      "Epoch 640/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4441 - accuracy: 0.4157 - val_loss: 2.0973 - val_accuracy: 0.2367\n",
      "Epoch 641/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4437 - accuracy: 0.4143 - val_loss: 2.1183 - val_accuracy: 0.2467\n",
      "Epoch 642/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4448 - accuracy: 0.4100 - val_loss: 2.1281 - val_accuracy: 0.2433\n",
      "Epoch 643/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4439 - accuracy: 0.4129 - val_loss: 2.1331 - val_accuracy: 0.2300\n",
      "Epoch 644/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4440 - accuracy: 0.4129 - val_loss: 2.1148 - val_accuracy: 0.2367\n",
      "Epoch 645/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4432 - accuracy: 0.4186 - val_loss: 2.1250 - val_accuracy: 0.2333\n",
      "Epoch 646/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4414 - accuracy: 0.4114 - val_loss: 2.1179 - val_accuracy: 0.2567\n",
      "Epoch 647/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4423 - accuracy: 0.4114 - val_loss: 2.1133 - val_accuracy: 0.2367\n",
      "Epoch 648/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4431 - accuracy: 0.4100 - val_loss: 2.1343 - val_accuracy: 0.2333\n",
      "Epoch 649/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4415 - accuracy: 0.4057 - val_loss: 2.1301 - val_accuracy: 0.2333\n",
      "Epoch 650/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4432 - accuracy: 0.4143 - val_loss: 2.1169 - val_accuracy: 0.2333\n",
      "Epoch 651/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4418 - accuracy: 0.4157 - val_loss: 2.1391 - val_accuracy: 0.2400\n",
      "Epoch 652/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4430 - accuracy: 0.4114 - val_loss: 2.1186 - val_accuracy: 0.2333\n",
      "Epoch 653/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4415 - accuracy: 0.4171 - val_loss: 2.1247 - val_accuracy: 0.2433\n",
      "Epoch 654/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4414 - accuracy: 0.4143 - val_loss: 2.1066 - val_accuracy: 0.2467\n",
      "Epoch 655/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4406 - accuracy: 0.4100 - val_loss: 2.1201 - val_accuracy: 0.2533\n",
      "Epoch 656/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4426 - accuracy: 0.4086 - val_loss: 2.1340 - val_accuracy: 0.2433\n",
      "Epoch 657/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4409 - accuracy: 0.4186 - val_loss: 2.1286 - val_accuracy: 0.2300\n",
      "Epoch 658/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4409 - accuracy: 0.4143 - val_loss: 2.1242 - val_accuracy: 0.2367\n",
      "Epoch 659/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4404 - accuracy: 0.4186 - val_loss: 2.1269 - val_accuracy: 0.2467\n",
      "Epoch 660/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4409 - accuracy: 0.4100 - val_loss: 2.1270 - val_accuracy: 0.2367\n",
      "Epoch 661/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4418 - accuracy: 0.4086 - val_loss: 2.1221 - val_accuracy: 0.2367\n",
      "Epoch 662/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4410 - accuracy: 0.4000 - val_loss: 2.1275 - val_accuracy: 0.2367\n",
      "Epoch 663/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4402 - accuracy: 0.4157 - val_loss: 2.1482 - val_accuracy: 0.2400\n",
      "Epoch 664/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4394 - accuracy: 0.4186 - val_loss: 2.1317 - val_accuracy: 0.2400\n",
      "Epoch 665/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4396 - accuracy: 0.4114 - val_loss: 2.1400 - val_accuracy: 0.2333\n",
      "Epoch 666/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4390 - accuracy: 0.4200 - val_loss: 2.1294 - val_accuracy: 0.2533\n",
      "Epoch 667/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4406 - accuracy: 0.4114 - val_loss: 2.1217 - val_accuracy: 0.2367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4375 - accuracy: 0.4157 - val_loss: 2.1405 - val_accuracy: 0.2567\n",
      "Epoch 669/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4382 - accuracy: 0.4157 - val_loss: 2.1450 - val_accuracy: 0.2333\n",
      "Epoch 670/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4393 - accuracy: 0.4171 - val_loss: 2.1303 - val_accuracy: 0.2333\n",
      "Epoch 671/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4377 - accuracy: 0.4157 - val_loss: 2.1282 - val_accuracy: 0.2533\n",
      "Epoch 672/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4382 - accuracy: 0.4100 - val_loss: 2.1405 - val_accuracy: 0.2367\n",
      "Epoch 673/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4384 - accuracy: 0.4186 - val_loss: 2.1311 - val_accuracy: 0.2400\n",
      "Epoch 674/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4374 - accuracy: 0.4086 - val_loss: 2.1580 - val_accuracy: 0.2433\n",
      "Epoch 675/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4366 - accuracy: 0.4214 - val_loss: 2.1570 - val_accuracy: 0.2533\n",
      "Epoch 676/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4370 - accuracy: 0.4186 - val_loss: 2.1286 - val_accuracy: 0.2567\n",
      "Epoch 677/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4360 - accuracy: 0.4143 - val_loss: 2.1505 - val_accuracy: 0.2300\n",
      "Epoch 678/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4355 - accuracy: 0.4200 - val_loss: 2.1176 - val_accuracy: 0.2333\n",
      "Epoch 679/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4369 - accuracy: 0.4257 - val_loss: 2.1406 - val_accuracy: 0.2367\n",
      "Epoch 680/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4377 - accuracy: 0.4157 - val_loss: 2.1416 - val_accuracy: 0.2400\n",
      "Epoch 681/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4370 - accuracy: 0.4186 - val_loss: 2.1307 - val_accuracy: 0.2400\n",
      "Epoch 682/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4360 - accuracy: 0.4214 - val_loss: 2.1368 - val_accuracy: 0.2567\n",
      "Epoch 683/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4356 - accuracy: 0.4129 - val_loss: 2.1275 - val_accuracy: 0.2500\n",
      "Epoch 684/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4330 - accuracy: 0.4143 - val_loss: 2.1410 - val_accuracy: 0.2600\n",
      "Epoch 685/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4356 - accuracy: 0.4143 - val_loss: 2.1360 - val_accuracy: 0.2567\n",
      "Epoch 686/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4352 - accuracy: 0.4200 - val_loss: 2.1651 - val_accuracy: 0.2533\n",
      "Epoch 687/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4354 - accuracy: 0.4143 - val_loss: 2.1270 - val_accuracy: 0.2367\n",
      "Epoch 688/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4355 - accuracy: 0.4157 - val_loss: 2.1346 - val_accuracy: 0.2400\n",
      "Epoch 689/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4348 - accuracy: 0.4200 - val_loss: 2.1469 - val_accuracy: 0.2367\n",
      "Epoch 690/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4345 - accuracy: 0.4143 - val_loss: 2.1563 - val_accuracy: 0.2333\n",
      "Epoch 691/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4337 - accuracy: 0.4229 - val_loss: 2.1496 - val_accuracy: 0.2333\n",
      "Epoch 692/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4339 - accuracy: 0.4186 - val_loss: 2.1345 - val_accuracy: 0.2400\n",
      "Epoch 693/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4345 - accuracy: 0.4171 - val_loss: 2.1337 - val_accuracy: 0.2400\n",
      "Epoch 694/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4335 - accuracy: 0.4186 - val_loss: 2.1663 - val_accuracy: 0.2467\n",
      "Epoch 695/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4348 - accuracy: 0.4171 - val_loss: 2.1408 - val_accuracy: 0.2567\n",
      "Epoch 696/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4324 - accuracy: 0.4214 - val_loss: 2.1548 - val_accuracy: 0.2333\n",
      "Epoch 697/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4337 - accuracy: 0.4186 - val_loss: 2.1654 - val_accuracy: 0.2467\n",
      "Epoch 698/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4333 - accuracy: 0.4257 - val_loss: 2.1511 - val_accuracy: 0.2433\n",
      "Epoch 699/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4328 - accuracy: 0.4214 - val_loss: 2.1524 - val_accuracy: 0.2400\n",
      "Epoch 700/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4329 - accuracy: 0.4200 - val_loss: 2.1518 - val_accuracy: 0.2467\n",
      "Epoch 701/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4316 - accuracy: 0.4171 - val_loss: 2.1483 - val_accuracy: 0.2433\n",
      "Epoch 702/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4327 - accuracy: 0.4129 - val_loss: 2.1556 - val_accuracy: 0.2367\n",
      "Epoch 703/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4316 - accuracy: 0.4229 - val_loss: 2.1657 - val_accuracy: 0.2333\n",
      "Epoch 704/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4325 - accuracy: 0.4214 - val_loss: 2.1498 - val_accuracy: 0.2433\n",
      "Epoch 705/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4320 - accuracy: 0.4157 - val_loss: 2.1429 - val_accuracy: 0.2400\n",
      "Epoch 706/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4321 - accuracy: 0.4214 - val_loss: 2.1335 - val_accuracy: 0.2400\n",
      "Epoch 707/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4315 - accuracy: 0.4243 - val_loss: 2.1494 - val_accuracy: 0.2367\n",
      "Epoch 708/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4316 - accuracy: 0.4214 - val_loss: 2.1488 - val_accuracy: 0.2333\n",
      "Epoch 709/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4296 - accuracy: 0.4186 - val_loss: 2.1794 - val_accuracy: 0.2533\n",
      "Epoch 710/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4314 - accuracy: 0.4229 - val_loss: 2.1527 - val_accuracy: 0.2467\n",
      "Epoch 711/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4304 - accuracy: 0.4186 - val_loss: 2.1542 - val_accuracy: 0.2367\n",
      "Epoch 712/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4300 - accuracy: 0.4214 - val_loss: 2.1636 - val_accuracy: 0.2567\n",
      "Epoch 713/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4310 - accuracy: 0.4186 - val_loss: 2.1410 - val_accuracy: 0.2400\n",
      "Epoch 714/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4305 - accuracy: 0.4243 - val_loss: 2.1585 - val_accuracy: 0.2367\n",
      "Epoch 715/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4282 - accuracy: 0.4243 - val_loss: 2.1502 - val_accuracy: 0.2600\n",
      "Epoch 716/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4305 - accuracy: 0.4157 - val_loss: 2.1677 - val_accuracy: 0.2367\n",
      "Epoch 717/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4297 - accuracy: 0.4157 - val_loss: 2.1621 - val_accuracy: 0.2367\n",
      "Epoch 718/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4289 - accuracy: 0.4186 - val_loss: 2.1916 - val_accuracy: 0.2533\n",
      "Epoch 719/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4303 - accuracy: 0.4186 - val_loss: 2.1728 - val_accuracy: 0.2400\n",
      "Epoch 720/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4295 - accuracy: 0.4214 - val_loss: 2.1658 - val_accuracy: 0.2367\n",
      "Epoch 721/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4291 - accuracy: 0.4200 - val_loss: 2.1649 - val_accuracy: 0.2433\n",
      "Epoch 722/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4286 - accuracy: 0.4200 - val_loss: 2.1653 - val_accuracy: 0.2367\n",
      "Epoch 723/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4282 - accuracy: 0.4214 - val_loss: 2.1490 - val_accuracy: 0.2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 724/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4281 - accuracy: 0.4257 - val_loss: 2.1736 - val_accuracy: 0.2367\n",
      "Epoch 725/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4277 - accuracy: 0.4229 - val_loss: 2.1819 - val_accuracy: 0.2433\n",
      "Epoch 726/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4278 - accuracy: 0.4257 - val_loss: 2.1563 - val_accuracy: 0.2367\n",
      "Epoch 727/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4273 - accuracy: 0.4214 - val_loss: 2.1938 - val_accuracy: 0.2333\n",
      "Epoch 728/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4276 - accuracy: 0.4200 - val_loss: 2.1558 - val_accuracy: 0.2400\n",
      "Epoch 729/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4269 - accuracy: 0.4229 - val_loss: 2.1856 - val_accuracy: 0.2467\n",
      "Epoch 730/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4269 - accuracy: 0.4257 - val_loss: 2.1927 - val_accuracy: 0.2400\n",
      "Epoch 731/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4277 - accuracy: 0.4143 - val_loss: 2.1736 - val_accuracy: 0.2367\n",
      "Epoch 732/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4261 - accuracy: 0.4243 - val_loss: 2.1707 - val_accuracy: 0.2400\n",
      "Epoch 733/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4263 - accuracy: 0.4286 - val_loss: 2.1618 - val_accuracy: 0.2400\n",
      "Epoch 734/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4271 - accuracy: 0.4214 - val_loss: 2.1844 - val_accuracy: 0.2400\n",
      "Epoch 735/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4261 - accuracy: 0.4286 - val_loss: 2.1732 - val_accuracy: 0.2367\n",
      "Epoch 736/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4249 - accuracy: 0.4300 - val_loss: 2.1629 - val_accuracy: 0.2400\n",
      "Epoch 737/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4265 - accuracy: 0.4229 - val_loss: 2.1866 - val_accuracy: 0.2433\n",
      "Epoch 738/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4265 - accuracy: 0.4200 - val_loss: 2.1722 - val_accuracy: 0.2467\n",
      "Epoch 739/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4251 - accuracy: 0.4271 - val_loss: 2.1827 - val_accuracy: 0.2367\n",
      "Epoch 740/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4250 - accuracy: 0.4314 - val_loss: 2.1680 - val_accuracy: 0.2400\n",
      "Epoch 741/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4249 - accuracy: 0.4200 - val_loss: 2.1864 - val_accuracy: 0.2567\n",
      "Epoch 742/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4252 - accuracy: 0.4143 - val_loss: 2.1628 - val_accuracy: 0.2533\n",
      "Epoch 743/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4240 - accuracy: 0.4286 - val_loss: 2.1670 - val_accuracy: 0.2533\n",
      "Epoch 744/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4257 - accuracy: 0.4186 - val_loss: 2.1682 - val_accuracy: 0.2433\n",
      "Epoch 745/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4221 - accuracy: 0.4329 - val_loss: 2.1818 - val_accuracy: 0.2533\n",
      "Epoch 746/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4254 - accuracy: 0.4300 - val_loss: 2.1702 - val_accuracy: 0.2400\n",
      "Epoch 747/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4251 - accuracy: 0.4157 - val_loss: 2.1784 - val_accuracy: 0.2433\n",
      "Epoch 748/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4233 - accuracy: 0.4257 - val_loss: 2.2001 - val_accuracy: 0.2600\n",
      "Epoch 749/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4222 - accuracy: 0.4271 - val_loss: 2.1563 - val_accuracy: 0.2333\n",
      "Epoch 750/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4239 - accuracy: 0.4329 - val_loss: 2.1629 - val_accuracy: 0.2300\n",
      "Epoch 751/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4224 - accuracy: 0.4171 - val_loss: 2.1794 - val_accuracy: 0.2400\n",
      "Epoch 752/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4233 - accuracy: 0.4243 - val_loss: 2.1854 - val_accuracy: 0.2367\n",
      "Epoch 753/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4223 - accuracy: 0.4257 - val_loss: 2.2051 - val_accuracy: 0.2333\n",
      "Epoch 754/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4235 - accuracy: 0.4271 - val_loss: 2.1869 - val_accuracy: 0.2333\n",
      "Epoch 755/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4221 - accuracy: 0.4386 - val_loss: 2.1849 - val_accuracy: 0.2467\n",
      "Epoch 756/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4223 - accuracy: 0.4143 - val_loss: 2.1829 - val_accuracy: 0.2400\n",
      "Epoch 757/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4233 - accuracy: 0.4200 - val_loss: 2.1907 - val_accuracy: 0.2433\n",
      "Epoch 758/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4220 - accuracy: 0.4300 - val_loss: 2.1885 - val_accuracy: 0.2433\n",
      "Epoch 759/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4221 - accuracy: 0.4271 - val_loss: 2.1786 - val_accuracy: 0.2400\n",
      "Epoch 760/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4218 - accuracy: 0.4329 - val_loss: 2.1784 - val_accuracy: 0.2400\n",
      "Epoch 761/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4215 - accuracy: 0.4229 - val_loss: 2.2086 - val_accuracy: 0.2500\n",
      "Epoch 762/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4225 - accuracy: 0.4257 - val_loss: 2.1981 - val_accuracy: 0.2400\n",
      "Epoch 763/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4215 - accuracy: 0.4200 - val_loss: 2.1838 - val_accuracy: 0.2400\n",
      "Epoch 764/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4227 - accuracy: 0.4300 - val_loss: 2.2048 - val_accuracy: 0.2433\n",
      "Epoch 765/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4203 - accuracy: 0.4214 - val_loss: 2.2158 - val_accuracy: 0.2333\n",
      "Epoch 766/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4217 - accuracy: 0.4214 - val_loss: 2.1842 - val_accuracy: 0.2400\n",
      "Epoch 767/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4217 - accuracy: 0.4257 - val_loss: 2.1846 - val_accuracy: 0.2367\n",
      "Epoch 768/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4205 - accuracy: 0.4257 - val_loss: 2.1738 - val_accuracy: 0.2400\n",
      "Epoch 769/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4207 - accuracy: 0.4243 - val_loss: 2.1856 - val_accuracy: 0.2367\n",
      "Epoch 770/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4200 - accuracy: 0.4214 - val_loss: 2.1758 - val_accuracy: 0.2333\n",
      "Epoch 771/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4196 - accuracy: 0.4214 - val_loss: 2.1942 - val_accuracy: 0.2367\n",
      "Epoch 772/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4202 - accuracy: 0.4229 - val_loss: 2.1983 - val_accuracy: 0.2433\n",
      "Epoch 773/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4200 - accuracy: 0.4229 - val_loss: 2.2066 - val_accuracy: 0.2500\n",
      "Epoch 774/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4191 - accuracy: 0.4243 - val_loss: 2.2019 - val_accuracy: 0.2400\n",
      "Epoch 775/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4182 - accuracy: 0.4286 - val_loss: 2.2032 - val_accuracy: 0.2533\n",
      "Epoch 776/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4193 - accuracy: 0.4271 - val_loss: 2.1977 - val_accuracy: 0.2467\n",
      "Epoch 777/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4177 - accuracy: 0.4314 - val_loss: 2.2090 - val_accuracy: 0.2333\n",
      "Epoch 778/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4190 - accuracy: 0.4214 - val_loss: 2.1922 - val_accuracy: 0.2333\n",
      "Epoch 779/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4191 - accuracy: 0.4300 - val_loss: 2.1962 - val_accuracy: 0.2333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4190 - accuracy: 0.4229 - val_loss: 2.1879 - val_accuracy: 0.2400\n",
      "Epoch 781/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4196 - accuracy: 0.4214 - val_loss: 2.1973 - val_accuracy: 0.2467\n",
      "Epoch 782/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4184 - accuracy: 0.4257 - val_loss: 2.1738 - val_accuracy: 0.2400\n",
      "Epoch 783/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4186 - accuracy: 0.4329 - val_loss: 2.2047 - val_accuracy: 0.2433\n",
      "Epoch 784/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4181 - accuracy: 0.4300 - val_loss: 2.2132 - val_accuracy: 0.2400\n",
      "Epoch 785/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4179 - accuracy: 0.4271 - val_loss: 2.2198 - val_accuracy: 0.2367\n",
      "Epoch 786/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4180 - accuracy: 0.4271 - val_loss: 2.1994 - val_accuracy: 0.2467\n",
      "Epoch 787/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4184 - accuracy: 0.4243 - val_loss: 2.1838 - val_accuracy: 0.2500\n",
      "Epoch 788/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4178 - accuracy: 0.4271 - val_loss: 2.1991 - val_accuracy: 0.2400\n",
      "Epoch 789/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4173 - accuracy: 0.4229 - val_loss: 2.1994 - val_accuracy: 0.2400\n",
      "Epoch 790/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4174 - accuracy: 0.4314 - val_loss: 2.2033 - val_accuracy: 0.2400\n",
      "Epoch 791/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4164 - accuracy: 0.4286 - val_loss: 2.2056 - val_accuracy: 0.2500\n",
      "Epoch 792/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4171 - accuracy: 0.4229 - val_loss: 2.1936 - val_accuracy: 0.2367\n",
      "Epoch 793/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4166 - accuracy: 0.4257 - val_loss: 2.2141 - val_accuracy: 0.2500\n",
      "Epoch 794/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4169 - accuracy: 0.4271 - val_loss: 2.2061 - val_accuracy: 0.2367\n",
      "Epoch 795/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4164 - accuracy: 0.4314 - val_loss: 2.2030 - val_accuracy: 0.2400\n",
      "Epoch 796/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4160 - accuracy: 0.4300 - val_loss: 2.2047 - val_accuracy: 0.2367\n",
      "Epoch 797/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4164 - accuracy: 0.4200 - val_loss: 2.2128 - val_accuracy: 0.2367\n",
      "Epoch 798/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4162 - accuracy: 0.4386 - val_loss: 2.2137 - val_accuracy: 0.2400\n",
      "Epoch 799/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4152 - accuracy: 0.4329 - val_loss: 2.2049 - val_accuracy: 0.2567\n",
      "Epoch 800/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4159 - accuracy: 0.4200 - val_loss: 2.2158 - val_accuracy: 0.2333\n",
      "Epoch 801/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4159 - accuracy: 0.4329 - val_loss: 2.2122 - val_accuracy: 0.2333\n",
      "Epoch 802/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4158 - accuracy: 0.4329 - val_loss: 2.2595 - val_accuracy: 0.2400\n",
      "Epoch 803/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4146 - accuracy: 0.4271 - val_loss: 2.2121 - val_accuracy: 0.2600\n",
      "Epoch 804/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4148 - accuracy: 0.4243 - val_loss: 2.2039 - val_accuracy: 0.2433\n",
      "Epoch 805/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4143 - accuracy: 0.4329 - val_loss: 2.2054 - val_accuracy: 0.2467\n",
      "Epoch 806/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4148 - accuracy: 0.4357 - val_loss: 2.2052 - val_accuracy: 0.2400\n",
      "Epoch 807/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4148 - accuracy: 0.4386 - val_loss: 2.2125 - val_accuracy: 0.2500\n",
      "Epoch 808/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4143 - accuracy: 0.4314 - val_loss: 2.2125 - val_accuracy: 0.2400\n",
      "Epoch 809/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4150 - accuracy: 0.4229 - val_loss: 2.2137 - val_accuracy: 0.2467\n",
      "Epoch 810/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4139 - accuracy: 0.4357 - val_loss: 2.2157 - val_accuracy: 0.2367\n",
      "Epoch 811/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4142 - accuracy: 0.4314 - val_loss: 2.2169 - val_accuracy: 0.2400\n",
      "Epoch 812/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4141 - accuracy: 0.4271 - val_loss: 2.2032 - val_accuracy: 0.2400\n",
      "Epoch 813/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4139 - accuracy: 0.4329 - val_loss: 2.2245 - val_accuracy: 0.2400\n",
      "Epoch 814/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4131 - accuracy: 0.4286 - val_loss: 2.2157 - val_accuracy: 0.2533\n",
      "Epoch 815/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4139 - accuracy: 0.4314 - val_loss: 2.2224 - val_accuracy: 0.2467\n",
      "Epoch 816/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4136 - accuracy: 0.4300 - val_loss: 2.2146 - val_accuracy: 0.2367\n",
      "Epoch 817/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4116 - accuracy: 0.4300 - val_loss: 2.2146 - val_accuracy: 0.2367\n",
      "Epoch 818/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4123 - accuracy: 0.4286 - val_loss: 2.2243 - val_accuracy: 0.2367\n",
      "Epoch 819/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4110 - accuracy: 0.4357 - val_loss: 2.2386 - val_accuracy: 0.2600\n",
      "Epoch 820/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4131 - accuracy: 0.4329 - val_loss: 2.2190 - val_accuracy: 0.2567\n",
      "Epoch 821/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4129 - accuracy: 0.4300 - val_loss: 2.2348 - val_accuracy: 0.2467\n",
      "Epoch 822/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4130 - accuracy: 0.4329 - val_loss: 2.2198 - val_accuracy: 0.2367\n",
      "Epoch 823/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4114 - accuracy: 0.4271 - val_loss: 2.2264 - val_accuracy: 0.2433\n",
      "Epoch 824/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4110 - accuracy: 0.4300 - val_loss: 2.2265 - val_accuracy: 0.2433\n",
      "Epoch 825/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4112 - accuracy: 0.4314 - val_loss: 2.2452 - val_accuracy: 0.2467\n",
      "Epoch 826/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4122 - accuracy: 0.4271 - val_loss: 2.2332 - val_accuracy: 0.2467\n",
      "Epoch 827/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4112 - accuracy: 0.4300 - val_loss: 2.2318 - val_accuracy: 0.2400\n",
      "Epoch 828/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4118 - accuracy: 0.4343 - val_loss: 2.2184 - val_accuracy: 0.2367\n",
      "Epoch 829/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4111 - accuracy: 0.4314 - val_loss: 2.2233 - val_accuracy: 0.2433\n",
      "Epoch 830/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4104 - accuracy: 0.4271 - val_loss: 2.2284 - val_accuracy: 0.2400\n",
      "Epoch 831/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4105 - accuracy: 0.4443 - val_loss: 2.2469 - val_accuracy: 0.2467\n",
      "Epoch 832/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4111 - accuracy: 0.4343 - val_loss: 2.2477 - val_accuracy: 0.2500\n",
      "Epoch 833/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4110 - accuracy: 0.4243 - val_loss: 2.2534 - val_accuracy: 0.2467\n",
      "Epoch 834/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4106 - accuracy: 0.4329 - val_loss: 2.2659 - val_accuracy: 0.2433\n",
      "Epoch 835/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4095 - accuracy: 0.4300 - val_loss: 2.2260 - val_accuracy: 0.2367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 836/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4098 - accuracy: 0.4271 - val_loss: 2.2383 - val_accuracy: 0.2500\n",
      "Epoch 837/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4102 - accuracy: 0.4300 - val_loss: 2.2211 - val_accuracy: 0.2433\n",
      "Epoch 838/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4107 - accuracy: 0.4329 - val_loss: 2.2368 - val_accuracy: 0.2367\n",
      "Epoch 839/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4088 - accuracy: 0.4300 - val_loss: 2.2353 - val_accuracy: 0.2367\n",
      "Epoch 840/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4081 - accuracy: 0.4343 - val_loss: 2.2224 - val_accuracy: 0.2433\n",
      "Epoch 841/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4092 - accuracy: 0.4371 - val_loss: 2.2331 - val_accuracy: 0.2367\n",
      "Epoch 842/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4098 - accuracy: 0.4271 - val_loss: 2.2487 - val_accuracy: 0.2500\n",
      "Epoch 843/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4090 - accuracy: 0.4314 - val_loss: 2.2326 - val_accuracy: 0.2367\n",
      "Epoch 844/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4082 - accuracy: 0.4300 - val_loss: 2.2510 - val_accuracy: 0.2367\n",
      "Epoch 845/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4088 - accuracy: 0.4314 - val_loss: 2.2242 - val_accuracy: 0.2367\n",
      "Epoch 846/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4092 - accuracy: 0.4357 - val_loss: 2.2349 - val_accuracy: 0.2400\n",
      "Epoch 847/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4075 - accuracy: 0.4229 - val_loss: 2.2487 - val_accuracy: 0.2433\n",
      "Epoch 848/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4079 - accuracy: 0.4371 - val_loss: 2.2414 - val_accuracy: 0.2533\n",
      "Epoch 849/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4086 - accuracy: 0.4300 - val_loss: 2.2446 - val_accuracy: 0.2433\n",
      "Epoch 850/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4071 - accuracy: 0.4314 - val_loss: 2.2355 - val_accuracy: 0.2367\n",
      "Epoch 851/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4071 - accuracy: 0.4229 - val_loss: 2.2345 - val_accuracy: 0.2333\n",
      "Epoch 852/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4086 - accuracy: 0.4371 - val_loss: 2.2389 - val_accuracy: 0.2433\n",
      "Epoch 853/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4066 - accuracy: 0.4329 - val_loss: 2.2368 - val_accuracy: 0.2367\n",
      "Epoch 854/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4046 - accuracy: 0.4371 - val_loss: 2.2682 - val_accuracy: 0.2600\n",
      "Epoch 855/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4074 - accuracy: 0.4271 - val_loss: 2.2383 - val_accuracy: 0.2333\n",
      "Epoch 856/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4074 - accuracy: 0.4357 - val_loss: 2.2498 - val_accuracy: 0.2500\n",
      "Epoch 857/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4067 - accuracy: 0.4286 - val_loss: 2.2486 - val_accuracy: 0.2467\n",
      "Epoch 858/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4066 - accuracy: 0.4343 - val_loss: 2.2459 - val_accuracy: 0.2367\n",
      "Epoch 859/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4052 - accuracy: 0.4357 - val_loss: 2.2438 - val_accuracy: 0.2367\n",
      "Epoch 860/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4057 - accuracy: 0.4357 - val_loss: 2.2736 - val_accuracy: 0.2533\n",
      "Epoch 861/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4064 - accuracy: 0.4343 - val_loss: 2.2575 - val_accuracy: 0.2433\n",
      "Epoch 862/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4071 - accuracy: 0.4271 - val_loss: 2.2603 - val_accuracy: 0.2533\n",
      "Epoch 863/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4055 - accuracy: 0.4329 - val_loss: 2.2607 - val_accuracy: 0.2500\n",
      "Epoch 864/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4053 - accuracy: 0.4329 - val_loss: 2.2554 - val_accuracy: 0.2533\n",
      "Epoch 865/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4047 - accuracy: 0.4386 - val_loss: 2.2618 - val_accuracy: 0.2633\n",
      "Epoch 866/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4049 - accuracy: 0.4314 - val_loss: 2.2232 - val_accuracy: 0.2433\n",
      "Epoch 867/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4052 - accuracy: 0.4357 - val_loss: 2.2613 - val_accuracy: 0.2433\n",
      "Epoch 868/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4054 - accuracy: 0.4357 - val_loss: 2.2531 - val_accuracy: 0.2467\n",
      "Epoch 869/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4050 - accuracy: 0.4386 - val_loss: 2.2509 - val_accuracy: 0.2400\n",
      "Epoch 870/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4034 - accuracy: 0.4357 - val_loss: 2.2675 - val_accuracy: 0.2467\n",
      "Epoch 871/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4048 - accuracy: 0.4314 - val_loss: 2.2729 - val_accuracy: 0.2467\n",
      "Epoch 872/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4037 - accuracy: 0.4357 - val_loss: 2.2533 - val_accuracy: 0.2567\n",
      "Epoch 873/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4042 - accuracy: 0.4343 - val_loss: 2.2292 - val_accuracy: 0.2367\n",
      "Epoch 874/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4048 - accuracy: 0.4329 - val_loss: 2.2420 - val_accuracy: 0.2367\n",
      "Epoch 875/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4038 - accuracy: 0.4329 - val_loss: 2.2705 - val_accuracy: 0.2467\n",
      "Epoch 876/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4035 - accuracy: 0.4314 - val_loss: 2.2423 - val_accuracy: 0.2433\n",
      "Epoch 877/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4037 - accuracy: 0.4271 - val_loss: 2.2683 - val_accuracy: 0.2367\n",
      "Epoch 878/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4042 - accuracy: 0.4343 - val_loss: 2.2634 - val_accuracy: 0.2400\n",
      "Epoch 879/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4012 - accuracy: 0.4371 - val_loss: 2.2625 - val_accuracy: 0.2400\n",
      "Epoch 880/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4051 - accuracy: 0.4329 - val_loss: 2.2507 - val_accuracy: 0.2400\n",
      "Epoch 881/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4035 - accuracy: 0.4429 - val_loss: 2.2849 - val_accuracy: 0.2500\n",
      "Epoch 882/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4035 - accuracy: 0.4371 - val_loss: 2.2680 - val_accuracy: 0.2400\n",
      "Epoch 883/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4044 - accuracy: 0.4286 - val_loss: 2.2364 - val_accuracy: 0.2400\n",
      "Epoch 884/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4027 - accuracy: 0.4314 - val_loss: 2.2784 - val_accuracy: 0.2533\n",
      "Epoch 885/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4031 - accuracy: 0.4314 - val_loss: 2.2322 - val_accuracy: 0.2433\n",
      "Epoch 886/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4036 - accuracy: 0.4386 - val_loss: 2.2614 - val_accuracy: 0.2467\n",
      "Epoch 887/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4026 - accuracy: 0.4371 - val_loss: 2.2456 - val_accuracy: 0.2367\n",
      "Epoch 888/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4027 - accuracy: 0.4357 - val_loss: 2.2595 - val_accuracy: 0.2400\n",
      "Epoch 889/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4010 - accuracy: 0.4443 - val_loss: 2.2736 - val_accuracy: 0.2600\n",
      "Epoch 890/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4028 - accuracy: 0.4386 - val_loss: 2.2630 - val_accuracy: 0.2567\n",
      "Epoch 891/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4024 - accuracy: 0.4271 - val_loss: 2.2669 - val_accuracy: 0.2433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 892/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4024 - accuracy: 0.4357 - val_loss: 2.2699 - val_accuracy: 0.2433\n",
      "Epoch 893/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4018 - accuracy: 0.4357 - val_loss: 2.2777 - val_accuracy: 0.2433\n",
      "Epoch 894/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4020 - accuracy: 0.4429 - val_loss: 2.2620 - val_accuracy: 0.2400\n",
      "Epoch 895/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4012 - accuracy: 0.4343 - val_loss: 2.2655 - val_accuracy: 0.2467\n",
      "Epoch 896/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4014 - accuracy: 0.4357 - val_loss: 2.2715 - val_accuracy: 0.2600\n",
      "Epoch 897/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4017 - accuracy: 0.4343 - val_loss: 2.2648 - val_accuracy: 0.2533\n",
      "Epoch 898/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4011 - accuracy: 0.4386 - val_loss: 2.2896 - val_accuracy: 0.2467\n",
      "Epoch 899/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4015 - accuracy: 0.4343 - val_loss: 2.2583 - val_accuracy: 0.2467\n",
      "Epoch 900/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4001 - accuracy: 0.4471 - val_loss: 2.2617 - val_accuracy: 0.2467\n",
      "Epoch 901/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3999 - accuracy: 0.4400 - val_loss: 2.2772 - val_accuracy: 0.2533\n",
      "Epoch 902/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4001 - accuracy: 0.4343 - val_loss: 2.2689 - val_accuracy: 0.2467\n",
      "Epoch 903/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3992 - accuracy: 0.4414 - val_loss: 2.2865 - val_accuracy: 0.2633\n",
      "Epoch 904/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3991 - accuracy: 0.4357 - val_loss: 2.2582 - val_accuracy: 0.2400\n",
      "Epoch 905/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4010 - accuracy: 0.4400 - val_loss: 2.2543 - val_accuracy: 0.2400\n",
      "Epoch 906/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3998 - accuracy: 0.4371 - val_loss: 2.2494 - val_accuracy: 0.2367\n",
      "Epoch 907/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4003 - accuracy: 0.4386 - val_loss: 2.2830 - val_accuracy: 0.2467\n",
      "Epoch 908/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3997 - accuracy: 0.4414 - val_loss: 2.2715 - val_accuracy: 0.2433\n",
      "Epoch 909/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3993 - accuracy: 0.4329 - val_loss: 2.2790 - val_accuracy: 0.2500\n",
      "Epoch 910/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4004 - accuracy: 0.4357 - val_loss: 2.2561 - val_accuracy: 0.2400\n",
      "Epoch 911/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3991 - accuracy: 0.4371 - val_loss: 2.2786 - val_accuracy: 0.2367\n",
      "Epoch 912/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3995 - accuracy: 0.4400 - val_loss: 2.2665 - val_accuracy: 0.2367\n",
      "Epoch 913/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4000 - accuracy: 0.4371 - val_loss: 2.2924 - val_accuracy: 0.2433\n",
      "Epoch 914/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3988 - accuracy: 0.4386 - val_loss: 2.2909 - val_accuracy: 0.2567\n",
      "Epoch 915/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3990 - accuracy: 0.4343 - val_loss: 2.2737 - val_accuracy: 0.2467\n",
      "Epoch 916/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3987 - accuracy: 0.4386 - val_loss: 2.2810 - val_accuracy: 0.2400\n",
      "Epoch 917/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3978 - accuracy: 0.4400 - val_loss: 2.2807 - val_accuracy: 0.2400\n",
      "Epoch 918/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3970 - accuracy: 0.4386 - val_loss: 2.2802 - val_accuracy: 0.2533\n",
      "Epoch 919/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3984 - accuracy: 0.4329 - val_loss: 2.2901 - val_accuracy: 0.2433\n",
      "Epoch 920/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3988 - accuracy: 0.4343 - val_loss: 2.2681 - val_accuracy: 0.2500\n",
      "Epoch 921/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3984 - accuracy: 0.4357 - val_loss: 2.2706 - val_accuracy: 0.2400\n",
      "Epoch 922/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3967 - accuracy: 0.4400 - val_loss: 2.2872 - val_accuracy: 0.2500\n",
      "Epoch 923/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3966 - accuracy: 0.4386 - val_loss: 2.2698 - val_accuracy: 0.2567\n",
      "Epoch 924/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3988 - accuracy: 0.4414 - val_loss: 2.2782 - val_accuracy: 0.2467\n",
      "Epoch 925/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3970 - accuracy: 0.4343 - val_loss: 2.2855 - val_accuracy: 0.2367\n",
      "Epoch 926/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3972 - accuracy: 0.4443 - val_loss: 2.2793 - val_accuracy: 0.2467\n",
      "Epoch 927/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3975 - accuracy: 0.4357 - val_loss: 2.2798 - val_accuracy: 0.2400\n",
      "Epoch 928/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3971 - accuracy: 0.4400 - val_loss: 2.3013 - val_accuracy: 0.2433\n",
      "Epoch 929/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3971 - accuracy: 0.4414 - val_loss: 2.2997 - val_accuracy: 0.2400\n",
      "Epoch 930/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3971 - accuracy: 0.4357 - val_loss: 2.2816 - val_accuracy: 0.2467\n",
      "Epoch 931/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3967 - accuracy: 0.4329 - val_loss: 2.2836 - val_accuracy: 0.2467\n",
      "Epoch 932/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3962 - accuracy: 0.4400 - val_loss: 2.2720 - val_accuracy: 0.2500\n",
      "Epoch 933/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3966 - accuracy: 0.4314 - val_loss: 2.2861 - val_accuracy: 0.2467\n",
      "Epoch 934/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3958 - accuracy: 0.4414 - val_loss: 2.2939 - val_accuracy: 0.2500\n",
      "Epoch 935/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3966 - accuracy: 0.4414 - val_loss: 2.2901 - val_accuracy: 0.2500\n",
      "Epoch 936/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3965 - accuracy: 0.4429 - val_loss: 2.2962 - val_accuracy: 0.2500\n",
      "Epoch 937/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3960 - accuracy: 0.4400 - val_loss: 2.2877 - val_accuracy: 0.2367\n",
      "Epoch 938/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3953 - accuracy: 0.4443 - val_loss: 2.2991 - val_accuracy: 0.2500\n",
      "Epoch 939/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3953 - accuracy: 0.4386 - val_loss: 2.3114 - val_accuracy: 0.2500\n",
      "Epoch 940/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3960 - accuracy: 0.4343 - val_loss: 2.2826 - val_accuracy: 0.2400\n",
      "Epoch 941/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3957 - accuracy: 0.4343 - val_loss: 2.2917 - val_accuracy: 0.2400\n",
      "Epoch 942/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3947 - accuracy: 0.4357 - val_loss: 2.2695 - val_accuracy: 0.2333\n",
      "Epoch 943/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3955 - accuracy: 0.4414 - val_loss: 2.3028 - val_accuracy: 0.2433\n",
      "Epoch 944/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3944 - accuracy: 0.4371 - val_loss: 2.3057 - val_accuracy: 0.2433\n",
      "Epoch 945/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3947 - accuracy: 0.4329 - val_loss: 2.3010 - val_accuracy: 0.2500\n",
      "Epoch 946/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3945 - accuracy: 0.4329 - val_loss: 2.2912 - val_accuracy: 0.2467\n",
      "Epoch 947/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3939 - accuracy: 0.4414 - val_loss: 2.3067 - val_accuracy: 0.2533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 948/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3940 - accuracy: 0.4300 - val_loss: 2.2777 - val_accuracy: 0.2367\n",
      "Epoch 949/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3938 - accuracy: 0.4471 - val_loss: 2.2906 - val_accuracy: 0.2400\n",
      "Epoch 950/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3929 - accuracy: 0.4386 - val_loss: 2.2916 - val_accuracy: 0.2367\n",
      "Epoch 951/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3940 - accuracy: 0.4429 - val_loss: 2.3014 - val_accuracy: 0.2500\n",
      "Epoch 952/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3938 - accuracy: 0.4414 - val_loss: 2.2949 - val_accuracy: 0.2467\n",
      "Epoch 953/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3935 - accuracy: 0.4371 - val_loss: 2.3148 - val_accuracy: 0.2533\n",
      "Epoch 954/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3940 - accuracy: 0.4471 - val_loss: 2.2962 - val_accuracy: 0.2567\n",
      "Epoch 955/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3936 - accuracy: 0.4429 - val_loss: 2.3098 - val_accuracy: 0.2500\n",
      "Epoch 956/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3928 - accuracy: 0.4386 - val_loss: 2.3181 - val_accuracy: 0.2433\n",
      "Epoch 957/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3925 - accuracy: 0.4414 - val_loss: 2.2925 - val_accuracy: 0.2433\n",
      "Epoch 958/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3938 - accuracy: 0.4343 - val_loss: 2.3365 - val_accuracy: 0.2467\n",
      "Epoch 959/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3936 - accuracy: 0.4414 - val_loss: 2.2892 - val_accuracy: 0.2467\n",
      "Epoch 960/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3930 - accuracy: 0.4400 - val_loss: 2.3049 - val_accuracy: 0.2467\n",
      "Epoch 961/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3923 - accuracy: 0.4429 - val_loss: 2.2714 - val_accuracy: 0.2467\n",
      "Epoch 962/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3931 - accuracy: 0.4400 - val_loss: 2.3025 - val_accuracy: 0.2467\n",
      "Epoch 963/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3926 - accuracy: 0.4386 - val_loss: 2.2963 - val_accuracy: 0.2500\n",
      "Epoch 964/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3919 - accuracy: 0.4357 - val_loss: 2.2856 - val_accuracy: 0.2433\n",
      "Epoch 965/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3913 - accuracy: 0.4414 - val_loss: 2.2959 - val_accuracy: 0.2533\n",
      "Epoch 966/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3924 - accuracy: 0.4429 - val_loss: 2.3148 - val_accuracy: 0.2567\n",
      "Epoch 967/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3923 - accuracy: 0.4429 - val_loss: 2.3105 - val_accuracy: 0.2467\n",
      "Epoch 968/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3913 - accuracy: 0.4400 - val_loss: 2.2989 - val_accuracy: 0.2433\n",
      "Epoch 969/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3917 - accuracy: 0.4414 - val_loss: 2.3052 - val_accuracy: 0.2433\n",
      "Epoch 970/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3916 - accuracy: 0.4400 - val_loss: 2.3201 - val_accuracy: 0.2400\n",
      "Epoch 971/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3916 - accuracy: 0.4414 - val_loss: 2.3001 - val_accuracy: 0.2467\n",
      "Epoch 972/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3913 - accuracy: 0.4386 - val_loss: 2.3213 - val_accuracy: 0.2333\n",
      "Epoch 973/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3901 - accuracy: 0.4400 - val_loss: 2.3114 - val_accuracy: 0.2500\n",
      "Epoch 974/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3908 - accuracy: 0.4386 - val_loss: 2.3123 - val_accuracy: 0.2500\n",
      "Epoch 975/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3907 - accuracy: 0.4443 - val_loss: 2.3262 - val_accuracy: 0.2500\n",
      "Epoch 976/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3905 - accuracy: 0.4429 - val_loss: 2.3076 - val_accuracy: 0.2500\n",
      "Epoch 977/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3905 - accuracy: 0.4343 - val_loss: 2.3044 - val_accuracy: 0.2400\n",
      "Epoch 978/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3904 - accuracy: 0.4486 - val_loss: 2.3117 - val_accuracy: 0.2533\n",
      "Epoch 979/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3906 - accuracy: 0.4429 - val_loss: 2.3081 - val_accuracy: 0.2467\n",
      "Epoch 980/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3906 - accuracy: 0.4429 - val_loss: 2.3256 - val_accuracy: 0.2500\n",
      "Epoch 981/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3894 - accuracy: 0.4371 - val_loss: 2.3378 - val_accuracy: 0.2500\n",
      "Epoch 982/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3902 - accuracy: 0.4400 - val_loss: 2.3157 - val_accuracy: 0.2533\n",
      "Epoch 983/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3897 - accuracy: 0.4357 - val_loss: 2.3231 - val_accuracy: 0.2500\n",
      "Epoch 984/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3898 - accuracy: 0.4414 - val_loss: 2.3133 - val_accuracy: 0.2500\n",
      "Epoch 985/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3891 - accuracy: 0.4400 - val_loss: 2.3245 - val_accuracy: 0.2367\n",
      "Epoch 986/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3891 - accuracy: 0.4414 - val_loss: 2.3228 - val_accuracy: 0.2500\n",
      "Epoch 987/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3887 - accuracy: 0.4414 - val_loss: 2.3043 - val_accuracy: 0.2400\n",
      "Epoch 988/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3886 - accuracy: 0.4429 - val_loss: 2.3385 - val_accuracy: 0.2633\n",
      "Epoch 989/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3903 - accuracy: 0.4357 - val_loss: 2.3375 - val_accuracy: 0.2533\n",
      "Epoch 990/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3887 - accuracy: 0.4443 - val_loss: 2.3547 - val_accuracy: 0.2533\n",
      "Epoch 991/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3890 - accuracy: 0.4471 - val_loss: 2.3138 - val_accuracy: 0.2433\n",
      "Epoch 992/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3888 - accuracy: 0.4371 - val_loss: 2.3301 - val_accuracy: 0.2400\n",
      "Epoch 993/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3885 - accuracy: 0.4457 - val_loss: 2.3353 - val_accuracy: 0.2533\n",
      "Epoch 994/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3885 - accuracy: 0.4357 - val_loss: 2.3073 - val_accuracy: 0.2367\n",
      "Epoch 995/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3890 - accuracy: 0.4429 - val_loss: 2.3282 - val_accuracy: 0.2500\n",
      "Epoch 996/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3877 - accuracy: 0.4457 - val_loss: 2.3284 - val_accuracy: 0.2467\n",
      "Epoch 997/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3879 - accuracy: 0.4429 - val_loss: 2.3277 - val_accuracy: 0.2533\n",
      "Epoch 998/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3887 - accuracy: 0.4386 - val_loss: 2.3401 - val_accuracy: 0.2533\n",
      "Epoch 999/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3881 - accuracy: 0.4386 - val_loss: 2.3246 - val_accuracy: 0.2500\n",
      "Epoch 1000/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3879 - accuracy: 0.4386 - val_loss: 2.3363 - val_accuracy: 0.2500\n",
      "Epoch 1001/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3864 - accuracy: 0.4457 - val_loss: 2.3322 - val_accuracy: 0.2600\n",
      "Epoch 1002/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3883 - accuracy: 0.4371 - val_loss: 2.3279 - val_accuracy: 0.2500\n",
      "Epoch 1003/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3865 - accuracy: 0.4457 - val_loss: 2.3385 - val_accuracy: 0.2567\n",
      "Epoch 1004/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3885 - accuracy: 0.4414 - val_loss: 2.3496 - val_accuracy: 0.2500\n",
      "Epoch 1005/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3874 - accuracy: 0.4386 - val_loss: 2.3295 - val_accuracy: 0.2467\n",
      "Epoch 1006/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3869 - accuracy: 0.4371 - val_loss: 2.3564 - val_accuracy: 0.2500\n",
      "Epoch 1007/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3865 - accuracy: 0.4414 - val_loss: 2.3466 - val_accuracy: 0.2567\n",
      "Epoch 1008/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3868 - accuracy: 0.4386 - val_loss: 2.3211 - val_accuracy: 0.2500\n",
      "Epoch 1009/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3864 - accuracy: 0.4457 - val_loss: 2.3559 - val_accuracy: 0.2533\n",
      "Epoch 1010/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3865 - accuracy: 0.4486 - val_loss: 2.3248 - val_accuracy: 0.2500\n",
      "Epoch 1011/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3859 - accuracy: 0.4414 - val_loss: 2.3421 - val_accuracy: 0.2533\n",
      "Epoch 1012/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3852 - accuracy: 0.4414 - val_loss: 2.3446 - val_accuracy: 0.2533\n",
      "Epoch 1013/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3852 - accuracy: 0.4457 - val_loss: 2.3257 - val_accuracy: 0.2400\n",
      "Epoch 1014/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3853 - accuracy: 0.4414 - val_loss: 2.3256 - val_accuracy: 0.2567\n",
      "Epoch 1015/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3842 - accuracy: 0.4457 - val_loss: 2.3319 - val_accuracy: 0.2400\n",
      "Epoch 1016/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3867 - accuracy: 0.4414 - val_loss: 2.3376 - val_accuracy: 0.2500\n",
      "Epoch 1017/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3863 - accuracy: 0.4357 - val_loss: 2.3347 - val_accuracy: 0.2500\n",
      "Epoch 1018/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3861 - accuracy: 0.4486 - val_loss: 2.3471 - val_accuracy: 0.2500\n",
      "Epoch 1019/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3851 - accuracy: 0.4386 - val_loss: 2.3314 - val_accuracy: 0.2467\n",
      "Epoch 1020/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3845 - accuracy: 0.4529 - val_loss: 2.3294 - val_accuracy: 0.2500\n",
      "Epoch 1021/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3853 - accuracy: 0.4429 - val_loss: 2.3389 - val_accuracy: 0.2533\n",
      "Epoch 1022/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3842 - accuracy: 0.4514 - val_loss: 2.3396 - val_accuracy: 0.2400\n",
      "Epoch 1023/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3855 - accuracy: 0.4414 - val_loss: 2.3287 - val_accuracy: 0.2467\n",
      "Epoch 1024/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3850 - accuracy: 0.4529 - val_loss: 2.3287 - val_accuracy: 0.2433\n",
      "Epoch 1025/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3844 - accuracy: 0.4443 - val_loss: 2.3350 - val_accuracy: 0.2533\n",
      "Epoch 1026/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3848 - accuracy: 0.4457 - val_loss: 2.3112 - val_accuracy: 0.2433\n",
      "Epoch 1027/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3841 - accuracy: 0.4457 - val_loss: 2.3445 - val_accuracy: 0.2500\n",
      "Epoch 1028/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3842 - accuracy: 0.4386 - val_loss: 2.3323 - val_accuracy: 0.2433\n",
      "Epoch 1029/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3844 - accuracy: 0.4443 - val_loss: 2.3308 - val_accuracy: 0.2467\n",
      "Epoch 1030/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3835 - accuracy: 0.4500 - val_loss: 2.3470 - val_accuracy: 0.2500\n",
      "Epoch 1031/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3834 - accuracy: 0.4443 - val_loss: 2.3523 - val_accuracy: 0.2567\n",
      "Epoch 1032/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3846 - accuracy: 0.4443 - val_loss: 2.3494 - val_accuracy: 0.2433\n",
      "Epoch 1033/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3843 - accuracy: 0.4429 - val_loss: 2.3703 - val_accuracy: 0.2467\n",
      "Epoch 1034/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3822 - accuracy: 0.4443 - val_loss: 2.3406 - val_accuracy: 0.2333\n",
      "Epoch 1035/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3842 - accuracy: 0.4443 - val_loss: 2.3459 - val_accuracy: 0.2533\n",
      "Epoch 1036/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3837 - accuracy: 0.4486 - val_loss: 2.3452 - val_accuracy: 0.2500\n",
      "Epoch 1037/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3830 - accuracy: 0.4429 - val_loss: 2.3415 - val_accuracy: 0.2400\n",
      "Epoch 1038/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3838 - accuracy: 0.4443 - val_loss: 2.3751 - val_accuracy: 0.2567\n",
      "Epoch 1039/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3835 - accuracy: 0.4443 - val_loss: 2.3524 - val_accuracy: 0.2467\n",
      "Epoch 1040/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3832 - accuracy: 0.4414 - val_loss: 2.3506 - val_accuracy: 0.2467\n",
      "Epoch 1041/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3825 - accuracy: 0.4414 - val_loss: 2.3684 - val_accuracy: 0.2500\n",
      "Epoch 1042/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3814 - accuracy: 0.4400 - val_loss: 2.3343 - val_accuracy: 0.2467\n",
      "Epoch 1043/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3835 - accuracy: 0.4400 - val_loss: 2.3604 - val_accuracy: 0.2533\n",
      "Epoch 1044/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3825 - accuracy: 0.4429 - val_loss: 2.3520 - val_accuracy: 0.2467\n",
      "Epoch 1045/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3802 - accuracy: 0.4386 - val_loss: 2.3440 - val_accuracy: 0.2333\n",
      "Epoch 1046/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3831 - accuracy: 0.4514 - val_loss: 2.3538 - val_accuracy: 0.2433\n",
      "Epoch 1047/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3808 - accuracy: 0.4457 - val_loss: 2.3428 - val_accuracy: 0.2367\n",
      "Epoch 1048/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3824 - accuracy: 0.4400 - val_loss: 2.3375 - val_accuracy: 0.2433\n",
      "Epoch 1049/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3818 - accuracy: 0.4414 - val_loss: 2.3480 - val_accuracy: 0.2500\n",
      "Epoch 1050/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3808 - accuracy: 0.4471 - val_loss: 2.3605 - val_accuracy: 0.2433\n",
      "Epoch 1051/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3821 - accuracy: 0.4471 - val_loss: 2.3487 - val_accuracy: 0.2467\n",
      "Epoch 1052/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3810 - accuracy: 0.4357 - val_loss: 2.3688 - val_accuracy: 0.2433\n",
      "Epoch 1053/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3814 - accuracy: 0.4443 - val_loss: 2.3598 - val_accuracy: 0.2467\n",
      "Epoch 1054/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3808 - accuracy: 0.4486 - val_loss: 2.3476 - val_accuracy: 0.2500\n",
      "Epoch 1055/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3807 - accuracy: 0.4471 - val_loss: 2.3445 - val_accuracy: 0.2500\n",
      "Epoch 1056/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3805 - accuracy: 0.4400 - val_loss: 2.3697 - val_accuracy: 0.2500\n",
      "Epoch 1057/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3799 - accuracy: 0.4343 - val_loss: 2.3867 - val_accuracy: 0.2433\n",
      "Epoch 1058/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 94us/step - loss: 1.3813 - accuracy: 0.4414 - val_loss: 2.3657 - val_accuracy: 0.2533\n",
      "Epoch 1059/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3797 - accuracy: 0.4486 - val_loss: 2.3663 - val_accuracy: 0.2500\n",
      "Epoch 1060/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3802 - accuracy: 0.4443 - val_loss: 2.3557 - val_accuracy: 0.2500\n",
      "Epoch 1061/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3807 - accuracy: 0.4457 - val_loss: 2.3787 - val_accuracy: 0.2533\n",
      "Epoch 1062/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3811 - accuracy: 0.4386 - val_loss: 2.3482 - val_accuracy: 0.2500\n",
      "Epoch 1063/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3797 - accuracy: 0.4429 - val_loss: 2.3524 - val_accuracy: 0.2533\n",
      "Epoch 1064/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3799 - accuracy: 0.4429 - val_loss: 2.3675 - val_accuracy: 0.2500\n",
      "Epoch 1065/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3800 - accuracy: 0.4400 - val_loss: 2.3518 - val_accuracy: 0.2467\n",
      "Epoch 1066/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3800 - accuracy: 0.4429 - val_loss: 2.3537 - val_accuracy: 0.2400\n",
      "Epoch 1067/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3799 - accuracy: 0.4514 - val_loss: 2.3866 - val_accuracy: 0.2567\n",
      "Epoch 1068/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3793 - accuracy: 0.4443 - val_loss: 2.3872 - val_accuracy: 0.2500\n",
      "Epoch 1069/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3795 - accuracy: 0.4414 - val_loss: 2.3765 - val_accuracy: 0.2500\n",
      "Epoch 1070/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3789 - accuracy: 0.4471 - val_loss: 2.3595 - val_accuracy: 0.2367\n",
      "Epoch 1071/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3783 - accuracy: 0.4457 - val_loss: 2.3945 - val_accuracy: 0.2267\n",
      "Epoch 1072/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3789 - accuracy: 0.4514 - val_loss: 2.3712 - val_accuracy: 0.2533\n",
      "Epoch 1073/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3784 - accuracy: 0.4443 - val_loss: 2.3571 - val_accuracy: 0.2500\n",
      "Epoch 1074/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3788 - accuracy: 0.4514 - val_loss: 2.3474 - val_accuracy: 0.2500\n",
      "Epoch 1075/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3787 - accuracy: 0.4500 - val_loss: 2.3609 - val_accuracy: 0.2367\n",
      "Epoch 1076/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3789 - accuracy: 0.4429 - val_loss: 2.3611 - val_accuracy: 0.2500\n",
      "Epoch 1077/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3785 - accuracy: 0.4457 - val_loss: 2.3490 - val_accuracy: 0.2367\n",
      "Epoch 1078/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3785 - accuracy: 0.4443 - val_loss: 2.3810 - val_accuracy: 0.2400\n",
      "Epoch 1079/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3779 - accuracy: 0.4443 - val_loss: 2.3704 - val_accuracy: 0.2400\n",
      "Epoch 1080/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3780 - accuracy: 0.4414 - val_loss: 2.3673 - val_accuracy: 0.2533\n",
      "Epoch 1081/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3782 - accuracy: 0.4471 - val_loss: 2.3719 - val_accuracy: 0.2400\n",
      "Epoch 1082/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3770 - accuracy: 0.4471 - val_loss: 2.3847 - val_accuracy: 0.2533\n",
      "Epoch 1083/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3782 - accuracy: 0.4429 - val_loss: 2.3637 - val_accuracy: 0.2333\n",
      "Epoch 1084/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3784 - accuracy: 0.4471 - val_loss: 2.3890 - val_accuracy: 0.2433\n",
      "Epoch 1085/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3771 - accuracy: 0.4414 - val_loss: 2.3778 - val_accuracy: 0.2533\n",
      "Epoch 1086/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3776 - accuracy: 0.4471 - val_loss: 2.3988 - val_accuracy: 0.2400\n",
      "Epoch 1087/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3771 - accuracy: 0.4486 - val_loss: 2.3753 - val_accuracy: 0.2333\n",
      "Epoch 1088/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3769 - accuracy: 0.4543 - val_loss: 2.3642 - val_accuracy: 0.2500\n",
      "Epoch 1089/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3781 - accuracy: 0.4457 - val_loss: 2.3738 - val_accuracy: 0.2500\n",
      "Epoch 1090/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3766 - accuracy: 0.4471 - val_loss: 2.3861 - val_accuracy: 0.2533\n",
      "Epoch 1091/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3766 - accuracy: 0.4486 - val_loss: 2.3700 - val_accuracy: 0.2400\n",
      "Epoch 1092/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3765 - accuracy: 0.4514 - val_loss: 2.3865 - val_accuracy: 0.2500\n",
      "Epoch 1093/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3769 - accuracy: 0.4457 - val_loss: 2.3861 - val_accuracy: 0.2467\n",
      "Epoch 1094/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3753 - accuracy: 0.4571 - val_loss: 2.3644 - val_accuracy: 0.2433\n",
      "Epoch 1095/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3779 - accuracy: 0.4429 - val_loss: 2.3857 - val_accuracy: 0.2533\n",
      "Epoch 1096/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3761 - accuracy: 0.4429 - val_loss: 2.3808 - val_accuracy: 0.2367\n",
      "Epoch 1097/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3762 - accuracy: 0.4557 - val_loss: 2.3937 - val_accuracy: 0.2533\n",
      "Epoch 1098/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3767 - accuracy: 0.4457 - val_loss: 2.4162 - val_accuracy: 0.2500\n",
      "Epoch 1099/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3767 - accuracy: 0.4471 - val_loss: 2.4176 - val_accuracy: 0.2467\n",
      "Epoch 1100/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3761 - accuracy: 0.4500 - val_loss: 2.3906 - val_accuracy: 0.2467\n",
      "Epoch 1101/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3756 - accuracy: 0.4471 - val_loss: 2.3871 - val_accuracy: 0.2500\n",
      "Epoch 1102/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3750 - accuracy: 0.4400 - val_loss: 2.3934 - val_accuracy: 0.2367\n",
      "Epoch 1103/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3754 - accuracy: 0.4414 - val_loss: 2.4011 - val_accuracy: 0.2533\n",
      "Epoch 1104/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3758 - accuracy: 0.4414 - val_loss: 2.3780 - val_accuracy: 0.2533\n",
      "Epoch 1105/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3752 - accuracy: 0.4500 - val_loss: 2.3785 - val_accuracy: 0.2533\n",
      "Epoch 1106/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3748 - accuracy: 0.4500 - val_loss: 2.4023 - val_accuracy: 0.2533\n",
      "Epoch 1107/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3758 - accuracy: 0.4471 - val_loss: 2.3591 - val_accuracy: 0.2500\n",
      "Epoch 1108/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3755 - accuracy: 0.4471 - val_loss: 2.3990 - val_accuracy: 0.2467\n",
      "Epoch 1109/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3755 - accuracy: 0.4500 - val_loss: 2.4115 - val_accuracy: 0.2500\n",
      "Epoch 1110/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3746 - accuracy: 0.4414 - val_loss: 2.3729 - val_accuracy: 0.2433\n",
      "Epoch 1111/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3742 - accuracy: 0.4543 - val_loss: 2.3964 - val_accuracy: 0.2500\n",
      "Epoch 1112/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3742 - accuracy: 0.4457 - val_loss: 2.4009 - val_accuracy: 0.2400\n",
      "Epoch 1113/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3738 - accuracy: 0.4486 - val_loss: 2.4031 - val_accuracy: 0.2533\n",
      "Epoch 1114/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3746 - accuracy: 0.4486 - val_loss: 2.3946 - val_accuracy: 0.2533\n",
      "Epoch 1115/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3756 - accuracy: 0.4457 - val_loss: 2.3857 - val_accuracy: 0.2533\n",
      "Epoch 1116/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3737 - accuracy: 0.4500 - val_loss: 2.4026 - val_accuracy: 0.2500\n",
      "Epoch 1117/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3737 - accuracy: 0.4529 - val_loss: 2.3940 - val_accuracy: 0.2467\n",
      "Epoch 1118/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3739 - accuracy: 0.4557 - val_loss: 2.3943 - val_accuracy: 0.2467\n",
      "Epoch 1119/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3732 - accuracy: 0.4386 - val_loss: 2.3894 - val_accuracy: 0.2333\n",
      "Epoch 1120/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3733 - accuracy: 0.4543 - val_loss: 2.4235 - val_accuracy: 0.2500\n",
      "Epoch 1121/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3744 - accuracy: 0.4471 - val_loss: 2.3780 - val_accuracy: 0.2433\n",
      "Epoch 1122/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3736 - accuracy: 0.4486 - val_loss: 2.4027 - val_accuracy: 0.2533\n",
      "Epoch 1123/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3730 - accuracy: 0.4514 - val_loss: 2.4025 - val_accuracy: 0.2467\n",
      "Epoch 1124/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3739 - accuracy: 0.4500 - val_loss: 2.3965 - val_accuracy: 0.2400\n",
      "Epoch 1125/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3735 - accuracy: 0.4471 - val_loss: 2.3919 - val_accuracy: 0.2533\n",
      "Epoch 1126/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3722 - accuracy: 0.4529 - val_loss: 2.3982 - val_accuracy: 0.2533\n",
      "Epoch 1127/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3730 - accuracy: 0.4586 - val_loss: 2.4060 - val_accuracy: 0.2533\n",
      "Epoch 1128/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3737 - accuracy: 0.4457 - val_loss: 2.4372 - val_accuracy: 0.2500\n",
      "Epoch 1129/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3720 - accuracy: 0.4457 - val_loss: 2.4131 - val_accuracy: 0.2333\n",
      "Epoch 1130/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3727 - accuracy: 0.4429 - val_loss: 2.4031 - val_accuracy: 0.2433\n",
      "Epoch 1131/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3709 - accuracy: 0.4457 - val_loss: 2.4240 - val_accuracy: 0.2533\n",
      "Epoch 1132/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3738 - accuracy: 0.4514 - val_loss: 2.4069 - val_accuracy: 0.2467\n",
      "Epoch 1133/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3715 - accuracy: 0.4514 - val_loss: 2.4214 - val_accuracy: 0.2467\n",
      "Epoch 1134/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3717 - accuracy: 0.4457 - val_loss: 2.4085 - val_accuracy: 0.2333\n",
      "Epoch 1135/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3726 - accuracy: 0.4514 - val_loss: 2.4087 - val_accuracy: 0.2467\n",
      "Epoch 1136/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3718 - accuracy: 0.4514 - val_loss: 2.3966 - val_accuracy: 0.2467\n",
      "Epoch 1137/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3726 - accuracy: 0.4500 - val_loss: 2.4056 - val_accuracy: 0.2467\n",
      "Epoch 1138/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3716 - accuracy: 0.4471 - val_loss: 2.4076 - val_accuracy: 0.2433\n",
      "Epoch 1139/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3717 - accuracy: 0.4557 - val_loss: 2.3976 - val_accuracy: 0.2467\n",
      "Epoch 1140/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3701 - accuracy: 0.4557 - val_loss: 2.3885 - val_accuracy: 0.2300\n",
      "Epoch 1141/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3715 - accuracy: 0.4500 - val_loss: 2.4364 - val_accuracy: 0.2500\n",
      "Epoch 1142/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3718 - accuracy: 0.4557 - val_loss: 2.4286 - val_accuracy: 0.2500\n",
      "Epoch 1143/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3707 - accuracy: 0.4457 - val_loss: 2.4246 - val_accuracy: 0.2433\n",
      "Epoch 1144/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3686 - accuracy: 0.4443 - val_loss: 2.4378 - val_accuracy: 0.2367\n",
      "Epoch 1145/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3718 - accuracy: 0.4529 - val_loss: 2.4172 - val_accuracy: 0.2467\n",
      "Epoch 1146/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3705 - accuracy: 0.4514 - val_loss: 2.4258 - val_accuracy: 0.2333\n",
      "Epoch 1147/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3702 - accuracy: 0.4529 - val_loss: 2.4031 - val_accuracy: 0.2333\n",
      "Epoch 1148/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3715 - accuracy: 0.4543 - val_loss: 2.4235 - val_accuracy: 0.2467\n",
      "Epoch 1149/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3712 - accuracy: 0.4457 - val_loss: 2.4239 - val_accuracy: 0.2367\n",
      "Epoch 1150/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3713 - accuracy: 0.4486 - val_loss: 2.3925 - val_accuracy: 0.2400\n",
      "Epoch 1151/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3712 - accuracy: 0.4514 - val_loss: 2.4041 - val_accuracy: 0.2433\n",
      "Epoch 1152/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3697 - accuracy: 0.4529 - val_loss: 2.4164 - val_accuracy: 0.2533\n",
      "Epoch 1153/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3711 - accuracy: 0.4471 - val_loss: 2.4291 - val_accuracy: 0.2467\n",
      "Epoch 1154/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3699 - accuracy: 0.4543 - val_loss: 2.3820 - val_accuracy: 0.2367\n",
      "Epoch 1155/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3697 - accuracy: 0.4514 - val_loss: 2.4190 - val_accuracy: 0.2433\n",
      "Epoch 1156/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3706 - accuracy: 0.4457 - val_loss: 2.4048 - val_accuracy: 0.2300\n",
      "Epoch 1157/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3707 - accuracy: 0.4529 - val_loss: 2.4173 - val_accuracy: 0.2433\n",
      "Epoch 1158/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3696 - accuracy: 0.4543 - val_loss: 2.4481 - val_accuracy: 0.2533\n",
      "Epoch 1159/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3697 - accuracy: 0.4457 - val_loss: 2.4223 - val_accuracy: 0.2433\n",
      "Epoch 1160/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3708 - accuracy: 0.4543 - val_loss: 2.4358 - val_accuracy: 0.2333\n",
      "Epoch 1161/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3693 - accuracy: 0.4571 - val_loss: 2.4256 - val_accuracy: 0.2467\n",
      "Epoch 1162/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3693 - accuracy: 0.4571 - val_loss: 2.4286 - val_accuracy: 0.2467\n",
      "Epoch 1163/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3691 - accuracy: 0.4543 - val_loss: 2.4364 - val_accuracy: 0.2467\n",
      "Epoch 1164/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3688 - accuracy: 0.4586 - val_loss: 2.4378 - val_accuracy: 0.2333\n",
      "Epoch 1165/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3701 - accuracy: 0.4571 - val_loss: 2.3936 - val_accuracy: 0.2367\n",
      "Epoch 1166/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3689 - accuracy: 0.4543 - val_loss: 2.4123 - val_accuracy: 0.2433\n",
      "Epoch 1167/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3689 - accuracy: 0.4557 - val_loss: 2.4247 - val_accuracy: 0.2433\n",
      "Epoch 1168/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 94us/step - loss: 1.3688 - accuracy: 0.4529 - val_loss: 2.4140 - val_accuracy: 0.2333\n",
      "Epoch 1169/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3682 - accuracy: 0.4529 - val_loss: 2.4288 - val_accuracy: 0.2467\n",
      "Epoch 1170/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3682 - accuracy: 0.4514 - val_loss: 2.4249 - val_accuracy: 0.2467\n",
      "Epoch 1171/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3676 - accuracy: 0.4514 - val_loss: 2.4115 - val_accuracy: 0.2433\n",
      "Epoch 1172/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3681 - accuracy: 0.4529 - val_loss: 2.4387 - val_accuracy: 0.2433\n",
      "Epoch 1173/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3678 - accuracy: 0.4514 - val_loss: 2.4268 - val_accuracy: 0.2300\n",
      "Epoch 1174/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3688 - accuracy: 0.4471 - val_loss: 2.4151 - val_accuracy: 0.2433\n",
      "Epoch 1175/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3671 - accuracy: 0.4514 - val_loss: 2.4241 - val_accuracy: 0.2433\n",
      "Epoch 1176/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3680 - accuracy: 0.4500 - val_loss: 2.4368 - val_accuracy: 0.2433\n",
      "Epoch 1177/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3681 - accuracy: 0.4514 - val_loss: 2.4471 - val_accuracy: 0.2467\n",
      "Epoch 1178/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3675 - accuracy: 0.4500 - val_loss: 2.4336 - val_accuracy: 0.2267\n",
      "Epoch 1179/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3677 - accuracy: 0.4543 - val_loss: 2.4346 - val_accuracy: 0.2300\n",
      "Epoch 1180/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3678 - accuracy: 0.4514 - val_loss: 2.4402 - val_accuracy: 0.2400\n",
      "Epoch 1181/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3672 - accuracy: 0.4571 - val_loss: 2.4477 - val_accuracy: 0.2500\n",
      "Epoch 1182/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3679 - accuracy: 0.4557 - val_loss: 2.4301 - val_accuracy: 0.2400\n",
      "Epoch 1183/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3673 - accuracy: 0.4500 - val_loss: 2.4334 - val_accuracy: 0.2433\n",
      "Epoch 1184/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3663 - accuracy: 0.4586 - val_loss: 2.4227 - val_accuracy: 0.2467\n",
      "Epoch 1185/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3675 - accuracy: 0.4557 - val_loss: 2.4282 - val_accuracy: 0.2400\n",
      "Epoch 1186/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3671 - accuracy: 0.4471 - val_loss: 2.4531 - val_accuracy: 0.2467\n",
      "Epoch 1187/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3664 - accuracy: 0.4529 - val_loss: 2.4296 - val_accuracy: 0.2333\n",
      "Epoch 1188/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3665 - accuracy: 0.4543 - val_loss: 2.4561 - val_accuracy: 0.2467\n",
      "Epoch 1189/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3656 - accuracy: 0.4600 - val_loss: 2.4385 - val_accuracy: 0.2467\n",
      "Epoch 1190/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3665 - accuracy: 0.4500 - val_loss: 2.4635 - val_accuracy: 0.2500\n",
      "Epoch 1191/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3668 - accuracy: 0.4486 - val_loss: 2.4467 - val_accuracy: 0.2333\n",
      "Epoch 1192/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3664 - accuracy: 0.4600 - val_loss: 2.4209 - val_accuracy: 0.2433\n",
      "Epoch 1193/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3669 - accuracy: 0.4557 - val_loss: 2.4436 - val_accuracy: 0.2400\n",
      "Epoch 1194/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3660 - accuracy: 0.4500 - val_loss: 2.4313 - val_accuracy: 0.2300\n",
      "Epoch 1195/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3666 - accuracy: 0.4543 - val_loss: 2.4317 - val_accuracy: 0.2267\n",
      "Epoch 1196/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3657 - accuracy: 0.4614 - val_loss: 2.4489 - val_accuracy: 0.2500\n",
      "Epoch 1197/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3658 - accuracy: 0.4557 - val_loss: 2.4299 - val_accuracy: 0.2433\n",
      "Epoch 1198/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3653 - accuracy: 0.4529 - val_loss: 2.4437 - val_accuracy: 0.2467\n",
      "Epoch 1199/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3656 - accuracy: 0.4543 - val_loss: 2.4290 - val_accuracy: 0.2300\n",
      "Epoch 1200/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3662 - accuracy: 0.4500 - val_loss: 2.4460 - val_accuracy: 0.2400\n",
      "Epoch 1201/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3651 - accuracy: 0.4600 - val_loss: 2.4490 - val_accuracy: 0.2433\n",
      "Epoch 1202/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3660 - accuracy: 0.4529 - val_loss: 2.4605 - val_accuracy: 0.2467\n",
      "Epoch 1203/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3653 - accuracy: 0.4571 - val_loss: 2.4225 - val_accuracy: 0.2467\n",
      "Epoch 1204/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3654 - accuracy: 0.4643 - val_loss: 2.4242 - val_accuracy: 0.2467\n",
      "Epoch 1205/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3639 - accuracy: 0.4571 - val_loss: 2.4371 - val_accuracy: 0.2433\n",
      "Epoch 1206/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3649 - accuracy: 0.4600 - val_loss: 2.4495 - val_accuracy: 0.2433\n",
      "Epoch 1207/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3637 - accuracy: 0.4571 - val_loss: 2.4561 - val_accuracy: 0.2233\n",
      "Epoch 1208/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3636 - accuracy: 0.4514 - val_loss: 2.4504 - val_accuracy: 0.2267\n",
      "Epoch 1209/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3630 - accuracy: 0.4600 - val_loss: 2.4415 - val_accuracy: 0.2433\n",
      "Epoch 1210/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3648 - accuracy: 0.4557 - val_loss: 2.4462 - val_accuracy: 0.2433\n",
      "Epoch 1211/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3645 - accuracy: 0.4586 - val_loss: 2.4559 - val_accuracy: 0.2433\n",
      "Epoch 1212/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3631 - accuracy: 0.4471 - val_loss: 2.4737 - val_accuracy: 0.2500\n",
      "Epoch 1213/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3655 - accuracy: 0.4557 - val_loss: 2.4452 - val_accuracy: 0.2433\n",
      "Epoch 1214/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3634 - accuracy: 0.4557 - val_loss: 2.4679 - val_accuracy: 0.2467\n",
      "Epoch 1215/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3633 - accuracy: 0.4529 - val_loss: 2.4549 - val_accuracy: 0.2467\n",
      "Epoch 1216/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3637 - accuracy: 0.4571 - val_loss: 2.4434 - val_accuracy: 0.2433\n",
      "Epoch 1217/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3636 - accuracy: 0.4514 - val_loss: 2.4625 - val_accuracy: 0.2433\n",
      "Epoch 1218/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3634 - accuracy: 0.4586 - val_loss: 2.4542 - val_accuracy: 0.2433\n",
      "Epoch 1219/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3632 - accuracy: 0.4529 - val_loss: 2.4596 - val_accuracy: 0.2467\n",
      "Epoch 1220/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3642 - accuracy: 0.4529 - val_loss: 2.4367 - val_accuracy: 0.2433\n",
      "Epoch 1221/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3633 - accuracy: 0.4614 - val_loss: 2.4614 - val_accuracy: 0.2300\n",
      "Epoch 1222/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3633 - accuracy: 0.4586 - val_loss: 2.4712 - val_accuracy: 0.2433\n",
      "Epoch 1223/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3632 - accuracy: 0.4586 - val_loss: 2.4696 - val_accuracy: 0.2467\n",
      "Epoch 1224/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3625 - accuracy: 0.4571 - val_loss: 2.4725 - val_accuracy: 0.2467\n",
      "Epoch 1225/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3621 - accuracy: 0.4529 - val_loss: 2.4651 - val_accuracy: 0.2300\n",
      "Epoch 1226/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3636 - accuracy: 0.4629 - val_loss: 2.4592 - val_accuracy: 0.2433\n",
      "Epoch 1227/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3609 - accuracy: 0.4543 - val_loss: 2.4483 - val_accuracy: 0.2433\n",
      "Epoch 1228/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3626 - accuracy: 0.4614 - val_loss: 2.4718 - val_accuracy: 0.2433\n",
      "Epoch 1229/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3630 - accuracy: 0.4543 - val_loss: 2.4582 - val_accuracy: 0.2433\n",
      "Epoch 1230/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3624 - accuracy: 0.4600 - val_loss: 2.4488 - val_accuracy: 0.2467\n",
      "Epoch 1231/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3629 - accuracy: 0.4571 - val_loss: 2.4342 - val_accuracy: 0.2333\n",
      "Epoch 1232/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3626 - accuracy: 0.4543 - val_loss: 2.4819 - val_accuracy: 0.2500\n",
      "Epoch 1233/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3632 - accuracy: 0.4586 - val_loss: 2.4497 - val_accuracy: 0.2433\n",
      "Epoch 1234/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3616 - accuracy: 0.4686 - val_loss: 2.4396 - val_accuracy: 0.2467\n",
      "Epoch 1235/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3618 - accuracy: 0.4571 - val_loss: 2.4482 - val_accuracy: 0.2400\n",
      "Epoch 1236/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3620 - accuracy: 0.4543 - val_loss: 2.4448 - val_accuracy: 0.2367\n",
      "Epoch 1237/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3622 - accuracy: 0.4486 - val_loss: 2.4273 - val_accuracy: 0.2500\n",
      "Epoch 1238/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3610 - accuracy: 0.4586 - val_loss: 2.4741 - val_accuracy: 0.2467\n",
      "Epoch 1239/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3620 - accuracy: 0.4514 - val_loss: 2.4538 - val_accuracy: 0.2400\n",
      "Epoch 1240/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3614 - accuracy: 0.4557 - val_loss: 2.4519 - val_accuracy: 0.2433\n",
      "Epoch 1241/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3614 - accuracy: 0.4557 - val_loss: 2.4660 - val_accuracy: 0.2400\n",
      "Epoch 1242/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3609 - accuracy: 0.4514 - val_loss: 2.4591 - val_accuracy: 0.2433\n",
      "Epoch 1243/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3612 - accuracy: 0.4614 - val_loss: 2.4818 - val_accuracy: 0.2467\n",
      "Epoch 1244/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3611 - accuracy: 0.4529 - val_loss: 2.4443 - val_accuracy: 0.2467\n",
      "Epoch 1245/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3607 - accuracy: 0.4614 - val_loss: 2.4528 - val_accuracy: 0.2433\n",
      "Epoch 1246/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3603 - accuracy: 0.4600 - val_loss: 2.4831 - val_accuracy: 0.2433\n",
      "Epoch 1247/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3601 - accuracy: 0.4614 - val_loss: 2.4707 - val_accuracy: 0.2433\n",
      "Epoch 1248/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3607 - accuracy: 0.4557 - val_loss: 2.4791 - val_accuracy: 0.2400\n",
      "Epoch 1249/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3611 - accuracy: 0.4557 - val_loss: 2.4662 - val_accuracy: 0.2400\n",
      "Epoch 1250/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3596 - accuracy: 0.4571 - val_loss: 2.5088 - val_accuracy: 0.2300\n",
      "Epoch 1251/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3608 - accuracy: 0.4586 - val_loss: 2.4743 - val_accuracy: 0.2400\n",
      "Epoch 1252/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3597 - accuracy: 0.4643 - val_loss: 2.4841 - val_accuracy: 0.2433\n",
      "Epoch 1253/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3609 - accuracy: 0.4500 - val_loss: 2.4688 - val_accuracy: 0.2400\n",
      "Epoch 1254/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3600 - accuracy: 0.4614 - val_loss: 2.4605 - val_accuracy: 0.2433\n",
      "Epoch 1255/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3602 - accuracy: 0.4571 - val_loss: 2.4620 - val_accuracy: 0.2433\n",
      "Epoch 1256/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3592 - accuracy: 0.4586 - val_loss: 2.4859 - val_accuracy: 0.2333\n",
      "Epoch 1257/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3599 - accuracy: 0.4586 - val_loss: 2.4925 - val_accuracy: 0.2467\n",
      "Epoch 1258/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3600 - accuracy: 0.4686 - val_loss: 2.4568 - val_accuracy: 0.2433\n",
      "Epoch 1259/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3597 - accuracy: 0.4600 - val_loss: 2.4545 - val_accuracy: 0.2433\n",
      "Epoch 1260/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3592 - accuracy: 0.4600 - val_loss: 2.4853 - val_accuracy: 0.2467\n",
      "Epoch 1261/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3599 - accuracy: 0.4586 - val_loss: 2.4733 - val_accuracy: 0.2400\n",
      "Epoch 1262/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3597 - accuracy: 0.4571 - val_loss: 2.4772 - val_accuracy: 0.2400\n",
      "Epoch 1263/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3590 - accuracy: 0.4700 - val_loss: 2.4737 - val_accuracy: 0.2400\n",
      "Epoch 1264/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3593 - accuracy: 0.4586 - val_loss: 2.4638 - val_accuracy: 0.2333\n",
      "Epoch 1265/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3593 - accuracy: 0.4614 - val_loss: 2.4736 - val_accuracy: 0.2367\n",
      "Epoch 1266/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3591 - accuracy: 0.4571 - val_loss: 2.4519 - val_accuracy: 0.2467\n",
      "Epoch 1267/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3586 - accuracy: 0.4571 - val_loss: 2.4640 - val_accuracy: 0.2400\n",
      "Epoch 1268/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3596 - accuracy: 0.4629 - val_loss: 2.4807 - val_accuracy: 0.2433\n",
      "Epoch 1269/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3588 - accuracy: 0.4643 - val_loss: 2.4991 - val_accuracy: 0.2500\n",
      "Epoch 1270/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3584 - accuracy: 0.4614 - val_loss: 2.4851 - val_accuracy: 0.2433\n",
      "Epoch 1271/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3589 - accuracy: 0.4557 - val_loss: 2.4717 - val_accuracy: 0.2400\n",
      "Epoch 1272/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3581 - accuracy: 0.4629 - val_loss: 2.4797 - val_accuracy: 0.2433\n",
      "Epoch 1273/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3584 - accuracy: 0.4571 - val_loss: 2.4822 - val_accuracy: 0.2433\n",
      "Epoch 1274/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3586 - accuracy: 0.4614 - val_loss: 2.4796 - val_accuracy: 0.2433\n",
      "Epoch 1275/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3575 - accuracy: 0.4629 - val_loss: 2.4867 - val_accuracy: 0.2433\n",
      "Epoch 1276/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3587 - accuracy: 0.4600 - val_loss: 2.4842 - val_accuracy: 0.2433\n",
      "Epoch 1277/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3580 - accuracy: 0.4600 - val_loss: 2.4837 - val_accuracy: 0.2467\n",
      "Epoch 1278/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 90us/step - loss: 1.3575 - accuracy: 0.4614 - val_loss: 2.5011 - val_accuracy: 0.2467\n",
      "Epoch 1279/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3575 - accuracy: 0.4557 - val_loss: 2.4813 - val_accuracy: 0.2400\n",
      "Epoch 1280/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3577 - accuracy: 0.4614 - val_loss: 2.4975 - val_accuracy: 0.2433\n",
      "Epoch 1281/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3572 - accuracy: 0.4514 - val_loss: 2.4804 - val_accuracy: 0.2433\n",
      "Epoch 1282/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3576 - accuracy: 0.4586 - val_loss: 2.4914 - val_accuracy: 0.2433\n",
      "Epoch 1283/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3573 - accuracy: 0.4671 - val_loss: 2.5163 - val_accuracy: 0.2467\n",
      "Epoch 1284/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3573 - accuracy: 0.4629 - val_loss: 2.5124 - val_accuracy: 0.2533\n",
      "Epoch 1285/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3548 - accuracy: 0.4571 - val_loss: 2.4656 - val_accuracy: 0.2333\n",
      "Epoch 1286/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3547 - accuracy: 0.4643 - val_loss: 2.5010 - val_accuracy: 0.2500\n",
      "Epoch 1287/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3574 - accuracy: 0.4629 - val_loss: 2.5161 - val_accuracy: 0.2500\n",
      "Epoch 1288/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3565 - accuracy: 0.4571 - val_loss: 2.4953 - val_accuracy: 0.2467\n",
      "Epoch 1289/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3569 - accuracy: 0.4671 - val_loss: 2.4891 - val_accuracy: 0.2467\n",
      "Epoch 1290/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3569 - accuracy: 0.4629 - val_loss: 2.4831 - val_accuracy: 0.2400\n",
      "Epoch 1291/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3571 - accuracy: 0.4629 - val_loss: 2.5058 - val_accuracy: 0.2400\n",
      "Epoch 1292/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3563 - accuracy: 0.4600 - val_loss: 2.5124 - val_accuracy: 0.2533\n",
      "Epoch 1293/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3565 - accuracy: 0.4614 - val_loss: 2.4972 - val_accuracy: 0.2400\n",
      "Epoch 1294/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3566 - accuracy: 0.4643 - val_loss: 2.5009 - val_accuracy: 0.2367\n",
      "Epoch 1295/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3556 - accuracy: 0.4671 - val_loss: 2.4956 - val_accuracy: 0.2433\n",
      "Epoch 1296/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3567 - accuracy: 0.4671 - val_loss: 2.4943 - val_accuracy: 0.2400\n",
      "Epoch 1297/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3561 - accuracy: 0.4700 - val_loss: 2.4860 - val_accuracy: 0.2433\n",
      "Epoch 1298/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3563 - accuracy: 0.4643 - val_loss: 2.4872 - val_accuracy: 0.2400\n",
      "Epoch 1299/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3549 - accuracy: 0.4657 - val_loss: 2.5103 - val_accuracy: 0.2400\n",
      "Epoch 1300/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3547 - accuracy: 0.4671 - val_loss: 2.4812 - val_accuracy: 0.2333\n",
      "Epoch 1301/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3544 - accuracy: 0.4529 - val_loss: 2.4786 - val_accuracy: 0.2400\n",
      "Epoch 1302/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3560 - accuracy: 0.4614 - val_loss: 2.5031 - val_accuracy: 0.2467\n",
      "Epoch 1303/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3560 - accuracy: 0.4643 - val_loss: 2.5031 - val_accuracy: 0.2400\n",
      "Epoch 1304/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3556 - accuracy: 0.4729 - val_loss: 2.5089 - val_accuracy: 0.2433\n",
      "Epoch 1305/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3548 - accuracy: 0.4643 - val_loss: 2.5116 - val_accuracy: 0.2500\n",
      "Epoch 1306/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3550 - accuracy: 0.4586 - val_loss: 2.4953 - val_accuracy: 0.2467\n",
      "Epoch 1307/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3555 - accuracy: 0.4643 - val_loss: 2.4956 - val_accuracy: 0.2433\n",
      "Epoch 1308/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3541 - accuracy: 0.4600 - val_loss: 2.4838 - val_accuracy: 0.2400\n",
      "Epoch 1309/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3540 - accuracy: 0.4643 - val_loss: 2.5008 - val_accuracy: 0.2300\n",
      "Epoch 1310/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3551 - accuracy: 0.4643 - val_loss: 2.5070 - val_accuracy: 0.2467\n",
      "Epoch 1311/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3555 - accuracy: 0.4671 - val_loss: 2.5050 - val_accuracy: 0.2433\n",
      "Epoch 1312/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3545 - accuracy: 0.4614 - val_loss: 2.5020 - val_accuracy: 0.2467\n",
      "Epoch 1313/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3544 - accuracy: 0.4614 - val_loss: 2.4838 - val_accuracy: 0.2400\n",
      "Epoch 1314/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3540 - accuracy: 0.4571 - val_loss: 2.5158 - val_accuracy: 0.2367\n",
      "Epoch 1315/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3536 - accuracy: 0.4657 - val_loss: 2.4860 - val_accuracy: 0.2467\n",
      "Epoch 1316/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3545 - accuracy: 0.4643 - val_loss: 2.5217 - val_accuracy: 0.2500\n",
      "Epoch 1317/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3538 - accuracy: 0.4586 - val_loss: 2.4960 - val_accuracy: 0.2300\n",
      "Epoch 1318/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3545 - accuracy: 0.4657 - val_loss: 2.4824 - val_accuracy: 0.2433\n",
      "Epoch 1319/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3545 - accuracy: 0.4700 - val_loss: 2.5131 - val_accuracy: 0.2533\n",
      "Epoch 1320/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3541 - accuracy: 0.4600 - val_loss: 2.4959 - val_accuracy: 0.2433\n",
      "Epoch 1321/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3534 - accuracy: 0.4657 - val_loss: 2.5010 - val_accuracy: 0.2500\n",
      "Epoch 1322/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3536 - accuracy: 0.4629 - val_loss: 2.4931 - val_accuracy: 0.2400\n",
      "Epoch 1323/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3532 - accuracy: 0.4643 - val_loss: 2.5518 - val_accuracy: 0.2467\n",
      "Epoch 1324/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3539 - accuracy: 0.4629 - val_loss: 2.5080 - val_accuracy: 0.2400\n",
      "Epoch 1325/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3525 - accuracy: 0.4629 - val_loss: 2.5249 - val_accuracy: 0.2367\n",
      "Epoch 1326/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3539 - accuracy: 0.4657 - val_loss: 2.5024 - val_accuracy: 0.2400\n",
      "Epoch 1327/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3532 - accuracy: 0.4671 - val_loss: 2.4968 - val_accuracy: 0.2400\n",
      "Epoch 1328/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3529 - accuracy: 0.4643 - val_loss: 2.5416 - val_accuracy: 0.2500\n",
      "Epoch 1329/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3532 - accuracy: 0.4657 - val_loss: 2.5075 - val_accuracy: 0.2500\n",
      "Epoch 1330/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3533 - accuracy: 0.4600 - val_loss: 2.5370 - val_accuracy: 0.2400\n",
      "Epoch 1331/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3532 - accuracy: 0.4643 - val_loss: 2.5303 - val_accuracy: 0.2533\n",
      "Epoch 1332/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3528 - accuracy: 0.4671 - val_loss: 2.5211 - val_accuracy: 0.2433\n",
      "Epoch 1333/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3525 - accuracy: 0.4643 - val_loss: 2.4991 - val_accuracy: 0.2400\n",
      "Epoch 1334/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3520 - accuracy: 0.4657 - val_loss: 2.5432 - val_accuracy: 0.2500\n",
      "Epoch 1335/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3530 - accuracy: 0.4586 - val_loss: 2.4993 - val_accuracy: 0.2400\n",
      "Epoch 1336/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3532 - accuracy: 0.4714 - val_loss: 2.5237 - val_accuracy: 0.2433\n",
      "Epoch 1337/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3524 - accuracy: 0.4629 - val_loss: 2.5068 - val_accuracy: 0.2433\n",
      "Epoch 1338/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3520 - accuracy: 0.4586 - val_loss: 2.5152 - val_accuracy: 0.2400\n",
      "Epoch 1339/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3520 - accuracy: 0.4671 - val_loss: 2.5497 - val_accuracy: 0.2467\n",
      "Epoch 1340/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3526 - accuracy: 0.4643 - val_loss: 2.5148 - val_accuracy: 0.2467\n",
      "Epoch 1341/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3521 - accuracy: 0.4714 - val_loss: 2.5249 - val_accuracy: 0.2467\n",
      "Epoch 1342/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3523 - accuracy: 0.4700 - val_loss: 2.5136 - val_accuracy: 0.2433\n",
      "Epoch 1343/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3514 - accuracy: 0.4629 - val_loss: 2.5182 - val_accuracy: 0.2467\n",
      "Epoch 1344/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3517 - accuracy: 0.4629 - val_loss: 2.5268 - val_accuracy: 0.2500\n",
      "Epoch 1345/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3512 - accuracy: 0.4714 - val_loss: 2.5456 - val_accuracy: 0.2500\n",
      "Epoch 1346/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3513 - accuracy: 0.4600 - val_loss: 2.4946 - val_accuracy: 0.2400\n",
      "Epoch 1347/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3523 - accuracy: 0.4700 - val_loss: 2.5174 - val_accuracy: 0.2467\n",
      "Epoch 1348/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3506 - accuracy: 0.4643 - val_loss: 2.5170 - val_accuracy: 0.2433\n",
      "Epoch 1349/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3508 - accuracy: 0.4643 - val_loss: 2.5316 - val_accuracy: 0.2467\n",
      "Epoch 1350/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3514 - accuracy: 0.4657 - val_loss: 2.5330 - val_accuracy: 0.2433\n",
      "Epoch 1351/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3512 - accuracy: 0.4686 - val_loss: 2.5341 - val_accuracy: 0.2500\n",
      "Epoch 1352/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3513 - accuracy: 0.4714 - val_loss: 2.5058 - val_accuracy: 0.2400\n",
      "Epoch 1353/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3507 - accuracy: 0.4686 - val_loss: 2.5294 - val_accuracy: 0.2433\n",
      "Epoch 1354/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3513 - accuracy: 0.4629 - val_loss: 2.5016 - val_accuracy: 0.2400\n",
      "Epoch 1355/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3500 - accuracy: 0.4700 - val_loss: 2.5319 - val_accuracy: 0.2433\n",
      "Epoch 1356/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3512 - accuracy: 0.4643 - val_loss: 2.5323 - val_accuracy: 0.2400\n",
      "Epoch 1357/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3517 - accuracy: 0.4686 - val_loss: 2.5376 - val_accuracy: 0.2467\n",
      "Epoch 1358/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3506 - accuracy: 0.4643 - val_loss: 2.5133 - val_accuracy: 0.2433\n",
      "Epoch 1359/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3497 - accuracy: 0.4671 - val_loss: 2.5463 - val_accuracy: 0.2400\n",
      "Epoch 1360/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3507 - accuracy: 0.4657 - val_loss: 2.5322 - val_accuracy: 0.2433\n",
      "Epoch 1361/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3510 - accuracy: 0.4629 - val_loss: 2.5432 - val_accuracy: 0.2467\n",
      "Epoch 1362/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3497 - accuracy: 0.4629 - val_loss: 2.5164 - val_accuracy: 0.2433\n",
      "Epoch 1363/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3506 - accuracy: 0.4714 - val_loss: 2.5269 - val_accuracy: 0.2433\n",
      "Epoch 1364/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3498 - accuracy: 0.4643 - val_loss: 2.5448 - val_accuracy: 0.2467\n",
      "Epoch 1365/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3505 - accuracy: 0.4729 - val_loss: 2.5087 - val_accuracy: 0.2400\n",
      "Epoch 1366/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3499 - accuracy: 0.4686 - val_loss: 2.5339 - val_accuracy: 0.2433\n",
      "Epoch 1367/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3499 - accuracy: 0.4757 - val_loss: 2.5131 - val_accuracy: 0.2433\n",
      "Epoch 1368/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3504 - accuracy: 0.4671 - val_loss: 2.5416 - val_accuracy: 0.2467\n",
      "Epoch 1369/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3505 - accuracy: 0.4686 - val_loss: 2.5629 - val_accuracy: 0.2433\n",
      "Epoch 1370/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3490 - accuracy: 0.4657 - val_loss: 2.5629 - val_accuracy: 0.2467\n",
      "Epoch 1371/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3502 - accuracy: 0.4714 - val_loss: 2.5404 - val_accuracy: 0.2400\n",
      "Epoch 1372/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3495 - accuracy: 0.4686 - val_loss: 2.5402 - val_accuracy: 0.2400\n",
      "Epoch 1373/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3495 - accuracy: 0.4714 - val_loss: 2.5460 - val_accuracy: 0.2533\n",
      "Epoch 1374/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3494 - accuracy: 0.4643 - val_loss: 2.5523 - val_accuracy: 0.2500\n",
      "Epoch 1375/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3496 - accuracy: 0.4743 - val_loss: 2.5248 - val_accuracy: 0.2433\n",
      "Epoch 1376/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3488 - accuracy: 0.4700 - val_loss: 2.5314 - val_accuracy: 0.2500\n",
      "Epoch 1377/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3495 - accuracy: 0.4686 - val_loss: 2.5093 - val_accuracy: 0.2433\n",
      "Epoch 1378/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3490 - accuracy: 0.4714 - val_loss: 2.5521 - val_accuracy: 0.2500\n",
      "Epoch 1379/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3487 - accuracy: 0.4643 - val_loss: 2.5612 - val_accuracy: 0.2433\n",
      "Epoch 1380/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3483 - accuracy: 0.4671 - val_loss: 2.5491 - val_accuracy: 0.2467\n",
      "Epoch 1381/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3487 - accuracy: 0.4686 - val_loss: 2.5499 - val_accuracy: 0.2433\n",
      "Epoch 1382/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3470 - accuracy: 0.4729 - val_loss: 2.5616 - val_accuracy: 0.2467\n",
      "Epoch 1383/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3481 - accuracy: 0.4643 - val_loss: 2.5498 - val_accuracy: 0.2433\n",
      "Epoch 1384/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3487 - accuracy: 0.4700 - val_loss: 2.5387 - val_accuracy: 0.2433\n",
      "Epoch 1385/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3475 - accuracy: 0.4743 - val_loss: 2.5509 - val_accuracy: 0.2467\n",
      "Epoch 1386/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3480 - accuracy: 0.4600 - val_loss: 2.5393 - val_accuracy: 0.2333\n",
      "Epoch 1387/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3478 - accuracy: 0.4700 - val_loss: 2.5598 - val_accuracy: 0.2300\n",
      "Epoch 1388/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 90us/step - loss: 1.3481 - accuracy: 0.4657 - val_loss: 2.5517 - val_accuracy: 0.2433\n",
      "Epoch 1389/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3471 - accuracy: 0.4671 - val_loss: 2.5614 - val_accuracy: 0.2467\n",
      "Epoch 1390/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3481 - accuracy: 0.4657 - val_loss: 2.5490 - val_accuracy: 0.2433\n",
      "Epoch 1391/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3483 - accuracy: 0.4657 - val_loss: 2.5623 - val_accuracy: 0.2467\n",
      "Epoch 1392/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3483 - accuracy: 0.4600 - val_loss: 2.5656 - val_accuracy: 0.2400\n",
      "Epoch 1393/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3475 - accuracy: 0.4700 - val_loss: 2.5671 - val_accuracy: 0.2467\n",
      "Epoch 1394/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3463 - accuracy: 0.4586 - val_loss: 2.5563 - val_accuracy: 0.2267\n",
      "Epoch 1395/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3475 - accuracy: 0.4671 - val_loss: 2.5644 - val_accuracy: 0.2300\n",
      "Epoch 1396/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3483 - accuracy: 0.4643 - val_loss: 2.5414 - val_accuracy: 0.2500\n",
      "Epoch 1397/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3462 - accuracy: 0.4657 - val_loss: 2.5557 - val_accuracy: 0.2467\n",
      "Epoch 1398/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3474 - accuracy: 0.4657 - val_loss: 2.5734 - val_accuracy: 0.2500\n",
      "Epoch 1399/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3466 - accuracy: 0.4757 - val_loss: 2.5919 - val_accuracy: 0.2500\n",
      "Epoch 1400/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3460 - accuracy: 0.4657 - val_loss: 2.6060 - val_accuracy: 0.2467\n",
      "Epoch 1401/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3471 - accuracy: 0.4714 - val_loss: 2.5623 - val_accuracy: 0.2500\n",
      "Epoch 1402/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3464 - accuracy: 0.4714 - val_loss: 2.5495 - val_accuracy: 0.2433\n",
      "Epoch 1403/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3450 - accuracy: 0.4671 - val_loss: 2.5464 - val_accuracy: 0.2467\n",
      "Epoch 1404/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3467 - accuracy: 0.4586 - val_loss: 2.5844 - val_accuracy: 0.2467\n",
      "Epoch 1405/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3465 - accuracy: 0.4614 - val_loss: 2.5606 - val_accuracy: 0.2467\n",
      "Epoch 1406/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3466 - accuracy: 0.4671 - val_loss: 2.5438 - val_accuracy: 0.2400\n",
      "Epoch 1407/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3464 - accuracy: 0.4714 - val_loss: 2.5516 - val_accuracy: 0.2433\n",
      "Epoch 1408/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3459 - accuracy: 0.4686 - val_loss: 2.5539 - val_accuracy: 0.2467\n",
      "Epoch 1409/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3458 - accuracy: 0.4657 - val_loss: 2.5339 - val_accuracy: 0.2467\n",
      "Epoch 1410/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3464 - accuracy: 0.4686 - val_loss: 2.5373 - val_accuracy: 0.2467\n",
      "Epoch 1411/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3458 - accuracy: 0.4714 - val_loss: 2.5891 - val_accuracy: 0.2467\n",
      "Epoch 1412/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3462 - accuracy: 0.4729 - val_loss: 2.5486 - val_accuracy: 0.2467\n",
      "Epoch 1413/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3458 - accuracy: 0.4643 - val_loss: 2.5771 - val_accuracy: 0.2400\n",
      "Epoch 1414/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3466 - accuracy: 0.4657 - val_loss: 2.5414 - val_accuracy: 0.2433\n",
      "Epoch 1415/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3458 - accuracy: 0.4743 - val_loss: 2.5668 - val_accuracy: 0.2500\n",
      "Epoch 1416/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3458 - accuracy: 0.4714 - val_loss: 2.5674 - val_accuracy: 0.2500\n",
      "Epoch 1417/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3462 - accuracy: 0.4714 - val_loss: 2.5347 - val_accuracy: 0.2500\n",
      "Epoch 1418/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3449 - accuracy: 0.4629 - val_loss: 2.5530 - val_accuracy: 0.2467\n",
      "Epoch 1419/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3457 - accuracy: 0.4686 - val_loss: 2.5247 - val_accuracy: 0.2433\n",
      "Epoch 1420/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3458 - accuracy: 0.4714 - val_loss: 2.5874 - val_accuracy: 0.2433\n",
      "Epoch 1421/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3458 - accuracy: 0.4657 - val_loss: 2.5665 - val_accuracy: 0.2433\n",
      "Epoch 1422/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3439 - accuracy: 0.4700 - val_loss: 2.5543 - val_accuracy: 0.2467\n",
      "Epoch 1423/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3447 - accuracy: 0.4643 - val_loss: 2.5797 - val_accuracy: 0.2400\n",
      "Epoch 1424/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3454 - accuracy: 0.4700 - val_loss: 2.5645 - val_accuracy: 0.2433\n",
      "Epoch 1425/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3439 - accuracy: 0.4614 - val_loss: 2.5740 - val_accuracy: 0.2333\n",
      "Epoch 1426/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3446 - accuracy: 0.4714 - val_loss: 2.5718 - val_accuracy: 0.2467\n",
      "Epoch 1427/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3441 - accuracy: 0.4686 - val_loss: 2.5912 - val_accuracy: 0.2467\n",
      "Epoch 1428/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3446 - accuracy: 0.4729 - val_loss: 2.5646 - val_accuracy: 0.2467\n",
      "Epoch 1429/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3446 - accuracy: 0.4657 - val_loss: 2.5360 - val_accuracy: 0.2433\n",
      "Epoch 1430/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3445 - accuracy: 0.4671 - val_loss: 2.5871 - val_accuracy: 0.2467\n",
      "Epoch 1431/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3437 - accuracy: 0.4771 - val_loss: 2.5388 - val_accuracy: 0.2400\n",
      "Epoch 1432/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3444 - accuracy: 0.4714 - val_loss: 2.5817 - val_accuracy: 0.2433\n",
      "Epoch 1433/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3449 - accuracy: 0.4686 - val_loss: 2.5714 - val_accuracy: 0.2467\n",
      "Epoch 1434/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3447 - accuracy: 0.4686 - val_loss: 2.5630 - val_accuracy: 0.2467\n",
      "Epoch 1435/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3447 - accuracy: 0.4643 - val_loss: 2.5701 - val_accuracy: 0.2433\n",
      "Epoch 1436/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3424 - accuracy: 0.4643 - val_loss: 2.5874 - val_accuracy: 0.2467\n",
      "Epoch 1437/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3446 - accuracy: 0.4743 - val_loss: 2.5755 - val_accuracy: 0.2467\n",
      "Epoch 1438/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3442 - accuracy: 0.4643 - val_loss: 2.5609 - val_accuracy: 0.2433\n",
      "Epoch 1439/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3439 - accuracy: 0.4729 - val_loss: 2.5808 - val_accuracy: 0.2500\n",
      "Epoch 1440/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3440 - accuracy: 0.4671 - val_loss: 2.5737 - val_accuracy: 0.2467\n",
      "Epoch 1441/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3436 - accuracy: 0.4714 - val_loss: 2.5730 - val_accuracy: 0.2400\n",
      "Epoch 1442/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3440 - accuracy: 0.4729 - val_loss: 2.5866 - val_accuracy: 0.2433\n",
      "Epoch 1443/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3433 - accuracy: 0.4686 - val_loss: 2.5838 - val_accuracy: 0.2433\n",
      "Epoch 1444/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3439 - accuracy: 0.4686 - val_loss: 2.5707 - val_accuracy: 0.2500\n",
      "Epoch 1445/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3425 - accuracy: 0.4600 - val_loss: 2.5708 - val_accuracy: 0.2333\n",
      "Epoch 1446/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3433 - accuracy: 0.4743 - val_loss: 2.6016 - val_accuracy: 0.2467\n",
      "Epoch 1447/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3436 - accuracy: 0.4643 - val_loss: 2.5811 - val_accuracy: 0.2433\n",
      "Epoch 1448/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3422 - accuracy: 0.4671 - val_loss: 2.5787 - val_accuracy: 0.2367\n",
      "Epoch 1449/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3428 - accuracy: 0.4671 - val_loss: 2.5523 - val_accuracy: 0.2433\n",
      "Epoch 1450/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3432 - accuracy: 0.4814 - val_loss: 2.5552 - val_accuracy: 0.2433\n",
      "Epoch 1451/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3425 - accuracy: 0.4714 - val_loss: 2.5922 - val_accuracy: 0.2467\n",
      "Epoch 1452/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3429 - accuracy: 0.4686 - val_loss: 2.5733 - val_accuracy: 0.2433\n",
      "Epoch 1453/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3423 - accuracy: 0.4657 - val_loss: 2.5708 - val_accuracy: 0.2433\n",
      "Epoch 1454/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3429 - accuracy: 0.4771 - val_loss: 2.5675 - val_accuracy: 0.2433\n",
      "Epoch 1455/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3427 - accuracy: 0.4757 - val_loss: 2.5933 - val_accuracy: 0.2467\n",
      "Epoch 1456/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3430 - accuracy: 0.4757 - val_loss: 2.5798 - val_accuracy: 0.2400\n",
      "Epoch 1457/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3425 - accuracy: 0.4643 - val_loss: 2.5912 - val_accuracy: 0.2500\n",
      "Epoch 1458/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3428 - accuracy: 0.4629 - val_loss: 2.5766 - val_accuracy: 0.2400\n",
      "Epoch 1459/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3425 - accuracy: 0.4686 - val_loss: 2.5751 - val_accuracy: 0.2500\n",
      "Epoch 1460/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3414 - accuracy: 0.4714 - val_loss: 2.5802 - val_accuracy: 0.2367\n",
      "Epoch 1461/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3412 - accuracy: 0.4671 - val_loss: 2.5682 - val_accuracy: 0.2533\n",
      "Epoch 1462/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3418 - accuracy: 0.4757 - val_loss: 2.6162 - val_accuracy: 0.2467\n",
      "Epoch 1463/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3418 - accuracy: 0.4657 - val_loss: 2.5876 - val_accuracy: 0.2433\n",
      "Epoch 1464/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3417 - accuracy: 0.4657 - val_loss: 2.5726 - val_accuracy: 0.2467\n",
      "Epoch 1465/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3418 - accuracy: 0.4700 - val_loss: 2.6127 - val_accuracy: 0.2433\n",
      "Epoch 1466/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3417 - accuracy: 0.4671 - val_loss: 2.5952 - val_accuracy: 0.2433\n",
      "Epoch 1467/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3396 - accuracy: 0.4729 - val_loss: 2.5920 - val_accuracy: 0.2433\n",
      "Epoch 1468/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3431 - accuracy: 0.4714 - val_loss: 2.5850 - val_accuracy: 0.2500\n",
      "Epoch 1469/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3417 - accuracy: 0.4686 - val_loss: 2.5990 - val_accuracy: 0.2433\n",
      "Epoch 1470/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3412 - accuracy: 0.4714 - val_loss: 2.5959 - val_accuracy: 0.2433\n",
      "Epoch 1471/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3403 - accuracy: 0.4700 - val_loss: 2.5983 - val_accuracy: 0.2500\n",
      "Epoch 1472/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3413 - accuracy: 0.4643 - val_loss: 2.6075 - val_accuracy: 0.2433\n",
      "Epoch 1473/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3407 - accuracy: 0.4686 - val_loss: 2.5796 - val_accuracy: 0.2433\n",
      "Epoch 1474/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3404 - accuracy: 0.4714 - val_loss: 2.5906 - val_accuracy: 0.2500\n",
      "Epoch 1475/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3403 - accuracy: 0.4714 - val_loss: 2.6062 - val_accuracy: 0.2500\n",
      "Epoch 1476/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3409 - accuracy: 0.4671 - val_loss: 2.5975 - val_accuracy: 0.2433\n",
      "Epoch 1477/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3411 - accuracy: 0.4657 - val_loss: 2.6012 - val_accuracy: 0.2400\n",
      "Epoch 1478/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3401 - accuracy: 0.4729 - val_loss: 2.5700 - val_accuracy: 0.2533\n",
      "Epoch 1479/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3403 - accuracy: 0.4629 - val_loss: 2.5874 - val_accuracy: 0.2433\n",
      "Epoch 1480/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3408 - accuracy: 0.4700 - val_loss: 2.5913 - val_accuracy: 0.2433\n",
      "Epoch 1481/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3400 - accuracy: 0.4657 - val_loss: 2.5908 - val_accuracy: 0.2367\n",
      "Epoch 1482/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3401 - accuracy: 0.4714 - val_loss: 2.6251 - val_accuracy: 0.2500\n",
      "Epoch 1483/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3409 - accuracy: 0.4743 - val_loss: 2.6065 - val_accuracy: 0.2433\n",
      "Epoch 1484/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3397 - accuracy: 0.4686 - val_loss: 2.5875 - val_accuracy: 0.2367\n",
      "Epoch 1485/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3396 - accuracy: 0.4657 - val_loss: 2.6126 - val_accuracy: 0.2267\n",
      "Epoch 1486/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3402 - accuracy: 0.4700 - val_loss: 2.5930 - val_accuracy: 0.2500\n",
      "Epoch 1487/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3396 - accuracy: 0.4686 - val_loss: 2.6135 - val_accuracy: 0.2467\n",
      "Epoch 1488/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3391 - accuracy: 0.4629 - val_loss: 2.5694 - val_accuracy: 0.2400\n",
      "Epoch 1489/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3399 - accuracy: 0.4700 - val_loss: 2.6190 - val_accuracy: 0.2367\n",
      "Epoch 1490/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3390 - accuracy: 0.4686 - val_loss: 2.6249 - val_accuracy: 0.2467\n",
      "Epoch 1491/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3395 - accuracy: 0.4714 - val_loss: 2.6218 - val_accuracy: 0.2433\n",
      "Epoch 1492/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3378 - accuracy: 0.4714 - val_loss: 2.6114 - val_accuracy: 0.2367\n",
      "Epoch 1493/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3412 - accuracy: 0.4614 - val_loss: 2.6008 - val_accuracy: 0.2500\n",
      "Epoch 1494/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3398 - accuracy: 0.4743 - val_loss: 2.5969 - val_accuracy: 0.2500\n",
      "Epoch 1495/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3383 - accuracy: 0.4686 - val_loss: 2.5987 - val_accuracy: 0.2433\n",
      "Epoch 1496/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3393 - accuracy: 0.4714 - val_loss: 2.5972 - val_accuracy: 0.2500\n",
      "Epoch 1497/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3383 - accuracy: 0.4671 - val_loss: 2.6129 - val_accuracy: 0.2433\n",
      "Epoch 1498/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 90us/step - loss: 1.3387 - accuracy: 0.4743 - val_loss: 2.6393 - val_accuracy: 0.2500\n",
      "Epoch 1499/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3395 - accuracy: 0.4700 - val_loss: 2.6042 - val_accuracy: 0.2467\n",
      "Epoch 1500/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3388 - accuracy: 0.4771 - val_loss: 2.6116 - val_accuracy: 0.2433\n",
      "Epoch 1501/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3389 - accuracy: 0.4729 - val_loss: 2.6054 - val_accuracy: 0.2467\n",
      "Epoch 1502/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3390 - accuracy: 0.4714 - val_loss: 2.6098 - val_accuracy: 0.2467\n",
      "Epoch 1503/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3390 - accuracy: 0.4657 - val_loss: 2.6042 - val_accuracy: 0.2433\n",
      "Epoch 1504/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3381 - accuracy: 0.4743 - val_loss: 2.6240 - val_accuracy: 0.2433\n",
      "Epoch 1505/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3386 - accuracy: 0.4686 - val_loss: 2.6131 - val_accuracy: 0.2400\n",
      "Epoch 1506/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3391 - accuracy: 0.4786 - val_loss: 2.5983 - val_accuracy: 0.2433\n",
      "Epoch 1507/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3382 - accuracy: 0.4714 - val_loss: 2.6043 - val_accuracy: 0.2367\n",
      "Epoch 1508/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3387 - accuracy: 0.4643 - val_loss: 2.6308 - val_accuracy: 0.2467\n",
      "Epoch 1509/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3382 - accuracy: 0.4757 - val_loss: 2.6092 - val_accuracy: 0.2433\n",
      "Epoch 1510/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3384 - accuracy: 0.4743 - val_loss: 2.6532 - val_accuracy: 0.2467\n",
      "Epoch 1511/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3379 - accuracy: 0.4729 - val_loss: 2.6494 - val_accuracy: 0.2500\n",
      "Epoch 1512/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3368 - accuracy: 0.4714 - val_loss: 2.6204 - val_accuracy: 0.2433\n",
      "Epoch 1513/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3380 - accuracy: 0.4686 - val_loss: 2.5901 - val_accuracy: 0.2433\n",
      "Epoch 1514/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3381 - accuracy: 0.4671 - val_loss: 2.6135 - val_accuracy: 0.2433\n",
      "Epoch 1515/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3377 - accuracy: 0.4757 - val_loss: 2.6393 - val_accuracy: 0.2500\n",
      "Epoch 1516/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3395 - accuracy: 0.4743 - val_loss: 2.6289 - val_accuracy: 0.2467\n",
      "Epoch 1517/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3373 - accuracy: 0.4743 - val_loss: 2.6084 - val_accuracy: 0.2467\n",
      "Epoch 1518/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3371 - accuracy: 0.4757 - val_loss: 2.5965 - val_accuracy: 0.2500\n",
      "Epoch 1519/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3370 - accuracy: 0.4757 - val_loss: 2.5948 - val_accuracy: 0.2367\n",
      "Epoch 1520/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3373 - accuracy: 0.4700 - val_loss: 2.6313 - val_accuracy: 0.2467\n",
      "Epoch 1521/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3368 - accuracy: 0.4800 - val_loss: 2.5999 - val_accuracy: 0.2433\n",
      "Epoch 1522/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3379 - accuracy: 0.4714 - val_loss: 2.6182 - val_accuracy: 0.2467\n",
      "Epoch 1523/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3371 - accuracy: 0.4743 - val_loss: 2.6055 - val_accuracy: 0.2467\n",
      "Epoch 1524/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3374 - accuracy: 0.4714 - val_loss: 2.6326 - val_accuracy: 0.2467\n",
      "Epoch 1525/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3370 - accuracy: 0.4729 - val_loss: 2.6146 - val_accuracy: 0.2467\n",
      "Epoch 1526/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3369 - accuracy: 0.4743 - val_loss: 2.6632 - val_accuracy: 0.2467\n",
      "Epoch 1527/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3354 - accuracy: 0.4686 - val_loss: 2.6116 - val_accuracy: 0.2333\n",
      "Epoch 1528/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3370 - accuracy: 0.4786 - val_loss: 2.6319 - val_accuracy: 0.2467\n",
      "Epoch 1529/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3375 - accuracy: 0.4657 - val_loss: 2.6297 - val_accuracy: 0.2433\n",
      "Epoch 1530/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3369 - accuracy: 0.4643 - val_loss: 2.6194 - val_accuracy: 0.2433\n",
      "Epoch 1531/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3366 - accuracy: 0.4757 - val_loss: 2.6224 - val_accuracy: 0.2433\n",
      "Epoch 1532/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3364 - accuracy: 0.4800 - val_loss: 2.6019 - val_accuracy: 0.2500\n",
      "Epoch 1533/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3365 - accuracy: 0.4729 - val_loss: 2.6190 - val_accuracy: 0.2433\n",
      "Epoch 1534/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3370 - accuracy: 0.4700 - val_loss: 2.6057 - val_accuracy: 0.2500\n",
      "Epoch 1535/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3368 - accuracy: 0.4771 - val_loss: 2.6405 - val_accuracy: 0.2400\n",
      "Epoch 1536/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3360 - accuracy: 0.4757 - val_loss: 2.6244 - val_accuracy: 0.2400\n",
      "Epoch 1537/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3359 - accuracy: 0.4743 - val_loss: 2.6217 - val_accuracy: 0.2467\n",
      "Epoch 1538/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3354 - accuracy: 0.4729 - val_loss: 2.6127 - val_accuracy: 0.2433\n",
      "Epoch 1539/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3354 - accuracy: 0.4671 - val_loss: 2.6013 - val_accuracy: 0.2500\n",
      "Epoch 1540/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3358 - accuracy: 0.4714 - val_loss: 2.6026 - val_accuracy: 0.2500\n",
      "Epoch 1541/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3362 - accuracy: 0.4714 - val_loss: 2.6284 - val_accuracy: 0.2433\n",
      "Epoch 1542/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3357 - accuracy: 0.4729 - val_loss: 2.6263 - val_accuracy: 0.2367\n",
      "Epoch 1543/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3357 - accuracy: 0.4757 - val_loss: 2.6158 - val_accuracy: 0.2433\n",
      "Epoch 1544/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3362 - accuracy: 0.4800 - val_loss: 2.6253 - val_accuracy: 0.2433\n",
      "Epoch 1545/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3352 - accuracy: 0.4729 - val_loss: 2.6046 - val_accuracy: 0.2433\n",
      "Epoch 1546/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3357 - accuracy: 0.4800 - val_loss: 2.6308 - val_accuracy: 0.2367\n",
      "Epoch 1547/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3356 - accuracy: 0.4757 - val_loss: 2.6498 - val_accuracy: 0.2433\n",
      "Epoch 1548/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3358 - accuracy: 0.4714 - val_loss: 2.6463 - val_accuracy: 0.2500\n",
      "Epoch 1549/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3343 - accuracy: 0.4729 - val_loss: 2.6542 - val_accuracy: 0.2433\n",
      "Epoch 1550/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3352 - accuracy: 0.4700 - val_loss: 2.6547 - val_accuracy: 0.2433\n",
      "Epoch 1551/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3351 - accuracy: 0.4743 - val_loss: 2.6209 - val_accuracy: 0.2367\n",
      "Epoch 1552/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3348 - accuracy: 0.4729 - val_loss: 2.6499 - val_accuracy: 0.2500\n",
      "Epoch 1553/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3348 - accuracy: 0.4771 - val_loss: 2.6502 - val_accuracy: 0.2467\n",
      "Epoch 1554/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3352 - accuracy: 0.4700 - val_loss: 2.6340 - val_accuracy: 0.2367\n",
      "Epoch 1555/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3350 - accuracy: 0.4714 - val_loss: 2.6340 - val_accuracy: 0.2400\n",
      "Epoch 1556/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3342 - accuracy: 0.4729 - val_loss: 2.6275 - val_accuracy: 0.2467\n",
      "Epoch 1557/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3339 - accuracy: 0.4729 - val_loss: 2.6351 - val_accuracy: 0.2433\n",
      "Epoch 1558/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3342 - accuracy: 0.4743 - val_loss: 2.5980 - val_accuracy: 0.2533\n",
      "Epoch 1559/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3345 - accuracy: 0.4757 - val_loss: 2.6485 - val_accuracy: 0.2467\n",
      "Epoch 1560/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3347 - accuracy: 0.4729 - val_loss: 2.6310 - val_accuracy: 0.2433\n",
      "Epoch 1561/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3337 - accuracy: 0.4714 - val_loss: 2.6370 - val_accuracy: 0.2467\n",
      "Epoch 1562/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3343 - accuracy: 0.4700 - val_loss: 2.6726 - val_accuracy: 0.2500\n",
      "Epoch 1563/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3350 - accuracy: 0.4757 - val_loss: 2.6434 - val_accuracy: 0.2467\n",
      "Epoch 1564/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3328 - accuracy: 0.4757 - val_loss: 2.6319 - val_accuracy: 0.2400\n",
      "Epoch 1565/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3350 - accuracy: 0.4757 - val_loss: 2.6307 - val_accuracy: 0.2467\n",
      "Epoch 1566/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3334 - accuracy: 0.4771 - val_loss: 2.6387 - val_accuracy: 0.2367\n",
      "Epoch 1567/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3343 - accuracy: 0.4757 - val_loss: 2.6435 - val_accuracy: 0.2400\n",
      "Epoch 1568/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3337 - accuracy: 0.4729 - val_loss: 2.6328 - val_accuracy: 0.2433\n",
      "Epoch 1569/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3342 - accuracy: 0.4786 - val_loss: 2.6693 - val_accuracy: 0.2467\n",
      "Epoch 1570/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3330 - accuracy: 0.4814 - val_loss: 2.6782 - val_accuracy: 0.2433\n",
      "Epoch 1571/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3347 - accuracy: 0.4714 - val_loss: 2.6616 - val_accuracy: 0.2433\n",
      "Epoch 1572/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3339 - accuracy: 0.4771 - val_loss: 2.6387 - val_accuracy: 0.2367\n",
      "Epoch 1573/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3335 - accuracy: 0.4757 - val_loss: 2.6814 - val_accuracy: 0.2433\n",
      "Epoch 1574/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3339 - accuracy: 0.4671 - val_loss: 2.6534 - val_accuracy: 0.2433\n",
      "Epoch 1575/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3327 - accuracy: 0.4757 - val_loss: 2.6278 - val_accuracy: 0.2467\n",
      "Epoch 1576/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3330 - accuracy: 0.4771 - val_loss: 2.6691 - val_accuracy: 0.2467\n",
      "Epoch 1577/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3337 - accuracy: 0.4700 - val_loss: 2.6356 - val_accuracy: 0.2400\n",
      "Epoch 1578/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3320 - accuracy: 0.4771 - val_loss: 2.6465 - val_accuracy: 0.2433\n",
      "Epoch 1579/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3331 - accuracy: 0.4714 - val_loss: 2.6453 - val_accuracy: 0.2467\n",
      "Epoch 1580/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3321 - accuracy: 0.4800 - val_loss: 2.6620 - val_accuracy: 0.2467\n",
      "Epoch 1581/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3335 - accuracy: 0.4671 - val_loss: 2.6603 - val_accuracy: 0.2400\n",
      "Epoch 1582/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3330 - accuracy: 0.4771 - val_loss: 2.6338 - val_accuracy: 0.2433\n",
      "Epoch 1583/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3323 - accuracy: 0.4743 - val_loss: 2.6476 - val_accuracy: 0.2433\n",
      "Epoch 1584/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3336 - accuracy: 0.4757 - val_loss: 2.6591 - val_accuracy: 0.2433\n",
      "Epoch 1585/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3327 - accuracy: 0.4700 - val_loss: 2.6486 - val_accuracy: 0.2500\n",
      "Epoch 1586/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3318 - accuracy: 0.4729 - val_loss: 2.6663 - val_accuracy: 0.2333\n",
      "Epoch 1587/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3321 - accuracy: 0.4714 - val_loss: 2.6713 - val_accuracy: 0.2400\n",
      "Epoch 1588/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3320 - accuracy: 0.4800 - val_loss: 2.6373 - val_accuracy: 0.2467\n",
      "Epoch 1589/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3324 - accuracy: 0.4786 - val_loss: 2.6690 - val_accuracy: 0.2400\n",
      "Epoch 1590/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3316 - accuracy: 0.4714 - val_loss: 2.6570 - val_accuracy: 0.2500\n",
      "Epoch 1591/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3324 - accuracy: 0.4800 - val_loss: 2.6426 - val_accuracy: 0.2433\n",
      "Epoch 1592/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3319 - accuracy: 0.4686 - val_loss: 2.6602 - val_accuracy: 0.2467\n",
      "Epoch 1593/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3310 - accuracy: 0.4700 - val_loss: 2.6723 - val_accuracy: 0.2400\n",
      "Epoch 1594/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3321 - accuracy: 0.4771 - val_loss: 2.6611 - val_accuracy: 0.2433\n",
      "Epoch 1595/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3310 - accuracy: 0.4771 - val_loss: 2.6530 - val_accuracy: 0.2433\n",
      "Epoch 1596/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3315 - accuracy: 0.4729 - val_loss: 2.6219 - val_accuracy: 0.2467\n",
      "Epoch 1597/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3311 - accuracy: 0.4757 - val_loss: 2.6387 - val_accuracy: 0.2433\n",
      "Epoch 1598/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3323 - accuracy: 0.4829 - val_loss: 2.6641 - val_accuracy: 0.2400\n",
      "Epoch 1599/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3313 - accuracy: 0.4686 - val_loss: 2.6547 - val_accuracy: 0.2333\n",
      "Epoch 1600/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3315 - accuracy: 0.4771 - val_loss: 2.6646 - val_accuracy: 0.2333\n",
      "Epoch 1601/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3320 - accuracy: 0.4771 - val_loss: 2.6424 - val_accuracy: 0.2467\n",
      "Epoch 1602/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3307 - accuracy: 0.4729 - val_loss: 2.6798 - val_accuracy: 0.2467\n",
      "Epoch 1603/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3313 - accuracy: 0.4714 - val_loss: 2.6782 - val_accuracy: 0.2500\n",
      "Epoch 1604/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3311 - accuracy: 0.4757 - val_loss: 2.6673 - val_accuracy: 0.2433\n",
      "Epoch 1605/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3313 - accuracy: 0.4800 - val_loss: 2.6857 - val_accuracy: 0.2500\n",
      "Epoch 1606/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3307 - accuracy: 0.4786 - val_loss: 2.6368 - val_accuracy: 0.2400\n",
      "Epoch 1607/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3324 - accuracy: 0.4800 - val_loss: 2.6526 - val_accuracy: 0.2467\n",
      "Epoch 1608/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 90us/step - loss: 1.3294 - accuracy: 0.4786 - val_loss: 2.6625 - val_accuracy: 0.2467\n",
      "Epoch 1609/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3308 - accuracy: 0.4786 - val_loss: 2.7004 - val_accuracy: 0.2500\n",
      "Epoch 1610/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3312 - accuracy: 0.4729 - val_loss: 2.6731 - val_accuracy: 0.2433\n",
      "Epoch 1611/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3299 - accuracy: 0.4743 - val_loss: 2.6899 - val_accuracy: 0.2433\n",
      "Epoch 1612/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3306 - accuracy: 0.4729 - val_loss: 2.6726 - val_accuracy: 0.2433\n",
      "Epoch 1613/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3300 - accuracy: 0.4743 - val_loss: 2.6727 - val_accuracy: 0.2333\n",
      "Epoch 1614/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3304 - accuracy: 0.4700 - val_loss: 2.6780 - val_accuracy: 0.2467\n",
      "Epoch 1615/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3310 - accuracy: 0.4800 - val_loss: 2.6939 - val_accuracy: 0.2467\n",
      "Epoch 1616/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3307 - accuracy: 0.4786 - val_loss: 2.6709 - val_accuracy: 0.2433\n",
      "Epoch 1617/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3293 - accuracy: 0.4757 - val_loss: 2.6457 - val_accuracy: 0.2433\n",
      "Epoch 1618/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3312 - accuracy: 0.4729 - val_loss: 2.6711 - val_accuracy: 0.2400\n",
      "Epoch 1619/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3300 - accuracy: 0.4743 - val_loss: 2.6753 - val_accuracy: 0.2467\n",
      "Epoch 1620/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3300 - accuracy: 0.4757 - val_loss: 2.6782 - val_accuracy: 0.2400\n",
      "Epoch 1621/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3298 - accuracy: 0.4800 - val_loss: 2.7107 - val_accuracy: 0.2467\n",
      "Epoch 1622/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3293 - accuracy: 0.4743 - val_loss: 2.6503 - val_accuracy: 0.2467\n",
      "Epoch 1623/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3291 - accuracy: 0.4729 - val_loss: 2.6661 - val_accuracy: 0.2400\n",
      "Epoch 1624/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3281 - accuracy: 0.4757 - val_loss: 2.6819 - val_accuracy: 0.2400\n",
      "Epoch 1625/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3297 - accuracy: 0.4743 - val_loss: 2.6781 - val_accuracy: 0.2367\n",
      "Epoch 1626/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3291 - accuracy: 0.4771 - val_loss: 2.6668 - val_accuracy: 0.2400\n",
      "Epoch 1627/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3291 - accuracy: 0.4771 - val_loss: 2.7246 - val_accuracy: 0.2433\n",
      "Epoch 1628/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3292 - accuracy: 0.4800 - val_loss: 2.6879 - val_accuracy: 0.2400\n",
      "Epoch 1629/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3294 - accuracy: 0.4814 - val_loss: 2.6605 - val_accuracy: 0.2433\n",
      "Epoch 1630/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3292 - accuracy: 0.4743 - val_loss: 2.6890 - val_accuracy: 0.2400\n",
      "Epoch 1631/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3295 - accuracy: 0.4800 - val_loss: 2.6815 - val_accuracy: 0.2433\n",
      "Epoch 1632/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3282 - accuracy: 0.4771 - val_loss: 2.7149 - val_accuracy: 0.2433\n",
      "Epoch 1633/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3291 - accuracy: 0.4729 - val_loss: 2.6811 - val_accuracy: 0.2400\n",
      "Epoch 1634/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3282 - accuracy: 0.4771 - val_loss: 2.7043 - val_accuracy: 0.2500\n",
      "Epoch 1635/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3278 - accuracy: 0.4714 - val_loss: 2.6794 - val_accuracy: 0.2400\n",
      "Epoch 1636/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3288 - accuracy: 0.4743 - val_loss: 2.7085 - val_accuracy: 0.2500\n",
      "Epoch 1637/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3265 - accuracy: 0.4714 - val_loss: 2.7041 - val_accuracy: 0.2433\n",
      "Epoch 1638/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3279 - accuracy: 0.4786 - val_loss: 2.7136 - val_accuracy: 0.2467\n",
      "Epoch 1639/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3275 - accuracy: 0.4686 - val_loss: 2.7062 - val_accuracy: 0.2400\n",
      "Epoch 1640/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3276 - accuracy: 0.4757 - val_loss: 2.7232 - val_accuracy: 0.2467\n",
      "Epoch 1641/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3284 - accuracy: 0.4814 - val_loss: 2.6766 - val_accuracy: 0.2400\n",
      "Epoch 1642/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3278 - accuracy: 0.4786 - val_loss: 2.6917 - val_accuracy: 0.2433\n",
      "Epoch 1643/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3274 - accuracy: 0.4814 - val_loss: 2.7086 - val_accuracy: 0.2467\n",
      "Epoch 1644/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3273 - accuracy: 0.4757 - val_loss: 2.6862 - val_accuracy: 0.2400\n",
      "Epoch 1645/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3257 - accuracy: 0.4829 - val_loss: 2.6932 - val_accuracy: 0.2433\n",
      "Epoch 1646/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3263 - accuracy: 0.4686 - val_loss: 2.6691 - val_accuracy: 0.2367\n",
      "Epoch 1647/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3266 - accuracy: 0.4843 - val_loss: 2.7287 - val_accuracy: 0.2433\n",
      "Epoch 1648/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3275 - accuracy: 0.4771 - val_loss: 2.7117 - val_accuracy: 0.2400\n",
      "Epoch 1649/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3265 - accuracy: 0.4743 - val_loss: 2.7074 - val_accuracy: 0.2400\n",
      "Epoch 1650/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3260 - accuracy: 0.4857 - val_loss: 2.6888 - val_accuracy: 0.2433\n",
      "Epoch 1651/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3276 - accuracy: 0.4729 - val_loss: 2.6837 - val_accuracy: 0.2467\n",
      "Epoch 1652/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3268 - accuracy: 0.4743 - val_loss: 2.6958 - val_accuracy: 0.2400\n",
      "Epoch 1653/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3259 - accuracy: 0.4743 - val_loss: 2.7185 - val_accuracy: 0.2500\n",
      "Epoch 1654/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3285 - accuracy: 0.4786 - val_loss: 2.6946 - val_accuracy: 0.2467\n",
      "Epoch 1655/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3257 - accuracy: 0.4771 - val_loss: 2.6982 - val_accuracy: 0.2400\n",
      "Epoch 1656/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3273 - accuracy: 0.4786 - val_loss: 2.6948 - val_accuracy: 0.2400\n",
      "Epoch 1657/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3268 - accuracy: 0.4829 - val_loss: 2.6933 - val_accuracy: 0.2467\n",
      "Epoch 1658/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3263 - accuracy: 0.4786 - val_loss: 2.7085 - val_accuracy: 0.2400\n",
      "Epoch 1659/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3266 - accuracy: 0.4857 - val_loss: 2.6862 - val_accuracy: 0.2400\n",
      "Epoch 1660/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3262 - accuracy: 0.4757 - val_loss: 2.7058 - val_accuracy: 0.2400\n",
      "Epoch 1661/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3259 - accuracy: 0.4786 - val_loss: 2.6907 - val_accuracy: 0.2433\n",
      "Epoch 1662/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3261 - accuracy: 0.4757 - val_loss: 2.6995 - val_accuracy: 0.2433\n",
      "Epoch 1663/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3263 - accuracy: 0.4800 - val_loss: 2.7092 - val_accuracy: 0.2433\n",
      "Epoch 1664/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3267 - accuracy: 0.4757 - val_loss: 2.7177 - val_accuracy: 0.2467\n",
      "Epoch 1665/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3258 - accuracy: 0.4657 - val_loss: 2.6972 - val_accuracy: 0.2467\n",
      "Epoch 1666/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3258 - accuracy: 0.4814 - val_loss: 2.6991 - val_accuracy: 0.2467\n",
      "Epoch 1667/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3253 - accuracy: 0.4786 - val_loss: 2.6890 - val_accuracy: 0.2400\n",
      "Epoch 1668/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3255 - accuracy: 0.4729 - val_loss: 2.6885 - val_accuracy: 0.2400\n",
      "Epoch 1669/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3258 - accuracy: 0.4829 - val_loss: 2.7045 - val_accuracy: 0.2400\n",
      "Epoch 1670/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3249 - accuracy: 0.4814 - val_loss: 2.7292 - val_accuracy: 0.2433\n",
      "Epoch 1671/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3256 - accuracy: 0.4757 - val_loss: 2.7207 - val_accuracy: 0.2433\n",
      "Epoch 1672/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3252 - accuracy: 0.4814 - val_loss: 2.7174 - val_accuracy: 0.2433\n",
      "Epoch 1673/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3248 - accuracy: 0.4771 - val_loss: 2.7509 - val_accuracy: 0.2533\n",
      "Epoch 1674/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3242 - accuracy: 0.4871 - val_loss: 2.7321 - val_accuracy: 0.2433\n",
      "Epoch 1675/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3251 - accuracy: 0.4786 - val_loss: 2.6973 - val_accuracy: 0.2400\n",
      "Epoch 1676/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3255 - accuracy: 0.4771 - val_loss: 2.7175 - val_accuracy: 0.2400\n",
      "Epoch 1677/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3237 - accuracy: 0.4771 - val_loss: 2.6928 - val_accuracy: 0.2467\n",
      "Epoch 1678/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3250 - accuracy: 0.4771 - val_loss: 2.7118 - val_accuracy: 0.2433\n",
      "Epoch 1679/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3245 - accuracy: 0.4757 - val_loss: 2.7226 - val_accuracy: 0.2400\n",
      "Epoch 1680/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3245 - accuracy: 0.4814 - val_loss: 2.7060 - val_accuracy: 0.2433\n",
      "Epoch 1681/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3249 - accuracy: 0.4800 - val_loss: 2.7123 - val_accuracy: 0.2400\n",
      "Epoch 1682/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3248 - accuracy: 0.4800 - val_loss: 2.7110 - val_accuracy: 0.2433\n",
      "Epoch 1683/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3248 - accuracy: 0.4829 - val_loss: 2.7117 - val_accuracy: 0.2400\n",
      "Epoch 1684/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3234 - accuracy: 0.4843 - val_loss: 2.7466 - val_accuracy: 0.2467\n",
      "Epoch 1685/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3248 - accuracy: 0.4786 - val_loss: 2.7151 - val_accuracy: 0.2433\n",
      "Epoch 1686/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3238 - accuracy: 0.4729 - val_loss: 2.7518 - val_accuracy: 0.2500\n",
      "Epoch 1687/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3245 - accuracy: 0.4871 - val_loss: 2.7195 - val_accuracy: 0.2400\n",
      "Epoch 1688/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3245 - accuracy: 0.4886 - val_loss: 2.7087 - val_accuracy: 0.2400\n",
      "Epoch 1689/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3250 - accuracy: 0.4757 - val_loss: 2.7209 - val_accuracy: 0.2433\n",
      "Epoch 1690/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3244 - accuracy: 0.4814 - val_loss: 2.7116 - val_accuracy: 0.2367\n",
      "Epoch 1691/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3233 - accuracy: 0.4829 - val_loss: 2.7133 - val_accuracy: 0.2433\n",
      "Epoch 1692/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3240 - accuracy: 0.4786 - val_loss: 2.7283 - val_accuracy: 0.2433\n",
      "Epoch 1693/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3237 - accuracy: 0.4757 - val_loss: 2.7456 - val_accuracy: 0.2400\n",
      "Epoch 1694/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3243 - accuracy: 0.4829 - val_loss: 2.7446 - val_accuracy: 0.2467\n",
      "Epoch 1695/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3240 - accuracy: 0.4786 - val_loss: 2.7232 - val_accuracy: 0.2433\n",
      "Epoch 1696/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3234 - accuracy: 0.4786 - val_loss: 2.6872 - val_accuracy: 0.2467\n",
      "Epoch 1697/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3235 - accuracy: 0.4871 - val_loss: 2.7205 - val_accuracy: 0.2433\n",
      "Epoch 1698/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3234 - accuracy: 0.4829 - val_loss: 2.7329 - val_accuracy: 0.2400\n",
      "Epoch 1699/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3238 - accuracy: 0.4786 - val_loss: 2.7470 - val_accuracy: 0.2467\n",
      "Epoch 1700/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3229 - accuracy: 0.4771 - val_loss: 2.7461 - val_accuracy: 0.2500\n",
      "Epoch 1701/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3228 - accuracy: 0.4814 - val_loss: 2.7329 - val_accuracy: 0.2433\n",
      "Epoch 1702/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3235 - accuracy: 0.4743 - val_loss: 2.7110 - val_accuracy: 0.2433\n",
      "Epoch 1703/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3229 - accuracy: 0.4714 - val_loss: 2.7191 - val_accuracy: 0.2400\n",
      "Epoch 1704/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3225 - accuracy: 0.4786 - val_loss: 2.7292 - val_accuracy: 0.2400\n",
      "Epoch 1705/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3232 - accuracy: 0.4829 - val_loss: 2.7529 - val_accuracy: 0.2467\n",
      "Epoch 1706/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3226 - accuracy: 0.4800 - val_loss: 2.7202 - val_accuracy: 0.2433\n",
      "Epoch 1707/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3232 - accuracy: 0.4814 - val_loss: 2.7391 - val_accuracy: 0.2467\n",
      "Epoch 1708/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3217 - accuracy: 0.4786 - val_loss: 2.7271 - val_accuracy: 0.2433\n",
      "Epoch 1709/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3221 - accuracy: 0.4771 - val_loss: 2.7326 - val_accuracy: 0.2433\n",
      "Epoch 1710/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3226 - accuracy: 0.4771 - val_loss: 2.7145 - val_accuracy: 0.2433\n",
      "Epoch 1711/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3225 - accuracy: 0.4800 - val_loss: 2.7277 - val_accuracy: 0.2433\n",
      "Epoch 1712/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3231 - accuracy: 0.4786 - val_loss: 2.7367 - val_accuracy: 0.2433\n",
      "Epoch 1713/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3219 - accuracy: 0.4757 - val_loss: 2.7637 - val_accuracy: 0.2500\n",
      "Epoch 1714/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3233 - accuracy: 0.4814 - val_loss: 2.7087 - val_accuracy: 0.2433\n",
      "Epoch 1715/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3225 - accuracy: 0.4857 - val_loss: 2.7605 - val_accuracy: 0.2533\n",
      "Epoch 1716/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3221 - accuracy: 0.4800 - val_loss: 2.7636 - val_accuracy: 0.2533\n",
      "Epoch 1717/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3220 - accuracy: 0.4800 - val_loss: 2.7174 - val_accuracy: 0.2433\n",
      "Epoch 1718/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 87us/step - loss: 1.3229 - accuracy: 0.4886 - val_loss: 2.7441 - val_accuracy: 0.2467\n",
      "Epoch 1719/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3224 - accuracy: 0.4857 - val_loss: 2.6847 - val_accuracy: 0.2433\n",
      "Epoch 1720/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3212 - accuracy: 0.4814 - val_loss: 2.7311 - val_accuracy: 0.2433\n",
      "Epoch 1721/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3220 - accuracy: 0.4800 - val_loss: 2.7231 - val_accuracy: 0.2433\n",
      "Epoch 1722/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3227 - accuracy: 0.4757 - val_loss: 2.7074 - val_accuracy: 0.2400\n",
      "Epoch 1723/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3219 - accuracy: 0.4800 - val_loss: 2.7116 - val_accuracy: 0.2400\n",
      "Epoch 1724/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3210 - accuracy: 0.4857 - val_loss: 2.7300 - val_accuracy: 0.2367\n",
      "Epoch 1725/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3217 - accuracy: 0.4857 - val_loss: 2.7403 - val_accuracy: 0.2433\n",
      "Epoch 1726/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3212 - accuracy: 0.4814 - val_loss: 2.7482 - val_accuracy: 0.2467\n",
      "Epoch 1727/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3221 - accuracy: 0.4829 - val_loss: 2.7459 - val_accuracy: 0.2500\n",
      "Epoch 1728/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3212 - accuracy: 0.4743 - val_loss: 2.7464 - val_accuracy: 0.2433\n",
      "Epoch 1729/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3219 - accuracy: 0.4757 - val_loss: 2.7380 - val_accuracy: 0.2400\n",
      "Epoch 1730/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3210 - accuracy: 0.4843 - val_loss: 2.7198 - val_accuracy: 0.2400\n",
      "Epoch 1731/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3213 - accuracy: 0.4814 - val_loss: 2.7584 - val_accuracy: 0.2500\n",
      "Epoch 1732/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3210 - accuracy: 0.4829 - val_loss: 2.7479 - val_accuracy: 0.2467\n",
      "Epoch 1733/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3201 - accuracy: 0.4800 - val_loss: 2.7631 - val_accuracy: 0.2467\n",
      "Epoch 1734/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3212 - accuracy: 0.4757 - val_loss: 2.7523 - val_accuracy: 0.2433\n",
      "Epoch 1735/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3217 - accuracy: 0.4814 - val_loss: 2.7310 - val_accuracy: 0.2433\n",
      "Epoch 1736/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3209 - accuracy: 0.4829 - val_loss: 2.7489 - val_accuracy: 0.2433\n",
      "Epoch 1737/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3194 - accuracy: 0.4843 - val_loss: 2.7576 - val_accuracy: 0.2433\n",
      "Epoch 1738/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3210 - accuracy: 0.4814 - val_loss: 2.7733 - val_accuracy: 0.2533\n",
      "Epoch 1739/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3208 - accuracy: 0.4800 - val_loss: 2.7405 - val_accuracy: 0.2400\n",
      "Epoch 1740/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3207 - accuracy: 0.4829 - val_loss: 2.7729 - val_accuracy: 0.2500\n",
      "Epoch 1741/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3206 - accuracy: 0.4857 - val_loss: 2.7087 - val_accuracy: 0.2400\n",
      "Epoch 1742/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3199 - accuracy: 0.4843 - val_loss: 2.7658 - val_accuracy: 0.2500\n",
      "Epoch 1743/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3208 - accuracy: 0.4814 - val_loss: 2.7667 - val_accuracy: 0.2467\n",
      "Epoch 1744/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3204 - accuracy: 0.4771 - val_loss: 2.7543 - val_accuracy: 0.2467\n",
      "Epoch 1745/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3201 - accuracy: 0.4843 - val_loss: 2.7372 - val_accuracy: 0.2400\n",
      "Epoch 1746/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3205 - accuracy: 0.4786 - val_loss: 2.7724 - val_accuracy: 0.2500\n",
      "Epoch 1747/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3201 - accuracy: 0.4814 - val_loss: 2.7602 - val_accuracy: 0.2433\n",
      "Epoch 1748/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3194 - accuracy: 0.4743 - val_loss: 2.7610 - val_accuracy: 0.2400\n",
      "Epoch 1749/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3201 - accuracy: 0.4800 - val_loss: 2.7603 - val_accuracy: 0.2467\n",
      "Epoch 1750/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3192 - accuracy: 0.4814 - val_loss: 2.7131 - val_accuracy: 0.2433\n",
      "Epoch 1751/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3200 - accuracy: 0.4829 - val_loss: 2.7128 - val_accuracy: 0.2433\n",
      "Epoch 1752/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3188 - accuracy: 0.4800 - val_loss: 2.7201 - val_accuracy: 0.2433\n",
      "Epoch 1753/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3199 - accuracy: 0.4771 - val_loss: 2.7706 - val_accuracy: 0.2433\n",
      "Epoch 1754/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3200 - accuracy: 0.4843 - val_loss: 2.7730 - val_accuracy: 0.2433\n",
      "Epoch 1755/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3186 - accuracy: 0.4843 - val_loss: 2.7610 - val_accuracy: 0.2467\n",
      "Epoch 1756/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3196 - accuracy: 0.4771 - val_loss: 2.7295 - val_accuracy: 0.2433\n",
      "Epoch 1757/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3193 - accuracy: 0.4871 - val_loss: 2.7785 - val_accuracy: 0.2467\n",
      "Epoch 1758/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3192 - accuracy: 0.4857 - val_loss: 2.7427 - val_accuracy: 0.2433\n",
      "Epoch 1759/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3191 - accuracy: 0.4814 - val_loss: 2.8140 - val_accuracy: 0.2500\n",
      "Epoch 1760/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3197 - accuracy: 0.4843 - val_loss: 2.7251 - val_accuracy: 0.2467\n",
      "Epoch 1761/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3201 - accuracy: 0.4900 - val_loss: 2.7417 - val_accuracy: 0.2433\n",
      "Epoch 1762/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3190 - accuracy: 0.4814 - val_loss: 2.7799 - val_accuracy: 0.2433\n",
      "Epoch 1763/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3190 - accuracy: 0.4771 - val_loss: 2.7540 - val_accuracy: 0.2400\n",
      "Epoch 1764/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3179 - accuracy: 0.4857 - val_loss: 2.7600 - val_accuracy: 0.2433\n",
      "Epoch 1765/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3197 - accuracy: 0.4800 - val_loss: 2.7545 - val_accuracy: 0.2467\n",
      "Epoch 1766/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3186 - accuracy: 0.4800 - val_loss: 2.7405 - val_accuracy: 0.2433\n",
      "Epoch 1767/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3192 - accuracy: 0.4829 - val_loss: 2.7429 - val_accuracy: 0.2433\n",
      "Epoch 1768/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3189 - accuracy: 0.4843 - val_loss: 2.7533 - val_accuracy: 0.2433\n",
      "Epoch 1769/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3183 - accuracy: 0.4829 - val_loss: 2.7567 - val_accuracy: 0.2467\n",
      "Epoch 1770/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3190 - accuracy: 0.4929 - val_loss: 2.7751 - val_accuracy: 0.2467\n",
      "Epoch 1771/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3186 - accuracy: 0.4843 - val_loss: 2.7471 - val_accuracy: 0.2433\n",
      "Epoch 1772/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3185 - accuracy: 0.4814 - val_loss: 2.7740 - val_accuracy: 0.2467\n",
      "Epoch 1773/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3183 - accuracy: 0.4843 - val_loss: 2.7609 - val_accuracy: 0.2400\n",
      "Epoch 1774/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3187 - accuracy: 0.4900 - val_loss: 2.7597 - val_accuracy: 0.2467\n",
      "Epoch 1775/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3187 - accuracy: 0.4829 - val_loss: 2.7884 - val_accuracy: 0.2533\n",
      "Epoch 1776/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3193 - accuracy: 0.4800 - val_loss: 2.7104 - val_accuracy: 0.2433\n",
      "Epoch 1777/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3178 - accuracy: 0.4871 - val_loss: 2.7617 - val_accuracy: 0.2400\n",
      "Epoch 1778/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3177 - accuracy: 0.4829 - val_loss: 2.7374 - val_accuracy: 0.2400\n",
      "Epoch 1779/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3184 - accuracy: 0.4886 - val_loss: 2.7702 - val_accuracy: 0.2400\n",
      "Epoch 1780/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3184 - accuracy: 0.4814 - val_loss: 2.7890 - val_accuracy: 0.2467\n",
      "Epoch 1781/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3174 - accuracy: 0.4871 - val_loss: 2.7951 - val_accuracy: 0.2467\n",
      "Epoch 1782/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3183 - accuracy: 0.4814 - val_loss: 2.7286 - val_accuracy: 0.2400\n",
      "Epoch 1783/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3176 - accuracy: 0.4914 - val_loss: 2.7833 - val_accuracy: 0.2467\n",
      "Epoch 1784/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3174 - accuracy: 0.4829 - val_loss: 2.7522 - val_accuracy: 0.2367\n",
      "Epoch 1785/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3179 - accuracy: 0.4857 - val_loss: 2.7539 - val_accuracy: 0.2467\n",
      "Epoch 1786/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3182 - accuracy: 0.4843 - val_loss: 2.7619 - val_accuracy: 0.2433\n",
      "Epoch 1787/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3176 - accuracy: 0.4914 - val_loss: 2.7564 - val_accuracy: 0.2433\n",
      "Epoch 1788/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3180 - accuracy: 0.4829 - val_loss: 2.7652 - val_accuracy: 0.2400\n",
      "Epoch 1789/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3178 - accuracy: 0.4843 - val_loss: 2.7345 - val_accuracy: 0.2400\n",
      "Epoch 1790/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3175 - accuracy: 0.4857 - val_loss: 2.7287 - val_accuracy: 0.2400\n",
      "Epoch 1791/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3179 - accuracy: 0.4814 - val_loss: 2.7616 - val_accuracy: 0.2400\n",
      "Epoch 1792/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3168 - accuracy: 0.4814 - val_loss: 2.7972 - val_accuracy: 0.2467\n",
      "Epoch 1793/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3170 - accuracy: 0.4814 - val_loss: 2.7817 - val_accuracy: 0.2467\n",
      "Epoch 1794/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3168 - accuracy: 0.4857 - val_loss: 2.7729 - val_accuracy: 0.2433\n",
      "Epoch 1795/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3173 - accuracy: 0.4814 - val_loss: 2.7766 - val_accuracy: 0.2433\n",
      "Epoch 1796/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3167 - accuracy: 0.4814 - val_loss: 2.8113 - val_accuracy: 0.2533\n",
      "Epoch 1797/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3163 - accuracy: 0.4800 - val_loss: 2.7876 - val_accuracy: 0.2433\n",
      "Epoch 1798/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3176 - accuracy: 0.4871 - val_loss: 2.7636 - val_accuracy: 0.2433\n",
      "Epoch 1799/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3168 - accuracy: 0.4900 - val_loss: 2.8183 - val_accuracy: 0.2467\n",
      "Epoch 1800/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3170 - accuracy: 0.4843 - val_loss: 2.7988 - val_accuracy: 0.2467\n",
      "Epoch 1801/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3162 - accuracy: 0.4857 - val_loss: 2.7613 - val_accuracy: 0.2400\n",
      "Epoch 1802/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3164 - accuracy: 0.4857 - val_loss: 2.7926 - val_accuracy: 0.2467\n",
      "Epoch 1803/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3160 - accuracy: 0.4843 - val_loss: 2.7755 - val_accuracy: 0.2467\n",
      "Epoch 1804/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3167 - accuracy: 0.4886 - val_loss: 2.7658 - val_accuracy: 0.2433\n",
      "Epoch 1805/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3167 - accuracy: 0.4843 - val_loss: 2.7955 - val_accuracy: 0.2467\n",
      "Epoch 1806/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3164 - accuracy: 0.4814 - val_loss: 2.7665 - val_accuracy: 0.2400\n",
      "Epoch 1807/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3162 - accuracy: 0.4800 - val_loss: 2.7949 - val_accuracy: 0.2467\n",
      "Epoch 1808/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3157 - accuracy: 0.4771 - val_loss: 2.7954 - val_accuracy: 0.2500\n",
      "Epoch 1809/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3164 - accuracy: 0.4814 - val_loss: 2.7507 - val_accuracy: 0.2367\n",
      "Epoch 1810/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3163 - accuracy: 0.4843 - val_loss: 2.7758 - val_accuracy: 0.2400\n",
      "Epoch 1811/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3158 - accuracy: 0.4871 - val_loss: 2.7749 - val_accuracy: 0.2433\n",
      "Epoch 1812/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3160 - accuracy: 0.4829 - val_loss: 2.7721 - val_accuracy: 0.2467\n",
      "Epoch 1813/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3169 - accuracy: 0.4771 - val_loss: 2.7732 - val_accuracy: 0.2400\n",
      "Epoch 1814/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3167 - accuracy: 0.4771 - val_loss: 2.7828 - val_accuracy: 0.2467\n",
      "Epoch 1815/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3155 - accuracy: 0.4871 - val_loss: 2.7902 - val_accuracy: 0.2467\n",
      "Epoch 1816/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3148 - accuracy: 0.4857 - val_loss: 2.7706 - val_accuracy: 0.2400\n",
      "Epoch 1817/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3150 - accuracy: 0.4843 - val_loss: 2.7923 - val_accuracy: 0.2433\n",
      "Epoch 1818/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3162 - accuracy: 0.4800 - val_loss: 2.7727 - val_accuracy: 0.2400\n",
      "Epoch 1819/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3158 - accuracy: 0.4871 - val_loss: 2.7900 - val_accuracy: 0.2433\n",
      "Epoch 1820/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3166 - accuracy: 0.4829 - val_loss: 2.7606 - val_accuracy: 0.2400\n",
      "Epoch 1821/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3147 - accuracy: 0.4829 - val_loss: 2.8329 - val_accuracy: 0.2467\n",
      "Epoch 1822/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3144 - accuracy: 0.4857 - val_loss: 2.7680 - val_accuracy: 0.2467\n",
      "Epoch 1823/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3142 - accuracy: 0.4786 - val_loss: 2.8176 - val_accuracy: 0.2433\n",
      "Epoch 1824/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3154 - accuracy: 0.4829 - val_loss: 2.8274 - val_accuracy: 0.2500\n",
      "Epoch 1825/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3146 - accuracy: 0.4814 - val_loss: 2.8094 - val_accuracy: 0.2500\n",
      "Epoch 1826/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3144 - accuracy: 0.4829 - val_loss: 2.7718 - val_accuracy: 0.2400\n",
      "Epoch 1827/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3151 - accuracy: 0.4857 - val_loss: 2.7812 - val_accuracy: 0.2433\n",
      "Epoch 1828/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 94us/step - loss: 1.3131 - accuracy: 0.4843 - val_loss: 2.7838 - val_accuracy: 0.2433\n",
      "Epoch 1829/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3153 - accuracy: 0.4800 - val_loss: 2.7718 - val_accuracy: 0.2433\n",
      "Epoch 1830/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3139 - accuracy: 0.4843 - val_loss: 2.7901 - val_accuracy: 0.2433\n",
      "Epoch 1831/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3138 - accuracy: 0.4871 - val_loss: 2.7782 - val_accuracy: 0.2400\n",
      "Epoch 1832/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3138 - accuracy: 0.4857 - val_loss: 2.7998 - val_accuracy: 0.2467\n",
      "Epoch 1833/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3136 - accuracy: 0.4843 - val_loss: 2.8160 - val_accuracy: 0.2433\n",
      "Epoch 1834/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3137 - accuracy: 0.4814 - val_loss: 2.8138 - val_accuracy: 0.2433\n",
      "Epoch 1835/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3134 - accuracy: 0.4871 - val_loss: 2.7999 - val_accuracy: 0.2433\n",
      "Epoch 1836/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3140 - accuracy: 0.4886 - val_loss: 2.7753 - val_accuracy: 0.2400\n",
      "Epoch 1837/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3136 - accuracy: 0.4843 - val_loss: 2.7887 - val_accuracy: 0.2400\n",
      "Epoch 1838/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3133 - accuracy: 0.4800 - val_loss: 2.7816 - val_accuracy: 0.2400\n",
      "Epoch 1839/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3124 - accuracy: 0.4900 - val_loss: 2.8309 - val_accuracy: 0.2467\n",
      "Epoch 1840/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3137 - accuracy: 0.4900 - val_loss: 2.7936 - val_accuracy: 0.2367\n",
      "Epoch 1841/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3119 - accuracy: 0.4843 - val_loss: 2.7613 - val_accuracy: 0.2433\n",
      "Epoch 1842/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3132 - accuracy: 0.4800 - val_loss: 2.8177 - val_accuracy: 0.2433\n",
      "Epoch 1843/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3129 - accuracy: 0.4857 - val_loss: 2.7970 - val_accuracy: 0.2367\n",
      "Epoch 1844/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3129 - accuracy: 0.4814 - val_loss: 2.8158 - val_accuracy: 0.2500\n",
      "Epoch 1845/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3125 - accuracy: 0.4829 - val_loss: 2.7741 - val_accuracy: 0.2400\n",
      "Epoch 1846/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3129 - accuracy: 0.4886 - val_loss: 2.8062 - val_accuracy: 0.2433\n",
      "Epoch 1847/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3133 - accuracy: 0.4943 - val_loss: 2.7454 - val_accuracy: 0.2467\n",
      "Epoch 1848/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3131 - accuracy: 0.4857 - val_loss: 2.8078 - val_accuracy: 0.2433\n",
      "Epoch 1849/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3129 - accuracy: 0.4886 - val_loss: 2.7887 - val_accuracy: 0.2400\n",
      "Epoch 1850/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3125 - accuracy: 0.4843 - val_loss: 2.8107 - val_accuracy: 0.2400\n",
      "Epoch 1851/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3125 - accuracy: 0.4871 - val_loss: 2.8048 - val_accuracy: 0.2433\n",
      "Epoch 1852/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3127 - accuracy: 0.4886 - val_loss: 2.8206 - val_accuracy: 0.2433\n",
      "Epoch 1853/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3130 - accuracy: 0.4857 - val_loss: 2.7899 - val_accuracy: 0.2400\n",
      "Epoch 1854/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3123 - accuracy: 0.4886 - val_loss: 2.7942 - val_accuracy: 0.2500\n",
      "Epoch 1855/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3122 - accuracy: 0.4857 - val_loss: 2.8018 - val_accuracy: 0.2467\n",
      "Epoch 1856/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3108 - accuracy: 0.4871 - val_loss: 2.7939 - val_accuracy: 0.2467\n",
      "Epoch 1857/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3127 - accuracy: 0.4857 - val_loss: 2.7873 - val_accuracy: 0.2400\n",
      "Epoch 1858/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3124 - accuracy: 0.4857 - val_loss: 2.8183 - val_accuracy: 0.2433\n",
      "Epoch 1859/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3116 - accuracy: 0.4857 - val_loss: 2.8009 - val_accuracy: 0.2367\n",
      "Epoch 1860/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3115 - accuracy: 0.4829 - val_loss: 2.8136 - val_accuracy: 0.2500\n",
      "Epoch 1861/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3121 - accuracy: 0.4957 - val_loss: 2.8175 - val_accuracy: 0.2433\n",
      "Epoch 1862/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3122 - accuracy: 0.4900 - val_loss: 2.7980 - val_accuracy: 0.2400\n",
      "Epoch 1863/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3121 - accuracy: 0.4886 - val_loss: 2.7967 - val_accuracy: 0.2400\n",
      "Epoch 1864/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3112 - accuracy: 0.4886 - val_loss: 2.8054 - val_accuracy: 0.2400\n",
      "Epoch 1865/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3112 - accuracy: 0.4886 - val_loss: 2.8361 - val_accuracy: 0.2467\n",
      "Epoch 1866/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3115 - accuracy: 0.4857 - val_loss: 2.8192 - val_accuracy: 0.2467\n",
      "Epoch 1867/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3118 - accuracy: 0.4886 - val_loss: 2.8251 - val_accuracy: 0.2433\n",
      "Epoch 1868/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3116 - accuracy: 0.4871 - val_loss: 2.8125 - val_accuracy: 0.2333\n",
      "Epoch 1869/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3108 - accuracy: 0.4929 - val_loss: 2.8443 - val_accuracy: 0.2500\n",
      "Epoch 1870/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3118 - accuracy: 0.4829 - val_loss: 2.7841 - val_accuracy: 0.2400\n",
      "Epoch 1871/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3113 - accuracy: 0.4829 - val_loss: 2.7913 - val_accuracy: 0.2400\n",
      "Epoch 1872/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3114 - accuracy: 0.4843 - val_loss: 2.7903 - val_accuracy: 0.2400\n",
      "Epoch 1873/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3111 - accuracy: 0.4871 - val_loss: 2.8482 - val_accuracy: 0.2467\n",
      "Epoch 1874/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3110 - accuracy: 0.4943 - val_loss: 2.8149 - val_accuracy: 0.2467\n",
      "Epoch 1875/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3110 - accuracy: 0.4971 - val_loss: 2.8357 - val_accuracy: 0.2467\n",
      "Epoch 1876/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3108 - accuracy: 0.4771 - val_loss: 2.8073 - val_accuracy: 0.2367\n",
      "Epoch 1877/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3113 - accuracy: 0.4843 - val_loss: 2.7962 - val_accuracy: 0.2467\n",
      "Epoch 1878/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3110 - accuracy: 0.4886 - val_loss: 2.8292 - val_accuracy: 0.2500\n",
      "Epoch 1879/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3105 - accuracy: 0.4886 - val_loss: 2.8224 - val_accuracy: 0.2400\n",
      "Epoch 1880/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3104 - accuracy: 0.4957 - val_loss: 2.8272 - val_accuracy: 0.2467\n",
      "Epoch 1881/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3104 - accuracy: 0.4900 - val_loss: 2.8498 - val_accuracy: 0.2467\n",
      "Epoch 1882/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3106 - accuracy: 0.4786 - val_loss: 2.7938 - val_accuracy: 0.2400\n",
      "Epoch 1883/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3107 - accuracy: 0.4843 - val_loss: 2.8107 - val_accuracy: 0.2433\n",
      "Epoch 1884/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3104 - accuracy: 0.4914 - val_loss: 2.8013 - val_accuracy: 0.2400\n",
      "Epoch 1885/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3099 - accuracy: 0.4857 - val_loss: 2.7881 - val_accuracy: 0.2433\n",
      "Epoch 1886/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3106 - accuracy: 0.4857 - val_loss: 2.8056 - val_accuracy: 0.2433\n",
      "Epoch 1887/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3101 - accuracy: 0.4886 - val_loss: 2.8165 - val_accuracy: 0.2400\n",
      "Epoch 1888/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3091 - accuracy: 0.4900 - val_loss: 2.8411 - val_accuracy: 0.2433\n",
      "Epoch 1889/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3106 - accuracy: 0.4886 - val_loss: 2.7948 - val_accuracy: 0.2467\n",
      "Epoch 1890/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3101 - accuracy: 0.4929 - val_loss: 2.8211 - val_accuracy: 0.2433\n",
      "Epoch 1891/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3102 - accuracy: 0.4900 - val_loss: 2.8212 - val_accuracy: 0.2433\n",
      "Epoch 1892/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3098 - accuracy: 0.4886 - val_loss: 2.8131 - val_accuracy: 0.2433\n",
      "Epoch 1893/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3093 - accuracy: 0.4843 - val_loss: 2.8456 - val_accuracy: 0.2500\n",
      "Epoch 1894/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3097 - accuracy: 0.4871 - val_loss: 2.8119 - val_accuracy: 0.2400\n",
      "Epoch 1895/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3099 - accuracy: 0.4914 - val_loss: 2.8029 - val_accuracy: 0.2433\n",
      "Epoch 1896/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3097 - accuracy: 0.4871 - val_loss: 2.8489 - val_accuracy: 0.2467\n",
      "Epoch 1897/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3096 - accuracy: 0.4914 - val_loss: 2.8088 - val_accuracy: 0.2467\n",
      "Epoch 1898/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3097 - accuracy: 0.4829 - val_loss: 2.7960 - val_accuracy: 0.2433\n",
      "Epoch 1899/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3095 - accuracy: 0.4871 - val_loss: 2.8084 - val_accuracy: 0.2500\n",
      "Epoch 1900/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3092 - accuracy: 0.4914 - val_loss: 2.8463 - val_accuracy: 0.2467\n",
      "Epoch 1901/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3096 - accuracy: 0.4843 - val_loss: 2.8045 - val_accuracy: 0.2433\n",
      "Epoch 1902/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3094 - accuracy: 0.4843 - val_loss: 2.8558 - val_accuracy: 0.2433\n",
      "Epoch 1903/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3084 - accuracy: 0.4886 - val_loss: 2.8097 - val_accuracy: 0.2433\n",
      "Epoch 1904/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3091 - accuracy: 0.4929 - val_loss: 2.8486 - val_accuracy: 0.2500\n",
      "Epoch 1905/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3096 - accuracy: 0.4871 - val_loss: 2.8503 - val_accuracy: 0.2467\n",
      "Epoch 1906/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3101 - accuracy: 0.4914 - val_loss: 2.8367 - val_accuracy: 0.2467\n",
      "Epoch 1907/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3085 - accuracy: 0.4886 - val_loss: 2.8391 - val_accuracy: 0.2500\n",
      "Epoch 1908/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3100 - accuracy: 0.4843 - val_loss: 2.8508 - val_accuracy: 0.2467\n",
      "Epoch 1909/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3083 - accuracy: 0.4829 - val_loss: 2.8309 - val_accuracy: 0.2400\n",
      "Epoch 1910/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3090 - accuracy: 0.4900 - val_loss: 2.8291 - val_accuracy: 0.2400\n",
      "Epoch 1911/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3083 - accuracy: 0.4986 - val_loss: 2.8184 - val_accuracy: 0.2367\n",
      "Epoch 1912/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3087 - accuracy: 0.4886 - val_loss: 2.8391 - val_accuracy: 0.2500\n",
      "Epoch 1913/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3084 - accuracy: 0.4900 - val_loss: 2.8394 - val_accuracy: 0.2400\n",
      "Epoch 1914/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3074 - accuracy: 0.4871 - val_loss: 2.8482 - val_accuracy: 0.2500\n",
      "Epoch 1915/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3086 - accuracy: 0.4857 - val_loss: 2.8231 - val_accuracy: 0.2433\n",
      "Epoch 1916/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3084 - accuracy: 0.4886 - val_loss: 2.8078 - val_accuracy: 0.2400\n",
      "Epoch 1917/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3087 - accuracy: 0.4871 - val_loss: 2.8301 - val_accuracy: 0.2500\n",
      "Epoch 1918/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3084 - accuracy: 0.4929 - val_loss: 2.8409 - val_accuracy: 0.2400\n",
      "Epoch 1919/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3081 - accuracy: 0.4886 - val_loss: 2.8454 - val_accuracy: 0.2400\n",
      "Epoch 1920/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3092 - accuracy: 0.4900 - val_loss: 2.8403 - val_accuracy: 0.2433\n",
      "Epoch 1921/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3079 - accuracy: 0.4929 - val_loss: 2.8347 - val_accuracy: 0.2433\n",
      "Epoch 1922/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3073 - accuracy: 0.4886 - val_loss: 2.8219 - val_accuracy: 0.2467\n",
      "Epoch 1923/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3081 - accuracy: 0.4957 - val_loss: 2.8438 - val_accuracy: 0.2433\n",
      "Epoch 1924/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3076 - accuracy: 0.4843 - val_loss: 2.8003 - val_accuracy: 0.2433\n",
      "Epoch 1925/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3076 - accuracy: 0.4929 - val_loss: 2.8544 - val_accuracy: 0.2400\n",
      "Epoch 1926/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3071 - accuracy: 0.4871 - val_loss: 2.8218 - val_accuracy: 0.2433\n",
      "Epoch 1927/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3075 - accuracy: 0.4914 - val_loss: 2.8277 - val_accuracy: 0.2467\n",
      "Epoch 1928/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3070 - accuracy: 0.4900 - val_loss: 2.8586 - val_accuracy: 0.2467\n",
      "Epoch 1929/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3079 - accuracy: 0.4929 - val_loss: 2.8490 - val_accuracy: 0.2433\n",
      "Epoch 1930/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3082 - accuracy: 0.4829 - val_loss: 2.8390 - val_accuracy: 0.2433\n",
      "Epoch 1931/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3078 - accuracy: 0.4929 - val_loss: 2.8290 - val_accuracy: 0.2400\n",
      "Epoch 1932/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3072 - accuracy: 0.4886 - val_loss: 2.8522 - val_accuracy: 0.2467\n",
      "Epoch 1933/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3068 - accuracy: 0.4929 - val_loss: 2.8398 - val_accuracy: 0.2467\n",
      "Epoch 1934/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3075 - accuracy: 0.4814 - val_loss: 2.8384 - val_accuracy: 0.2500\n",
      "Epoch 1935/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3069 - accuracy: 0.4914 - val_loss: 2.8372 - val_accuracy: 0.2467\n",
      "Epoch 1936/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3071 - accuracy: 0.4886 - val_loss: 2.8738 - val_accuracy: 0.2467\n",
      "Epoch 1937/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3067 - accuracy: 0.4957 - val_loss: 2.8457 - val_accuracy: 0.2467\n",
      "Epoch 1938/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 90us/step - loss: 1.3071 - accuracy: 0.4886 - val_loss: 2.8680 - val_accuracy: 0.2467\n",
      "Epoch 1939/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3071 - accuracy: 0.4929 - val_loss: 2.8414 - val_accuracy: 0.2467\n",
      "Epoch 1940/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3071 - accuracy: 0.4914 - val_loss: 2.8538 - val_accuracy: 0.2467\n",
      "Epoch 1941/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3066 - accuracy: 0.4857 - val_loss: 2.8291 - val_accuracy: 0.2467\n",
      "Epoch 1942/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3066 - accuracy: 0.4914 - val_loss: 2.8601 - val_accuracy: 0.2467\n",
      "Epoch 1943/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3066 - accuracy: 0.4900 - val_loss: 2.8644 - val_accuracy: 0.2467\n",
      "Epoch 1944/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3065 - accuracy: 0.4929 - val_loss: 2.8741 - val_accuracy: 0.2467\n",
      "Epoch 1945/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3064 - accuracy: 0.4929 - val_loss: 2.8441 - val_accuracy: 0.2400\n",
      "Epoch 1946/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3068 - accuracy: 0.4871 - val_loss: 2.8646 - val_accuracy: 0.2500\n",
      "Epoch 1947/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3073 - accuracy: 0.4857 - val_loss: 2.8327 - val_accuracy: 0.2467\n",
      "Epoch 1948/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3059 - accuracy: 0.4914 - val_loss: 2.8601 - val_accuracy: 0.2467\n",
      "Epoch 1949/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3074 - accuracy: 0.4900 - val_loss: 2.8628 - val_accuracy: 0.2433\n",
      "Epoch 1950/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3072 - accuracy: 0.4914 - val_loss: 2.8465 - val_accuracy: 0.2400\n",
      "Epoch 1951/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3056 - accuracy: 0.4857 - val_loss: 2.8831 - val_accuracy: 0.2500\n",
      "Epoch 1952/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3065 - accuracy: 0.4857 - val_loss: 2.8920 - val_accuracy: 0.2467\n",
      "Epoch 1953/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3060 - accuracy: 0.4871 - val_loss: 2.8458 - val_accuracy: 0.2467\n",
      "Epoch 1954/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3061 - accuracy: 0.4929 - val_loss: 2.8430 - val_accuracy: 0.2500\n",
      "Epoch 1955/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3063 - accuracy: 0.4886 - val_loss: 2.8634 - val_accuracy: 0.2433\n",
      "Epoch 1956/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3058 - accuracy: 0.4914 - val_loss: 2.8676 - val_accuracy: 0.2467\n",
      "Epoch 1957/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3057 - accuracy: 0.4886 - val_loss: 2.8187 - val_accuracy: 0.2433\n",
      "Epoch 1958/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3062 - accuracy: 0.4914 - val_loss: 2.8320 - val_accuracy: 0.2433\n",
      "Epoch 1959/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3057 - accuracy: 0.4943 - val_loss: 2.8322 - val_accuracy: 0.2433\n",
      "Epoch 1960/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3060 - accuracy: 0.4971 - val_loss: 2.8572 - val_accuracy: 0.2400\n",
      "Epoch 1961/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3058 - accuracy: 0.4843 - val_loss: 2.8839 - val_accuracy: 0.2467\n",
      "Epoch 1962/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3055 - accuracy: 0.4943 - val_loss: 2.8521 - val_accuracy: 0.2467\n",
      "Epoch 1963/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3049 - accuracy: 0.4900 - val_loss: 2.8646 - val_accuracy: 0.2467\n",
      "Epoch 1964/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3056 - accuracy: 0.4886 - val_loss: 2.8605 - val_accuracy: 0.2400\n",
      "Epoch 1965/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3054 - accuracy: 0.4829 - val_loss: 2.8708 - val_accuracy: 0.2467\n",
      "Epoch 1966/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3055 - accuracy: 0.4900 - val_loss: 2.8691 - val_accuracy: 0.2433\n",
      "Epoch 1967/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3053 - accuracy: 0.4929 - val_loss: 2.8624 - val_accuracy: 0.2433\n",
      "Epoch 1968/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3047 - accuracy: 0.4886 - val_loss: 2.8806 - val_accuracy: 0.2500\n",
      "Epoch 1969/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3059 - accuracy: 0.4943 - val_loss: 2.8855 - val_accuracy: 0.2467\n",
      "Epoch 1970/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3051 - accuracy: 0.4857 - val_loss: 2.8786 - val_accuracy: 0.2467\n",
      "Epoch 1971/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3051 - accuracy: 0.4914 - val_loss: 2.8770 - val_accuracy: 0.2467\n",
      "Epoch 1972/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3040 - accuracy: 0.4900 - val_loss: 2.8643 - val_accuracy: 0.2433\n",
      "Epoch 1973/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3055 - accuracy: 0.4971 - val_loss: 2.8736 - val_accuracy: 0.2467\n",
      "Epoch 1974/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3048 - accuracy: 0.4929 - val_loss: 2.8328 - val_accuracy: 0.2433\n",
      "Epoch 1975/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3050 - accuracy: 0.4929 - val_loss: 2.8568 - val_accuracy: 0.2500\n",
      "Epoch 1976/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3051 - accuracy: 0.4857 - val_loss: 2.8777 - val_accuracy: 0.2467\n",
      "Epoch 1977/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3049 - accuracy: 0.4914 - val_loss: 2.8717 - val_accuracy: 0.2433\n",
      "Epoch 1978/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3052 - accuracy: 0.4943 - val_loss: 2.8666 - val_accuracy: 0.2433\n",
      "Epoch 1979/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3040 - accuracy: 0.4943 - val_loss: 2.8949 - val_accuracy: 0.2467\n",
      "Epoch 1980/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3033 - accuracy: 0.4900 - val_loss: 2.8520 - val_accuracy: 0.2467\n",
      "Epoch 1981/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3044 - accuracy: 0.4900 - val_loss: 2.8652 - val_accuracy: 0.2433\n",
      "Epoch 1982/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3043 - accuracy: 0.4900 - val_loss: 2.8490 - val_accuracy: 0.2500\n",
      "Epoch 1983/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3045 - accuracy: 0.4886 - val_loss: 2.8584 - val_accuracy: 0.2467\n",
      "Epoch 1984/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3045 - accuracy: 0.4943 - val_loss: 2.8657 - val_accuracy: 0.2433\n",
      "Epoch 1985/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3039 - accuracy: 0.4957 - val_loss: 2.8935 - val_accuracy: 0.2467\n",
      "Epoch 1986/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3048 - accuracy: 0.4886 - val_loss: 2.8810 - val_accuracy: 0.2433\n",
      "Epoch 1987/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3042 - accuracy: 0.4957 - val_loss: 2.8605 - val_accuracy: 0.2500\n",
      "Epoch 1988/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3054 - accuracy: 0.4886 - val_loss: 2.9012 - val_accuracy: 0.2467\n",
      "Epoch 1989/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3043 - accuracy: 0.4986 - val_loss: 2.8706 - val_accuracy: 0.2433\n",
      "Epoch 1990/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3037 - accuracy: 0.4857 - val_loss: 2.8657 - val_accuracy: 0.2433\n",
      "Epoch 1991/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3039 - accuracy: 0.4957 - val_loss: 2.8685 - val_accuracy: 0.2433\n",
      "Epoch 1992/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3033 - accuracy: 0.4871 - val_loss: 2.9042 - val_accuracy: 0.2533\n",
      "Epoch 1993/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3037 - accuracy: 0.4914 - val_loss: 2.8293 - val_accuracy: 0.2500\n",
      "Epoch 1994/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3043 - accuracy: 0.4929 - val_loss: 2.8735 - val_accuracy: 0.2467\n",
      "Epoch 1995/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3036 - accuracy: 0.4886 - val_loss: 2.8896 - val_accuracy: 0.2467\n",
      "Epoch 1996/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3034 - accuracy: 0.4914 - val_loss: 2.8969 - val_accuracy: 0.2467\n",
      "Epoch 1997/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3035 - accuracy: 0.4914 - val_loss: 2.8496 - val_accuracy: 0.2433\n",
      "Epoch 1998/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3031 - accuracy: 0.4914 - val_loss: 2.9240 - val_accuracy: 0.2433\n",
      "Epoch 1999/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3040 - accuracy: 0.4900 - val_loss: 2.9074 - val_accuracy: 0.2467\n",
      "Epoch 2000/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3034 - accuracy: 0.4914 - val_loss: 2.8850 - val_accuracy: 0.2467\n",
      "Epoch 2001/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3033 - accuracy: 0.4900 - val_loss: 2.8375 - val_accuracy: 0.2433\n",
      "Epoch 2002/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3039 - accuracy: 0.4914 - val_loss: 2.8816 - val_accuracy: 0.2433\n",
      "Epoch 2003/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3038 - accuracy: 0.4886 - val_loss: 2.9124 - val_accuracy: 0.2433\n",
      "Epoch 2004/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3034 - accuracy: 0.4857 - val_loss: 2.8708 - val_accuracy: 0.2433\n",
      "Epoch 2005/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3029 - accuracy: 0.4900 - val_loss: 2.8974 - val_accuracy: 0.2467\n",
      "Epoch 2006/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3026 - accuracy: 0.4871 - val_loss: 2.9059 - val_accuracy: 0.2467\n",
      "Epoch 2007/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3022 - accuracy: 0.4943 - val_loss: 2.8725 - val_accuracy: 0.2400\n",
      "Epoch 2008/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3024 - accuracy: 0.4914 - val_loss: 2.9234 - val_accuracy: 0.2500\n",
      "Epoch 2009/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3035 - accuracy: 0.4929 - val_loss: 2.8806 - val_accuracy: 0.2400\n",
      "Epoch 2010/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3025 - accuracy: 0.4900 - val_loss: 2.8812 - val_accuracy: 0.2467\n",
      "Epoch 2011/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3033 - accuracy: 0.4943 - val_loss: 2.9064 - val_accuracy: 0.2500\n",
      "Epoch 2012/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3027 - accuracy: 0.4886 - val_loss: 2.8612 - val_accuracy: 0.2467\n",
      "Epoch 2013/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3023 - accuracy: 0.4929 - val_loss: 2.8897 - val_accuracy: 0.2433\n",
      "Epoch 2014/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3021 - accuracy: 0.4971 - val_loss: 2.9538 - val_accuracy: 0.2433\n",
      "Epoch 2015/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3021 - accuracy: 0.4929 - val_loss: 2.8762 - val_accuracy: 0.2467\n",
      "Epoch 2016/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3024 - accuracy: 0.4900 - val_loss: 2.9218 - val_accuracy: 0.2467\n",
      "Epoch 2017/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3022 - accuracy: 0.4957 - val_loss: 2.8549 - val_accuracy: 0.2367\n",
      "Epoch 2018/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3023 - accuracy: 0.4900 - val_loss: 2.9003 - val_accuracy: 0.2467\n",
      "Epoch 2019/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3026 - accuracy: 0.4871 - val_loss: 2.8540 - val_accuracy: 0.2433\n",
      "Epoch 2020/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3025 - accuracy: 0.4943 - val_loss: 2.9057 - val_accuracy: 0.2467\n",
      "Epoch 2021/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3021 - accuracy: 0.4986 - val_loss: 2.9067 - val_accuracy: 0.2467\n",
      "Epoch 2022/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3027 - accuracy: 0.4929 - val_loss: 2.8875 - val_accuracy: 0.2433\n",
      "Epoch 2023/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3020 - accuracy: 0.4943 - val_loss: 2.8703 - val_accuracy: 0.2467\n",
      "Epoch 2024/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3024 - accuracy: 0.4914 - val_loss: 2.9283 - val_accuracy: 0.2433\n",
      "Epoch 2025/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3024 - accuracy: 0.4943 - val_loss: 2.9028 - val_accuracy: 0.2467\n",
      "Epoch 2026/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3018 - accuracy: 0.4971 - val_loss: 2.8720 - val_accuracy: 0.2433\n",
      "Epoch 2027/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3022 - accuracy: 0.4971 - val_loss: 2.8811 - val_accuracy: 0.2400\n",
      "Epoch 2028/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3016 - accuracy: 0.4929 - val_loss: 2.9233 - val_accuracy: 0.2467\n",
      "Epoch 2029/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3013 - accuracy: 0.4971 - val_loss: 2.8877 - val_accuracy: 0.2400\n",
      "Epoch 2030/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3011 - accuracy: 0.4957 - val_loss: 2.9335 - val_accuracy: 0.2433\n",
      "Epoch 2031/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3013 - accuracy: 0.4914 - val_loss: 2.8518 - val_accuracy: 0.2433\n",
      "Epoch 2032/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3018 - accuracy: 0.4929 - val_loss: 2.8966 - val_accuracy: 0.2467\n",
      "Epoch 2033/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3014 - accuracy: 0.4957 - val_loss: 2.9316 - val_accuracy: 0.2467\n",
      "Epoch 2034/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3018 - accuracy: 0.4843 - val_loss: 2.8761 - val_accuracy: 0.2467\n",
      "Epoch 2035/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3012 - accuracy: 0.4943 - val_loss: 2.8715 - val_accuracy: 0.2433\n",
      "Epoch 2036/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3017 - accuracy: 0.4900 - val_loss: 2.8901 - val_accuracy: 0.2500\n",
      "Epoch 2037/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3005 - accuracy: 0.4957 - val_loss: 2.8875 - val_accuracy: 0.2467\n",
      "Epoch 2038/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3009 - accuracy: 0.4914 - val_loss: 2.8858 - val_accuracy: 0.2433\n",
      "Epoch 2039/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3018 - accuracy: 0.4986 - val_loss: 2.9216 - val_accuracy: 0.2500\n",
      "Epoch 2040/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3015 - accuracy: 0.4929 - val_loss: 2.9108 - val_accuracy: 0.2467\n",
      "Epoch 2041/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3005 - accuracy: 0.4943 - val_loss: 2.9133 - val_accuracy: 0.2467\n",
      "Epoch 2042/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3011 - accuracy: 0.4957 - val_loss: 2.9282 - val_accuracy: 0.2467\n",
      "Epoch 2043/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3007 - accuracy: 0.4914 - val_loss: 2.9261 - val_accuracy: 0.2467\n",
      "Epoch 2044/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3010 - accuracy: 0.4914 - val_loss: 2.9057 - val_accuracy: 0.2500\n",
      "Epoch 2045/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3015 - accuracy: 0.4957 - val_loss: 2.9395 - val_accuracy: 0.2433\n",
      "Epoch 2046/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3007 - accuracy: 0.4971 - val_loss: 2.8818 - val_accuracy: 0.2467\n",
      "Epoch 2047/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3000 - accuracy: 0.4929 - val_loss: 2.9029 - val_accuracy: 0.2500\n",
      "Epoch 2048/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 104us/step - loss: 1.3000 - accuracy: 0.4943 - val_loss: 2.8693 - val_accuracy: 0.2433\n",
      "Epoch 2049/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3026 - accuracy: 0.4929 - val_loss: 2.9239 - val_accuracy: 0.2467\n",
      "Epoch 2050/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3009 - accuracy: 0.4900 - val_loss: 2.9248 - val_accuracy: 0.2433\n",
      "Epoch 2051/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3010 - accuracy: 0.4929 - val_loss: 2.8964 - val_accuracy: 0.2400\n",
      "Epoch 2052/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3012 - accuracy: 0.4943 - val_loss: 2.8942 - val_accuracy: 0.2433\n",
      "Epoch 2053/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3008 - accuracy: 0.4900 - val_loss: 2.8887 - val_accuracy: 0.2400\n",
      "Epoch 2054/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3000 - accuracy: 0.4971 - val_loss: 2.9069 - val_accuracy: 0.2433\n",
      "Epoch 2055/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3011 - accuracy: 0.4943 - val_loss: 2.8985 - val_accuracy: 0.2400\n",
      "Epoch 2056/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2995 - accuracy: 0.4986 - val_loss: 2.9264 - val_accuracy: 0.2433\n",
      "Epoch 2057/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3007 - accuracy: 0.4900 - val_loss: 2.9170 - val_accuracy: 0.2467\n",
      "Epoch 2058/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2994 - accuracy: 0.4971 - val_loss: 2.9365 - val_accuracy: 0.2467\n",
      "Epoch 2059/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3001 - accuracy: 0.4929 - val_loss: 2.9158 - val_accuracy: 0.2467\n",
      "Epoch 2060/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2999 - accuracy: 0.4929 - val_loss: 2.9154 - val_accuracy: 0.2467\n",
      "Epoch 2061/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2998 - accuracy: 0.4900 - val_loss: 2.9118 - val_accuracy: 0.2467\n",
      "Epoch 2062/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3000 - accuracy: 0.4914 - val_loss: 2.9181 - val_accuracy: 0.2467\n",
      "Epoch 2063/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2993 - accuracy: 0.4943 - val_loss: 2.9160 - val_accuracy: 0.2467\n",
      "Epoch 2064/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2996 - accuracy: 0.4886 - val_loss: 2.9179 - val_accuracy: 0.2467\n",
      "Epoch 2065/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2999 - accuracy: 0.4943 - val_loss: 2.9116 - val_accuracy: 0.2467\n",
      "Epoch 2066/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2999 - accuracy: 0.4971 - val_loss: 2.9345 - val_accuracy: 0.2433\n",
      "Epoch 2067/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2997 - accuracy: 0.4943 - val_loss: 2.9195 - val_accuracy: 0.2500\n",
      "Epoch 2068/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2996 - accuracy: 0.4929 - val_loss: 2.9196 - val_accuracy: 0.2433\n",
      "Epoch 2069/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2989 - accuracy: 0.4986 - val_loss: 2.9798 - val_accuracy: 0.2467\n",
      "Epoch 2070/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2995 - accuracy: 0.4929 - val_loss: 2.9306 - val_accuracy: 0.2467\n",
      "Epoch 2071/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2994 - accuracy: 0.4929 - val_loss: 2.9406 - val_accuracy: 0.2433\n",
      "Epoch 2072/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2995 - accuracy: 0.4914 - val_loss: 2.9463 - val_accuracy: 0.2433\n",
      "Epoch 2073/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2994 - accuracy: 0.4857 - val_loss: 2.9272 - val_accuracy: 0.2500\n",
      "Epoch 2074/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2990 - accuracy: 0.4971 - val_loss: 2.9164 - val_accuracy: 0.2467\n",
      "Epoch 2075/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2994 - accuracy: 0.4943 - val_loss: 2.9045 - val_accuracy: 0.2467\n",
      "Epoch 2076/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2993 - accuracy: 0.4900 - val_loss: 2.9156 - val_accuracy: 0.2433\n",
      "Epoch 2077/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2988 - accuracy: 0.4929 - val_loss: 2.9379 - val_accuracy: 0.2467\n",
      "Epoch 2078/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2990 - accuracy: 0.4914 - val_loss: 2.9233 - val_accuracy: 0.2400\n",
      "Epoch 2079/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2988 - accuracy: 0.4929 - val_loss: 2.9485 - val_accuracy: 0.2400\n",
      "Epoch 2080/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2992 - accuracy: 0.4943 - val_loss: 2.9444 - val_accuracy: 0.2433\n",
      "Epoch 2081/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2999 - accuracy: 0.4957 - val_loss: 2.9589 - val_accuracy: 0.2467\n",
      "Epoch 2082/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2988 - accuracy: 0.4857 - val_loss: 2.8897 - val_accuracy: 0.2367\n",
      "Epoch 2083/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2994 - accuracy: 0.4943 - val_loss: 2.9204 - val_accuracy: 0.2467\n",
      "Epoch 2084/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2980 - accuracy: 0.4943 - val_loss: 2.9091 - val_accuracy: 0.2533\n",
      "Epoch 2085/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2987 - accuracy: 0.4929 - val_loss: 2.8924 - val_accuracy: 0.2400\n",
      "Epoch 2086/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2982 - accuracy: 0.4914 - val_loss: 2.9158 - val_accuracy: 0.2467\n",
      "Epoch 2087/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2988 - accuracy: 0.4971 - val_loss: 2.9633 - val_accuracy: 0.2500\n",
      "Epoch 2088/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2989 - accuracy: 0.4943 - val_loss: 2.9321 - val_accuracy: 0.2433\n",
      "Epoch 2089/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2991 - accuracy: 0.4914 - val_loss: 2.9388 - val_accuracy: 0.2467\n",
      "Epoch 2090/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2979 - accuracy: 0.4943 - val_loss: 2.9819 - val_accuracy: 0.2433\n",
      "Epoch 2091/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2980 - accuracy: 0.4929 - val_loss: 2.9268 - val_accuracy: 0.2467\n",
      "Epoch 2092/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2981 - accuracy: 0.4943 - val_loss: 2.9507 - val_accuracy: 0.2467\n",
      "Epoch 2093/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2984 - accuracy: 0.4886 - val_loss: 2.9404 - val_accuracy: 0.2467\n",
      "Epoch 2094/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2987 - accuracy: 0.4943 - val_loss: 2.9301 - val_accuracy: 0.2433\n",
      "Epoch 2095/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2974 - accuracy: 0.4971 - val_loss: 2.9619 - val_accuracy: 0.2467\n",
      "Epoch 2096/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2979 - accuracy: 0.4914 - val_loss: 2.9437 - val_accuracy: 0.2467\n",
      "Epoch 2097/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2974 - accuracy: 0.4929 - val_loss: 2.9237 - val_accuracy: 0.2467\n",
      "Epoch 2098/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2968 - accuracy: 0.4943 - val_loss: 2.9134 - val_accuracy: 0.2433\n",
      "Epoch 2099/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2982 - accuracy: 0.4929 - val_loss: 2.9367 - val_accuracy: 0.2467\n",
      "Epoch 2100/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2977 - accuracy: 0.4943 - val_loss: 2.9300 - val_accuracy: 0.2433\n",
      "Epoch 2101/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2982 - accuracy: 0.5000 - val_loss: 2.9465 - val_accuracy: 0.2467\n",
      "Epoch 2102/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2982 - accuracy: 0.4957 - val_loss: 2.9457 - val_accuracy: 0.2433\n",
      "Epoch 2103/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2974 - accuracy: 0.4957 - val_loss: 2.9532 - val_accuracy: 0.2467\n",
      "Epoch 2104/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2977 - accuracy: 0.4971 - val_loss: 2.9145 - val_accuracy: 0.2467\n",
      "Epoch 2105/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2971 - accuracy: 0.4900 - val_loss: 2.9387 - val_accuracy: 0.2500\n",
      "Epoch 2106/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2978 - accuracy: 0.4957 - val_loss: 2.9099 - val_accuracy: 0.2467\n",
      "Epoch 2107/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2973 - accuracy: 0.4900 - val_loss: 2.9215 - val_accuracy: 0.2433\n",
      "Epoch 2108/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2976 - accuracy: 0.4943 - val_loss: 2.9449 - val_accuracy: 0.2467\n",
      "Epoch 2109/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2976 - accuracy: 0.4914 - val_loss: 2.9393 - val_accuracy: 0.2500\n",
      "Epoch 2110/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2986 - accuracy: 0.4971 - val_loss: 2.9343 - val_accuracy: 0.2433\n",
      "Epoch 2111/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2983 - accuracy: 0.4900 - val_loss: 2.9255 - val_accuracy: 0.2433\n",
      "Epoch 2112/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2969 - accuracy: 0.4914 - val_loss: 2.9790 - val_accuracy: 0.2433\n",
      "Epoch 2113/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2976 - accuracy: 0.4943 - val_loss: 2.9396 - val_accuracy: 0.2467\n",
      "Epoch 2114/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2966 - accuracy: 0.4957 - val_loss: 2.9319 - val_accuracy: 0.2433\n",
      "Epoch 2115/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2973 - accuracy: 0.4957 - val_loss: 2.9676 - val_accuracy: 0.2400\n",
      "Epoch 2116/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2970 - accuracy: 0.4986 - val_loss: 2.9529 - val_accuracy: 0.2467\n",
      "Epoch 2117/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2973 - accuracy: 0.4957 - val_loss: 2.9742 - val_accuracy: 0.2467\n",
      "Epoch 2118/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2965 - accuracy: 0.4943 - val_loss: 2.9443 - val_accuracy: 0.2467\n",
      "Epoch 2119/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2968 - accuracy: 0.4929 - val_loss: 2.9473 - val_accuracy: 0.2467\n",
      "Epoch 2120/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2965 - accuracy: 0.4957 - val_loss: 2.9546 - val_accuracy: 0.2467\n",
      "Epoch 2121/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2965 - accuracy: 0.4986 - val_loss: 2.9825 - val_accuracy: 0.2400\n",
      "Epoch 2122/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2968 - accuracy: 0.4971 - val_loss: 2.9642 - val_accuracy: 0.2433\n",
      "Epoch 2123/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2964 - accuracy: 0.4971 - val_loss: 2.9346 - val_accuracy: 0.2433\n",
      "Epoch 2124/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2967 - accuracy: 0.4957 - val_loss: 2.9504 - val_accuracy: 0.2467\n",
      "Epoch 2125/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2961 - accuracy: 0.4986 - val_loss: 2.9483 - val_accuracy: 0.2433\n",
      "Epoch 2126/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2971 - accuracy: 0.4943 - val_loss: 2.9473 - val_accuracy: 0.2433\n",
      "Epoch 2127/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2966 - accuracy: 0.4914 - val_loss: 2.9366 - val_accuracy: 0.2400\n",
      "Epoch 2128/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2964 - accuracy: 0.4971 - val_loss: 2.9706 - val_accuracy: 0.2433\n",
      "Epoch 2129/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2964 - accuracy: 0.4871 - val_loss: 2.9183 - val_accuracy: 0.2433\n",
      "Epoch 2130/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2965 - accuracy: 0.5000 - val_loss: 2.9546 - val_accuracy: 0.2400\n",
      "Epoch 2131/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2964 - accuracy: 0.4914 - val_loss: 2.9450 - val_accuracy: 0.2467\n",
      "Epoch 2132/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2969 - accuracy: 0.4943 - val_loss: 2.9399 - val_accuracy: 0.2400\n",
      "Epoch 2133/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2960 - accuracy: 0.4943 - val_loss: 2.9527 - val_accuracy: 0.2500\n",
      "Epoch 2134/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2963 - accuracy: 0.5000 - val_loss: 2.9459 - val_accuracy: 0.2433\n",
      "Epoch 2135/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2956 - accuracy: 0.4943 - val_loss: 2.9504 - val_accuracy: 0.2467\n",
      "Epoch 2136/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2964 - accuracy: 0.4914 - val_loss: 2.9276 - val_accuracy: 0.2433\n",
      "Epoch 2137/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2958 - accuracy: 0.4986 - val_loss: 2.9637 - val_accuracy: 0.2433\n",
      "Epoch 2138/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2973 - accuracy: 0.4914 - val_loss: 2.9705 - val_accuracy: 0.2467\n",
      "Epoch 2139/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2959 - accuracy: 0.5014 - val_loss: 2.9424 - val_accuracy: 0.2467\n",
      "Epoch 2140/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2955 - accuracy: 0.4914 - val_loss: 2.9643 - val_accuracy: 0.2433\n",
      "Epoch 2141/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2966 - accuracy: 0.4943 - val_loss: 2.9626 - val_accuracy: 0.2467\n",
      "Epoch 2142/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2956 - accuracy: 0.4943 - val_loss: 2.9579 - val_accuracy: 0.2467\n",
      "Epoch 2143/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2959 - accuracy: 0.4957 - val_loss: 2.9831 - val_accuracy: 0.2433\n",
      "Epoch 2144/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2957 - accuracy: 0.4957 - val_loss: 2.9599 - val_accuracy: 0.2467\n",
      "Epoch 2145/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2950 - accuracy: 0.4914 - val_loss: 2.9394 - val_accuracy: 0.2500\n",
      "Epoch 2146/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2946 - accuracy: 0.4914 - val_loss: 2.9126 - val_accuracy: 0.2467\n",
      "Epoch 2147/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2953 - accuracy: 0.5014 - val_loss: 2.9672 - val_accuracy: 0.2433\n",
      "Epoch 2148/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2964 - accuracy: 0.4857 - val_loss: 2.9567 - val_accuracy: 0.2467\n",
      "Epoch 2149/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2947 - accuracy: 0.5000 - val_loss: 2.9089 - val_accuracy: 0.2467\n",
      "Epoch 2150/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2951 - accuracy: 0.4929 - val_loss: 2.9311 - val_accuracy: 0.2533\n",
      "Epoch 2151/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2954 - accuracy: 0.4929 - val_loss: 2.9897 - val_accuracy: 0.2367\n",
      "Epoch 2152/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2947 - accuracy: 0.4914 - val_loss: 2.9873 - val_accuracy: 0.2467\n",
      "Epoch 2153/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2953 - accuracy: 0.4943 - val_loss: 2.9586 - val_accuracy: 0.2467\n",
      "Epoch 2154/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2949 - accuracy: 0.4957 - val_loss: 2.9991 - val_accuracy: 0.2367\n",
      "Epoch 2155/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2951 - accuracy: 0.4971 - val_loss: 2.9910 - val_accuracy: 0.2433\n",
      "Epoch 2156/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2943 - accuracy: 0.4986 - val_loss: 2.9977 - val_accuracy: 0.2433\n",
      "Epoch 2157/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2946 - accuracy: 0.4871 - val_loss: 2.9287 - val_accuracy: 0.2467\n",
      "Epoch 2158/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 93us/step - loss: 1.2944 - accuracy: 0.4971 - val_loss: 3.0044 - val_accuracy: 0.2433\n",
      "Epoch 2159/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2942 - accuracy: 0.4971 - val_loss: 2.9445 - val_accuracy: 0.2467\n",
      "Epoch 2160/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2951 - accuracy: 0.4943 - val_loss: 2.9919 - val_accuracy: 0.2467\n",
      "Epoch 2161/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2946 - accuracy: 0.5014 - val_loss: 2.9727 - val_accuracy: 0.2467\n",
      "Epoch 2162/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2941 - accuracy: 0.4929 - val_loss: 2.9620 - val_accuracy: 0.2400\n",
      "Epoch 2163/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2946 - accuracy: 0.4914 - val_loss: 2.9412 - val_accuracy: 0.2433\n",
      "Epoch 2164/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2953 - accuracy: 0.4986 - val_loss: 2.9747 - val_accuracy: 0.2467\n",
      "Epoch 2165/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2945 - accuracy: 0.4914 - val_loss: 2.9616 - val_accuracy: 0.2500\n",
      "Epoch 2166/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2949 - accuracy: 0.4957 - val_loss: 2.9696 - val_accuracy: 0.2467\n",
      "Epoch 2167/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2942 - accuracy: 0.4943 - val_loss: 2.9640 - val_accuracy: 0.2467\n",
      "Epoch 2168/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2945 - accuracy: 0.5014 - val_loss: 2.9832 - val_accuracy: 0.2433\n",
      "Epoch 2169/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2940 - accuracy: 0.4957 - val_loss: 2.9874 - val_accuracy: 0.2500\n",
      "Epoch 2170/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2939 - accuracy: 0.5000 - val_loss: 2.9851 - val_accuracy: 0.2433\n",
      "Epoch 2171/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2935 - accuracy: 0.5000 - val_loss: 2.9433 - val_accuracy: 0.2533\n",
      "Epoch 2172/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2937 - accuracy: 0.4971 - val_loss: 3.0003 - val_accuracy: 0.2467\n",
      "Epoch 2173/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2931 - accuracy: 0.4971 - val_loss: 2.9833 - val_accuracy: 0.2467\n",
      "Epoch 2174/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2940 - accuracy: 0.5014 - val_loss: 2.9685 - val_accuracy: 0.2400\n",
      "Epoch 2175/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2931 - accuracy: 0.4914 - val_loss: 2.9362 - val_accuracy: 0.2500\n",
      "Epoch 2176/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2936 - accuracy: 0.4957 - val_loss: 2.9328 - val_accuracy: 0.2467\n",
      "Epoch 2177/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2940 - accuracy: 0.4957 - val_loss: 2.9792 - val_accuracy: 0.2533\n",
      "Epoch 2178/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2939 - accuracy: 0.4957 - val_loss: 2.9736 - val_accuracy: 0.2467\n",
      "Epoch 2179/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2930 - accuracy: 0.4986 - val_loss: 2.9691 - val_accuracy: 0.2467\n",
      "Epoch 2180/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2945 - accuracy: 0.4886 - val_loss: 2.9722 - val_accuracy: 0.2467\n",
      "Epoch 2181/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2933 - accuracy: 0.5000 - val_loss: 2.9766 - val_accuracy: 0.2367\n",
      "Epoch 2182/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2934 - accuracy: 0.4971 - val_loss: 2.9911 - val_accuracy: 0.2433\n",
      "Epoch 2183/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2932 - accuracy: 0.4971 - val_loss: 3.0172 - val_accuracy: 0.2433\n",
      "Epoch 2184/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2942 - accuracy: 0.4957 - val_loss: 2.9783 - val_accuracy: 0.2500\n",
      "Epoch 2185/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2927 - accuracy: 0.4929 - val_loss: 2.9729 - val_accuracy: 0.2433\n",
      "Epoch 2186/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2939 - accuracy: 0.4957 - val_loss: 2.9794 - val_accuracy: 0.2533\n",
      "Epoch 2187/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2933 - accuracy: 0.5014 - val_loss: 2.9947 - val_accuracy: 0.2467\n",
      "Epoch 2188/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2945 - accuracy: 0.4986 - val_loss: 3.0096 - val_accuracy: 0.2433\n",
      "Epoch 2189/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2932 - accuracy: 0.4914 - val_loss: 3.0249 - val_accuracy: 0.2433\n",
      "Epoch 2190/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2924 - accuracy: 0.4957 - val_loss: 2.9966 - val_accuracy: 0.2400\n",
      "Epoch 2191/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2927 - accuracy: 0.4900 - val_loss: 2.9930 - val_accuracy: 0.2400\n",
      "Epoch 2192/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2929 - accuracy: 0.4986 - val_loss: 2.9564 - val_accuracy: 0.2433\n",
      "Epoch 2193/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2929 - accuracy: 0.5000 - val_loss: 2.9775 - val_accuracy: 0.2400\n",
      "Epoch 2194/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2934 - accuracy: 0.4986 - val_loss: 3.0012 - val_accuracy: 0.2433\n",
      "Epoch 2195/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2925 - accuracy: 0.4929 - val_loss: 2.9939 - val_accuracy: 0.2433\n",
      "Epoch 2196/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2931 - accuracy: 0.5000 - val_loss: 3.0017 - val_accuracy: 0.2467\n",
      "Epoch 2197/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2928 - accuracy: 0.5014 - val_loss: 2.9959 - val_accuracy: 0.2467\n",
      "Epoch 2198/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2929 - accuracy: 0.4943 - val_loss: 2.9731 - val_accuracy: 0.2433\n",
      "Epoch 2199/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2930 - accuracy: 0.5014 - val_loss: 3.0075 - val_accuracy: 0.2433\n",
      "Epoch 2200/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2931 - accuracy: 0.4957 - val_loss: 2.9801 - val_accuracy: 0.2400\n",
      "Epoch 2201/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2926 - accuracy: 0.4971 - val_loss: 3.0237 - val_accuracy: 0.2500\n",
      "Epoch 2202/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2908 - accuracy: 0.4957 - val_loss: 2.9923 - val_accuracy: 0.2500\n",
      "Epoch 2203/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2929 - accuracy: 0.4929 - val_loss: 3.0029 - val_accuracy: 0.2433\n",
      "Epoch 2204/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2920 - accuracy: 0.4943 - val_loss: 2.9536 - val_accuracy: 0.2367\n",
      "Epoch 2205/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2919 - accuracy: 0.4957 - val_loss: 3.0053 - val_accuracy: 0.2433\n",
      "Epoch 2206/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2924 - accuracy: 0.4971 - val_loss: 2.9827 - val_accuracy: 0.2467\n",
      "Epoch 2207/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2921 - accuracy: 0.4957 - val_loss: 3.0116 - val_accuracy: 0.2433\n",
      "Epoch 2208/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2923 - accuracy: 0.5014 - val_loss: 2.9527 - val_accuracy: 0.2400\n",
      "Epoch 2209/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2917 - accuracy: 0.4943 - val_loss: 2.9438 - val_accuracy: 0.2533\n",
      "Epoch 2210/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2926 - accuracy: 0.4914 - val_loss: 2.9870 - val_accuracy: 0.2467\n",
      "Epoch 2211/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2922 - accuracy: 0.4914 - val_loss: 2.9898 - val_accuracy: 0.2467\n",
      "Epoch 2212/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2917 - accuracy: 0.4986 - val_loss: 3.0150 - val_accuracy: 0.2500\n",
      "Epoch 2213/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2918 - accuracy: 0.4929 - val_loss: 2.9788 - val_accuracy: 0.2400\n",
      "Epoch 2214/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2908 - accuracy: 0.5014 - val_loss: 3.0061 - val_accuracy: 0.2433\n",
      "Epoch 2215/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2919 - accuracy: 0.4971 - val_loss: 2.9813 - val_accuracy: 0.2433\n",
      "Epoch 2216/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2924 - accuracy: 0.4929 - val_loss: 2.9775 - val_accuracy: 0.2433\n",
      "Epoch 2217/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2916 - accuracy: 0.4957 - val_loss: 2.9995 - val_accuracy: 0.2467\n",
      "Epoch 2218/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2913 - accuracy: 0.5043 - val_loss: 3.0070 - val_accuracy: 0.2367\n",
      "Epoch 2219/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2918 - accuracy: 0.4971 - val_loss: 2.9868 - val_accuracy: 0.2433\n",
      "Epoch 2220/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2905 - accuracy: 0.5014 - val_loss: 2.9751 - val_accuracy: 0.2500\n",
      "Epoch 2221/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2909 - accuracy: 0.5057 - val_loss: 2.9880 - val_accuracy: 0.2533\n",
      "Epoch 2222/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2930 - accuracy: 0.4943 - val_loss: 2.9567 - val_accuracy: 0.2433\n",
      "Epoch 2223/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2917 - accuracy: 0.4986 - val_loss: 3.0000 - val_accuracy: 0.2533\n",
      "Epoch 2224/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2912 - accuracy: 0.4971 - val_loss: 3.0005 - val_accuracy: 0.2467\n",
      "Epoch 2225/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2907 - accuracy: 0.4971 - val_loss: 2.9930 - val_accuracy: 0.2500\n",
      "Epoch 2226/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2911 - accuracy: 0.4971 - val_loss: 3.0288 - val_accuracy: 0.2500\n",
      "Epoch 2227/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2912 - accuracy: 0.5014 - val_loss: 2.9850 - val_accuracy: 0.2433\n",
      "Epoch 2228/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2913 - accuracy: 0.4943 - val_loss: 3.0042 - val_accuracy: 0.2500\n",
      "Epoch 2229/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2908 - accuracy: 0.5043 - val_loss: 2.9709 - val_accuracy: 0.2400\n",
      "Epoch 2230/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2913 - accuracy: 0.5029 - val_loss: 2.9943 - val_accuracy: 0.2433\n",
      "Epoch 2231/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2905 - accuracy: 0.5014 - val_loss: 2.9890 - val_accuracy: 0.2500\n",
      "Epoch 2232/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2912 - accuracy: 0.4957 - val_loss: 3.0006 - val_accuracy: 0.2467\n",
      "Epoch 2233/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2909 - accuracy: 0.4914 - val_loss: 3.0033 - val_accuracy: 0.2500\n",
      "Epoch 2234/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2911 - accuracy: 0.4971 - val_loss: 2.9738 - val_accuracy: 0.2433\n",
      "Epoch 2235/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2904 - accuracy: 0.5014 - val_loss: 3.0174 - val_accuracy: 0.2433\n",
      "Epoch 2236/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2903 - accuracy: 0.4971 - val_loss: 2.9764 - val_accuracy: 0.2400\n",
      "Epoch 2237/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2906 - accuracy: 0.4986 - val_loss: 3.0356 - val_accuracy: 0.2400\n",
      "Epoch 2238/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2909 - accuracy: 0.4986 - val_loss: 3.0531 - val_accuracy: 0.2367\n",
      "Epoch 2239/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2900 - accuracy: 0.4943 - val_loss: 2.9887 - val_accuracy: 0.2567\n",
      "Epoch 2240/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2908 - accuracy: 0.5000 - val_loss: 3.0257 - val_accuracy: 0.2433\n",
      "Epoch 2241/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2909 - accuracy: 0.4957 - val_loss: 2.9856 - val_accuracy: 0.2467\n",
      "Epoch 2242/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2901 - accuracy: 0.4971 - val_loss: 3.0020 - val_accuracy: 0.2467\n",
      "Epoch 2243/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2903 - accuracy: 0.4971 - val_loss: 3.0035 - val_accuracy: 0.2467\n",
      "Epoch 2244/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2904 - accuracy: 0.4957 - val_loss: 2.9939 - val_accuracy: 0.2433\n",
      "Epoch 2245/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2894 - accuracy: 0.5014 - val_loss: 3.0497 - val_accuracy: 0.2433\n",
      "Epoch 2246/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2898 - accuracy: 0.5000 - val_loss: 3.0106 - val_accuracy: 0.2433\n",
      "Epoch 2247/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2900 - accuracy: 0.4971 - val_loss: 3.0019 - val_accuracy: 0.2467\n",
      "Epoch 2248/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2903 - accuracy: 0.4943 - val_loss: 3.0819 - val_accuracy: 0.2367\n",
      "Epoch 2249/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2910 - accuracy: 0.4986 - val_loss: 3.0042 - val_accuracy: 0.2533\n",
      "Epoch 2250/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2896 - accuracy: 0.4986 - val_loss: 2.9994 - val_accuracy: 0.2467\n",
      "Epoch 2251/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2908 - accuracy: 0.4929 - val_loss: 3.0059 - val_accuracy: 0.2467\n",
      "Epoch 2252/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2899 - accuracy: 0.4957 - val_loss: 2.9869 - val_accuracy: 0.2400\n",
      "Epoch 2253/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2888 - accuracy: 0.4957 - val_loss: 3.0356 - val_accuracy: 0.2467\n",
      "Epoch 2254/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2902 - accuracy: 0.4943 - val_loss: 3.0290 - val_accuracy: 0.2500\n",
      "Epoch 2255/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2895 - accuracy: 0.4986 - val_loss: 3.0367 - val_accuracy: 0.2400\n",
      "Epoch 2256/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2899 - accuracy: 0.4986 - val_loss: 3.0064 - val_accuracy: 0.2400\n",
      "Epoch 2257/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2898 - accuracy: 0.5000 - val_loss: 3.0487 - val_accuracy: 0.2367\n",
      "Epoch 2258/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2894 - accuracy: 0.5029 - val_loss: 2.9942 - val_accuracy: 0.2500\n",
      "Epoch 2259/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2886 - accuracy: 0.5014 - val_loss: 3.0578 - val_accuracy: 0.2433\n",
      "Epoch 2260/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2896 - accuracy: 0.4957 - val_loss: 3.0301 - val_accuracy: 0.2500\n",
      "Epoch 2261/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2889 - accuracy: 0.4957 - val_loss: 3.0184 - val_accuracy: 0.2433\n",
      "Epoch 2262/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2894 - accuracy: 0.5057 - val_loss: 3.0172 - val_accuracy: 0.2433\n",
      "Epoch 2263/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2893 - accuracy: 0.4971 - val_loss: 3.0454 - val_accuracy: 0.2367\n",
      "Epoch 2264/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2892 - accuracy: 0.5000 - val_loss: 3.0688 - val_accuracy: 0.2400\n",
      "Epoch 2265/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2898 - accuracy: 0.4971 - val_loss: 3.0117 - val_accuracy: 0.2467\n",
      "Epoch 2266/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2890 - accuracy: 0.5014 - val_loss: 3.0649 - val_accuracy: 0.2400\n",
      "Epoch 2267/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2899 - accuracy: 0.4929 - val_loss: 3.0009 - val_accuracy: 0.2433\n",
      "Epoch 2268/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 90us/step - loss: 1.2891 - accuracy: 0.4986 - val_loss: 2.9907 - val_accuracy: 0.2433\n",
      "Epoch 2269/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2879 - accuracy: 0.4971 - val_loss: 3.0618 - val_accuracy: 0.2500\n",
      "Epoch 2270/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2895 - accuracy: 0.5014 - val_loss: 3.0078 - val_accuracy: 0.2533\n",
      "Epoch 2271/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2893 - accuracy: 0.4929 - val_loss: 3.0545 - val_accuracy: 0.2433\n",
      "Epoch 2272/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2883 - accuracy: 0.4971 - val_loss: 3.0627 - val_accuracy: 0.2433\n",
      "Epoch 2273/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2890 - accuracy: 0.4971 - val_loss: 3.0107 - val_accuracy: 0.2433\n",
      "Epoch 2274/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2892 - accuracy: 0.4957 - val_loss: 3.0373 - val_accuracy: 0.2533\n",
      "Epoch 2275/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2885 - accuracy: 0.5014 - val_loss: 3.0313 - val_accuracy: 0.2433\n",
      "Epoch 2276/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2889 - accuracy: 0.4957 - val_loss: 3.0383 - val_accuracy: 0.2467\n",
      "Epoch 2277/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2895 - accuracy: 0.4957 - val_loss: 3.0362 - val_accuracy: 0.2400\n",
      "Epoch 2278/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2883 - accuracy: 0.4914 - val_loss: 3.0252 - val_accuracy: 0.2433\n",
      "Epoch 2279/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2885 - accuracy: 0.4929 - val_loss: 3.0419 - val_accuracy: 0.2400\n",
      "Epoch 2280/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2882 - accuracy: 0.4943 - val_loss: 3.0568 - val_accuracy: 0.2333\n",
      "Epoch 2281/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2872 - accuracy: 0.5000 - val_loss: 3.0381 - val_accuracy: 0.2500\n",
      "Epoch 2282/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2883 - accuracy: 0.4943 - val_loss: 3.0309 - val_accuracy: 0.2467\n",
      "Epoch 2283/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2874 - accuracy: 0.5000 - val_loss: 2.9868 - val_accuracy: 0.2500\n",
      "Epoch 2284/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2892 - accuracy: 0.5014 - val_loss: 3.0288 - val_accuracy: 0.2533\n",
      "Epoch 2285/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2895 - accuracy: 0.4914 - val_loss: 3.0528 - val_accuracy: 0.2400\n",
      "Epoch 2286/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2882 - accuracy: 0.4971 - val_loss: 3.0373 - val_accuracy: 0.2467\n",
      "Epoch 2287/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2886 - accuracy: 0.4943 - val_loss: 3.0176 - val_accuracy: 0.2400\n",
      "Epoch 2288/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2885 - accuracy: 0.5000 - val_loss: 3.0210 - val_accuracy: 0.2433\n",
      "Epoch 2289/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2888 - accuracy: 0.5029 - val_loss: 3.0571 - val_accuracy: 0.2467\n",
      "Epoch 2290/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2882 - accuracy: 0.4943 - val_loss: 3.0391 - val_accuracy: 0.2400\n",
      "Epoch 2291/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2880 - accuracy: 0.4971 - val_loss: 3.0480 - val_accuracy: 0.2433\n",
      "Epoch 2292/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2874 - accuracy: 0.5029 - val_loss: 3.0390 - val_accuracy: 0.2400\n",
      "Epoch 2293/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2876 - accuracy: 0.5014 - val_loss: 3.0286 - val_accuracy: 0.2467\n",
      "Epoch 2294/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2877 - accuracy: 0.5043 - val_loss: 3.0477 - val_accuracy: 0.2500\n",
      "Epoch 2295/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2881 - accuracy: 0.4943 - val_loss: 3.0455 - val_accuracy: 0.2400\n",
      "Epoch 2296/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2880 - accuracy: 0.4971 - val_loss: 3.0204 - val_accuracy: 0.2467\n",
      "Epoch 2297/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2871 - accuracy: 0.4957 - val_loss: 3.0416 - val_accuracy: 0.2433\n",
      "Epoch 2298/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2871 - accuracy: 0.5000 - val_loss: 3.0597 - val_accuracy: 0.2467\n",
      "Epoch 2299/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2879 - accuracy: 0.5057 - val_loss: 3.0562 - val_accuracy: 0.2500\n",
      "Epoch 2300/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2869 - accuracy: 0.5014 - val_loss: 3.0270 - val_accuracy: 0.2367\n",
      "Epoch 2301/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2885 - accuracy: 0.4943 - val_loss: 3.0287 - val_accuracy: 0.2433\n",
      "Epoch 2302/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2873 - accuracy: 0.4986 - val_loss: 3.0734 - val_accuracy: 0.2433\n",
      "Epoch 2303/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2873 - accuracy: 0.4971 - val_loss: 3.0177 - val_accuracy: 0.2367\n",
      "Epoch 2304/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2878 - accuracy: 0.5000 - val_loss: 3.0454 - val_accuracy: 0.2533\n",
      "Epoch 2305/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2870 - accuracy: 0.4943 - val_loss: 3.1095 - val_accuracy: 0.2433\n",
      "Epoch 2306/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2878 - accuracy: 0.5000 - val_loss: 2.9850 - val_accuracy: 0.2400\n",
      "Epoch 2307/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2875 - accuracy: 0.5014 - val_loss: 3.0265 - val_accuracy: 0.2433\n",
      "Epoch 2308/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2874 - accuracy: 0.5014 - val_loss: 3.0221 - val_accuracy: 0.2500\n",
      "Epoch 2309/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2874 - accuracy: 0.4943 - val_loss: 3.0661 - val_accuracy: 0.2500\n",
      "Epoch 2310/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2868 - accuracy: 0.4986 - val_loss: 3.0606 - val_accuracy: 0.2400\n",
      "Epoch 2311/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2870 - accuracy: 0.4914 - val_loss: 3.0431 - val_accuracy: 0.2433\n",
      "Epoch 2312/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2867 - accuracy: 0.4986 - val_loss: 3.0720 - val_accuracy: 0.2400\n",
      "Epoch 2313/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2864 - accuracy: 0.4971 - val_loss: 3.0546 - val_accuracy: 0.2500\n",
      "Epoch 2314/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2877 - accuracy: 0.4986 - val_loss: 3.0405 - val_accuracy: 0.2433\n",
      "Epoch 2315/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2871 - accuracy: 0.5014 - val_loss: 3.0297 - val_accuracy: 0.2400\n",
      "Epoch 2316/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2867 - accuracy: 0.4943 - val_loss: 3.0755 - val_accuracy: 0.2367\n",
      "Epoch 2317/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2853 - accuracy: 0.5014 - val_loss: 3.0473 - val_accuracy: 0.2500\n",
      "Epoch 2318/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2869 - accuracy: 0.5000 - val_loss: 3.0520 - val_accuracy: 0.2433\n",
      "Epoch 2319/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2869 - accuracy: 0.4943 - val_loss: 3.0260 - val_accuracy: 0.2400\n",
      "Epoch 2320/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2868 - accuracy: 0.4943 - val_loss: 3.0513 - val_accuracy: 0.2533\n",
      "Epoch 2321/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2864 - accuracy: 0.5000 - val_loss: 3.0604 - val_accuracy: 0.2400\n",
      "Epoch 2322/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2866 - accuracy: 0.4957 - val_loss: 3.0595 - val_accuracy: 0.2400\n",
      "Epoch 2323/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2866 - accuracy: 0.5000 - val_loss: 3.0060 - val_accuracy: 0.2500\n",
      "Epoch 2324/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2865 - accuracy: 0.5000 - val_loss: 3.0846 - val_accuracy: 0.2400\n",
      "Epoch 2325/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2866 - accuracy: 0.4943 - val_loss: 3.0392 - val_accuracy: 0.2467\n",
      "Epoch 2326/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2867 - accuracy: 0.5000 - val_loss: 3.0619 - val_accuracy: 0.2433\n",
      "Epoch 2327/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2865 - accuracy: 0.5043 - val_loss: 3.0423 - val_accuracy: 0.2367\n",
      "Epoch 2328/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2865 - accuracy: 0.4971 - val_loss: 3.0824 - val_accuracy: 0.2333\n",
      "Epoch 2329/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2867 - accuracy: 0.4986 - val_loss: 3.0841 - val_accuracy: 0.2367\n",
      "Epoch 2330/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2861 - accuracy: 0.5014 - val_loss: 3.0891 - val_accuracy: 0.2467\n",
      "Epoch 2331/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2855 - accuracy: 0.5014 - val_loss: 3.0540 - val_accuracy: 0.2500\n",
      "Epoch 2332/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2870 - accuracy: 0.4986 - val_loss: 3.0503 - val_accuracy: 0.2533\n",
      "Epoch 2333/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2861 - accuracy: 0.5029 - val_loss: 3.0665 - val_accuracy: 0.2433\n",
      "Epoch 2334/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2863 - accuracy: 0.4971 - val_loss: 3.0518 - val_accuracy: 0.2467\n",
      "Epoch 2335/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2850 - accuracy: 0.5029 - val_loss: 3.0615 - val_accuracy: 0.2367\n",
      "Epoch 2336/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2858 - accuracy: 0.4914 - val_loss: 3.0845 - val_accuracy: 0.2467\n",
      "Epoch 2337/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2875 - accuracy: 0.4986 - val_loss: 3.0611 - val_accuracy: 0.2433\n",
      "Epoch 2338/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2860 - accuracy: 0.4943 - val_loss: 3.0657 - val_accuracy: 0.2467\n",
      "Epoch 2339/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2855 - accuracy: 0.4943 - val_loss: 3.0896 - val_accuracy: 0.2433\n",
      "Epoch 2340/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2853 - accuracy: 0.4957 - val_loss: 3.0997 - val_accuracy: 0.2467\n",
      "Epoch 2341/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2857 - accuracy: 0.4943 - val_loss: 3.0681 - val_accuracy: 0.2500\n",
      "Epoch 2342/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2857 - accuracy: 0.4986 - val_loss: 3.0439 - val_accuracy: 0.2500\n",
      "Epoch 2343/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2856 - accuracy: 0.5029 - val_loss: 3.0690 - val_accuracy: 0.2500\n",
      "Epoch 2344/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2852 - accuracy: 0.4971 - val_loss: 3.0570 - val_accuracy: 0.2500\n",
      "Epoch 2345/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2856 - accuracy: 0.5029 - val_loss: 3.0680 - val_accuracy: 0.2533\n",
      "Epoch 2346/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2858 - accuracy: 0.5000 - val_loss: 3.0885 - val_accuracy: 0.2433\n",
      "Epoch 2347/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2856 - accuracy: 0.5000 - val_loss: 3.0657 - val_accuracy: 0.2467\n",
      "Epoch 2348/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2848 - accuracy: 0.5014 - val_loss: 3.0438 - val_accuracy: 0.2433\n",
      "Epoch 2349/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2855 - accuracy: 0.4957 - val_loss: 3.0639 - val_accuracy: 0.2500\n",
      "Epoch 2350/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2845 - accuracy: 0.4929 - val_loss: 3.0773 - val_accuracy: 0.2533\n",
      "Epoch 2351/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2854 - accuracy: 0.4971 - val_loss: 3.0739 - val_accuracy: 0.2433\n",
      "Epoch 2352/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2866 - accuracy: 0.4971 - val_loss: 3.0754 - val_accuracy: 0.2467\n",
      "Epoch 2353/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2848 - accuracy: 0.4986 - val_loss: 3.0475 - val_accuracy: 0.2500\n",
      "Epoch 2354/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2845 - accuracy: 0.4971 - val_loss: 3.0899 - val_accuracy: 0.2300\n",
      "Epoch 2355/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2850 - accuracy: 0.4986 - val_loss: 3.0844 - val_accuracy: 0.2367\n",
      "Epoch 2356/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2842 - accuracy: 0.4971 - val_loss: 3.0599 - val_accuracy: 0.2433\n",
      "Epoch 2357/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2851 - accuracy: 0.4986 - val_loss: 3.0903 - val_accuracy: 0.2367\n",
      "Epoch 2358/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2850 - accuracy: 0.4971 - val_loss: 3.0877 - val_accuracy: 0.2400\n",
      "Epoch 2359/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2852 - accuracy: 0.5029 - val_loss: 3.0643 - val_accuracy: 0.2533\n",
      "Epoch 2360/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2846 - accuracy: 0.4957 - val_loss: 3.0870 - val_accuracy: 0.2400\n",
      "Epoch 2361/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2851 - accuracy: 0.5014 - val_loss: 3.0751 - val_accuracy: 0.2400\n",
      "Epoch 2362/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2846 - accuracy: 0.4957 - val_loss: 3.0374 - val_accuracy: 0.2467\n",
      "Epoch 2363/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2837 - accuracy: 0.5014 - val_loss: 3.0564 - val_accuracy: 0.2433\n",
      "Epoch 2364/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2844 - accuracy: 0.5029 - val_loss: 3.0695 - val_accuracy: 0.2367\n",
      "Epoch 2365/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2838 - accuracy: 0.5000 - val_loss: 3.1309 - val_accuracy: 0.2467\n",
      "Epoch 2366/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2843 - accuracy: 0.5043 - val_loss: 3.0905 - val_accuracy: 0.2300\n",
      "Epoch 2367/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2844 - accuracy: 0.4986 - val_loss: 3.0719 - val_accuracy: 0.2333\n",
      "Epoch 2368/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2848 - accuracy: 0.5043 - val_loss: 3.0823 - val_accuracy: 0.2333\n",
      "Epoch 2369/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2842 - accuracy: 0.5000 - val_loss: 3.0686 - val_accuracy: 0.2400\n",
      "Epoch 2370/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2830 - accuracy: 0.5029 - val_loss: 3.0698 - val_accuracy: 0.2467\n",
      "Epoch 2371/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2847 - accuracy: 0.5000 - val_loss: 3.0548 - val_accuracy: 0.2533\n",
      "Epoch 2372/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2836 - accuracy: 0.5000 - val_loss: 3.0844 - val_accuracy: 0.2433\n",
      "Epoch 2373/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2851 - accuracy: 0.4929 - val_loss: 3.1075 - val_accuracy: 0.2467\n",
      "Epoch 2374/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2840 - accuracy: 0.5014 - val_loss: 3.1001 - val_accuracy: 0.2367\n",
      "Epoch 2375/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2842 - accuracy: 0.4957 - val_loss: 3.0825 - val_accuracy: 0.2467\n",
      "Epoch 2376/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2841 - accuracy: 0.5014 - val_loss: 3.0905 - val_accuracy: 0.2433\n",
      "Epoch 2377/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2842 - accuracy: 0.4943 - val_loss: 3.0604 - val_accuracy: 0.2433\n",
      "Epoch 2378/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 97us/step - loss: 1.2836 - accuracy: 0.5014 - val_loss: 3.0401 - val_accuracy: 0.2467\n",
      "Epoch 2379/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2840 - accuracy: 0.5000 - val_loss: 3.0907 - val_accuracy: 0.2433\n",
      "Epoch 2380/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2832 - accuracy: 0.5014 - val_loss: 3.0667 - val_accuracy: 0.2467\n",
      "Epoch 2381/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2839 - accuracy: 0.5057 - val_loss: 3.0906 - val_accuracy: 0.2500\n",
      "Epoch 2382/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2836 - accuracy: 0.5014 - val_loss: 3.0918 - val_accuracy: 0.2467\n",
      "Epoch 2383/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2837 - accuracy: 0.5000 - val_loss: 3.0909 - val_accuracy: 0.2433\n",
      "Epoch 2384/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2835 - accuracy: 0.4971 - val_loss: 3.0886 - val_accuracy: 0.2467\n",
      "Epoch 2385/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2835 - accuracy: 0.5029 - val_loss: 3.1000 - val_accuracy: 0.2500\n",
      "Epoch 2386/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2828 - accuracy: 0.5014 - val_loss: 3.0926 - val_accuracy: 0.2433\n",
      "Epoch 2387/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2834 - accuracy: 0.5029 - val_loss: 3.0636 - val_accuracy: 0.2500\n",
      "Epoch 2388/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2831 - accuracy: 0.5029 - val_loss: 3.1069 - val_accuracy: 0.2400\n",
      "Epoch 2389/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2837 - accuracy: 0.5000 - val_loss: 3.0696 - val_accuracy: 0.2367\n",
      "Epoch 2390/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2831 - accuracy: 0.4914 - val_loss: 3.1220 - val_accuracy: 0.2433\n",
      "Epoch 2391/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2830 - accuracy: 0.4986 - val_loss: 3.1081 - val_accuracy: 0.2467\n",
      "Epoch 2392/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2842 - accuracy: 0.5000 - val_loss: 3.0988 - val_accuracy: 0.2433\n",
      "Epoch 2393/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2829 - accuracy: 0.5014 - val_loss: 3.0932 - val_accuracy: 0.2467\n",
      "Epoch 2394/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2833 - accuracy: 0.5057 - val_loss: 3.1029 - val_accuracy: 0.2467\n",
      "Epoch 2395/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2830 - accuracy: 0.4986 - val_loss: 3.1141 - val_accuracy: 0.2433\n",
      "Epoch 2396/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2828 - accuracy: 0.5043 - val_loss: 3.1331 - val_accuracy: 0.2433\n",
      "Epoch 2397/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2828 - accuracy: 0.5029 - val_loss: 3.1119 - val_accuracy: 0.2433\n",
      "Epoch 2398/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2829 - accuracy: 0.5071 - val_loss: 3.0591 - val_accuracy: 0.2500\n",
      "Epoch 2399/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2828 - accuracy: 0.5029 - val_loss: 3.1394 - val_accuracy: 0.2433\n",
      "Epoch 2400/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2825 - accuracy: 0.5000 - val_loss: 3.1111 - val_accuracy: 0.2433\n",
      "Epoch 2401/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2824 - accuracy: 0.4986 - val_loss: 3.1263 - val_accuracy: 0.2433\n",
      "Epoch 2402/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2838 - accuracy: 0.4943 - val_loss: 3.0616 - val_accuracy: 0.2433\n",
      "Epoch 2403/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2829 - accuracy: 0.4986 - val_loss: 3.0919 - val_accuracy: 0.2467\n",
      "Epoch 2404/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2819 - accuracy: 0.5014 - val_loss: 3.0945 - val_accuracy: 0.2500\n",
      "Epoch 2405/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2833 - accuracy: 0.5029 - val_loss: 3.0704 - val_accuracy: 0.2467\n",
      "Epoch 2406/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2828 - accuracy: 0.5000 - val_loss: 3.0973 - val_accuracy: 0.2467\n",
      "Epoch 2407/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2820 - accuracy: 0.5043 - val_loss: 3.0906 - val_accuracy: 0.2367\n",
      "Epoch 2408/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2819 - accuracy: 0.5057 - val_loss: 3.1130 - val_accuracy: 0.2500\n",
      "Epoch 2409/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2827 - accuracy: 0.4986 - val_loss: 3.0946 - val_accuracy: 0.2467\n",
      "Epoch 2410/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2820 - accuracy: 0.4986 - val_loss: 3.1220 - val_accuracy: 0.2367\n",
      "Epoch 2411/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2821 - accuracy: 0.5029 - val_loss: 3.0868 - val_accuracy: 0.2400\n",
      "Epoch 2412/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2825 - accuracy: 0.5029 - val_loss: 3.1544 - val_accuracy: 0.2467\n",
      "Epoch 2413/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2825 - accuracy: 0.4971 - val_loss: 3.1132 - val_accuracy: 0.2367\n",
      "Epoch 2414/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2823 - accuracy: 0.4971 - val_loss: 3.1163 - val_accuracy: 0.2400\n",
      "Epoch 2415/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2826 - accuracy: 0.5014 - val_loss: 3.1122 - val_accuracy: 0.2433\n",
      "Epoch 2416/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2818 - accuracy: 0.4971 - val_loss: 3.0875 - val_accuracy: 0.2400\n",
      "Epoch 2417/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2824 - accuracy: 0.4957 - val_loss: 3.1102 - val_accuracy: 0.2433\n",
      "Epoch 2418/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2825 - accuracy: 0.5000 - val_loss: 3.1335 - val_accuracy: 0.2300\n",
      "Epoch 2419/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2819 - accuracy: 0.4986 - val_loss: 3.0971 - val_accuracy: 0.2500\n",
      "Epoch 2420/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2818 - accuracy: 0.5029 - val_loss: 3.0733 - val_accuracy: 0.2400\n",
      "Epoch 2421/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2825 - accuracy: 0.4986 - val_loss: 3.0775 - val_accuracy: 0.2367\n",
      "Epoch 2422/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2817 - accuracy: 0.5043 - val_loss: 3.1085 - val_accuracy: 0.2367\n",
      "Epoch 2423/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2820 - accuracy: 0.5029 - val_loss: 3.1343 - val_accuracy: 0.2433\n",
      "Epoch 2424/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2816 - accuracy: 0.5014 - val_loss: 3.0903 - val_accuracy: 0.2467\n",
      "Epoch 2425/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2820 - accuracy: 0.5029 - val_loss: 3.1120 - val_accuracy: 0.2400\n",
      "Epoch 2426/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2808 - accuracy: 0.5057 - val_loss: 3.0776 - val_accuracy: 0.2400\n",
      "Epoch 2427/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2817 - accuracy: 0.4986 - val_loss: 3.1057 - val_accuracy: 0.2367\n",
      "Epoch 2428/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2818 - accuracy: 0.5057 - val_loss: 3.0877 - val_accuracy: 0.2400\n",
      "Epoch 2429/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2811 - accuracy: 0.5029 - val_loss: 3.1109 - val_accuracy: 0.2433\n",
      "Epoch 2430/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2812 - accuracy: 0.4986 - val_loss: 3.0771 - val_accuracy: 0.2433\n",
      "Epoch 2431/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2810 - accuracy: 0.5043 - val_loss: 3.1098 - val_accuracy: 0.2400\n",
      "Epoch 2432/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2812 - accuracy: 0.5071 - val_loss: 3.1246 - val_accuracy: 0.2433\n",
      "Epoch 2433/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2813 - accuracy: 0.5000 - val_loss: 3.1046 - val_accuracy: 0.2433\n",
      "Epoch 2434/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2811 - accuracy: 0.4971 - val_loss: 3.0939 - val_accuracy: 0.2467\n",
      "Epoch 2435/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2814 - accuracy: 0.5100 - val_loss: 3.1342 - val_accuracy: 0.2367\n",
      "Epoch 2436/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2808 - accuracy: 0.4986 - val_loss: 3.1451 - val_accuracy: 0.2433\n",
      "Epoch 2437/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2819 - accuracy: 0.4971 - val_loss: 3.1107 - val_accuracy: 0.2467\n",
      "Epoch 2438/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2816 - accuracy: 0.4929 - val_loss: 3.1269 - val_accuracy: 0.2467\n",
      "Epoch 2439/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2818 - accuracy: 0.5057 - val_loss: 3.1426 - val_accuracy: 0.2433\n",
      "Epoch 2440/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2816 - accuracy: 0.5043 - val_loss: 3.1438 - val_accuracy: 0.2433\n",
      "Epoch 2441/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2804 - accuracy: 0.4943 - val_loss: 3.1001 - val_accuracy: 0.2400\n",
      "Epoch 2442/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2814 - accuracy: 0.4971 - val_loss: 3.1627 - val_accuracy: 0.2367\n",
      "Epoch 2443/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2809 - accuracy: 0.5071 - val_loss: 3.1425 - val_accuracy: 0.2433\n",
      "Epoch 2444/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2803 - accuracy: 0.4986 - val_loss: 3.1182 - val_accuracy: 0.2467\n",
      "Epoch 2445/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2812 - accuracy: 0.5014 - val_loss: 3.1150 - val_accuracy: 0.2400\n",
      "Epoch 2446/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2806 - accuracy: 0.5029 - val_loss: 3.0977 - val_accuracy: 0.2500\n",
      "Epoch 2447/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2805 - accuracy: 0.5029 - val_loss: 3.1491 - val_accuracy: 0.2400\n",
      "Epoch 2448/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2805 - accuracy: 0.5000 - val_loss: 3.1152 - val_accuracy: 0.2433\n",
      "Epoch 2449/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2809 - accuracy: 0.4971 - val_loss: 3.1356 - val_accuracy: 0.2367\n",
      "Epoch 2450/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2803 - accuracy: 0.5014 - val_loss: 3.1083 - val_accuracy: 0.2300\n",
      "Epoch 2451/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2809 - accuracy: 0.5029 - val_loss: 3.1150 - val_accuracy: 0.2433\n",
      "Epoch 2452/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2812 - accuracy: 0.5057 - val_loss: 3.1280 - val_accuracy: 0.2400\n",
      "Epoch 2453/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2799 - accuracy: 0.4957 - val_loss: 3.1145 - val_accuracy: 0.2333\n",
      "Epoch 2454/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2804 - accuracy: 0.4986 - val_loss: 3.1742 - val_accuracy: 0.2467\n",
      "Epoch 2455/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2807 - accuracy: 0.5000 - val_loss: 3.1438 - val_accuracy: 0.2367\n",
      "Epoch 2456/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2799 - accuracy: 0.5071 - val_loss: 3.1672 - val_accuracy: 0.2467\n",
      "Epoch 2457/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2810 - accuracy: 0.5029 - val_loss: 3.1377 - val_accuracy: 0.2433\n",
      "Epoch 2458/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2801 - accuracy: 0.5014 - val_loss: 3.1105 - val_accuracy: 0.2467\n",
      "Epoch 2459/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2800 - accuracy: 0.5014 - val_loss: 3.1196 - val_accuracy: 0.2433\n",
      "Epoch 2460/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2800 - accuracy: 0.5000 - val_loss: 3.1112 - val_accuracy: 0.2400\n",
      "Epoch 2461/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2801 - accuracy: 0.5043 - val_loss: 3.1097 - val_accuracy: 0.2500\n",
      "Epoch 2462/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2795 - accuracy: 0.5000 - val_loss: 3.1391 - val_accuracy: 0.2367\n",
      "Epoch 2463/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2802 - accuracy: 0.5029 - val_loss: 3.1201 - val_accuracy: 0.2400\n",
      "Epoch 2464/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2795 - accuracy: 0.5000 - val_loss: 3.1227 - val_accuracy: 0.2467\n",
      "Epoch 2465/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2796 - accuracy: 0.4971 - val_loss: 3.1461 - val_accuracy: 0.2433\n",
      "Epoch 2466/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2793 - accuracy: 0.4971 - val_loss: 3.1242 - val_accuracy: 0.2433\n",
      "Epoch 2467/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2797 - accuracy: 0.5014 - val_loss: 3.1273 - val_accuracy: 0.2300\n",
      "Epoch 2468/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2795 - accuracy: 0.5043 - val_loss: 3.1188 - val_accuracy: 0.2500\n",
      "Epoch 2469/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2794 - accuracy: 0.4986 - val_loss: 3.1380 - val_accuracy: 0.2333\n",
      "Epoch 2470/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2795 - accuracy: 0.4943 - val_loss: 3.1465 - val_accuracy: 0.2467\n",
      "Epoch 2471/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2798 - accuracy: 0.5000 - val_loss: 3.1114 - val_accuracy: 0.2500\n",
      "Epoch 2472/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2792 - accuracy: 0.5029 - val_loss: 3.1518 - val_accuracy: 0.2367\n",
      "Epoch 2473/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2793 - accuracy: 0.5043 - val_loss: 3.1767 - val_accuracy: 0.2333\n",
      "Epoch 2474/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2801 - accuracy: 0.5000 - val_loss: 3.1371 - val_accuracy: 0.2300\n",
      "Epoch 2475/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2791 - accuracy: 0.5000 - val_loss: 3.1544 - val_accuracy: 0.2400\n",
      "Epoch 2476/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2789 - accuracy: 0.5029 - val_loss: 3.1561 - val_accuracy: 0.2433\n",
      "Epoch 2477/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2794 - accuracy: 0.4971 - val_loss: 3.1279 - val_accuracy: 0.2400\n",
      "Epoch 2478/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2798 - accuracy: 0.4957 - val_loss: 3.1436 - val_accuracy: 0.2367\n",
      "Epoch 2479/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2781 - accuracy: 0.5057 - val_loss: 3.0990 - val_accuracy: 0.2467\n",
      "Epoch 2480/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2780 - accuracy: 0.5057 - val_loss: 3.1773 - val_accuracy: 0.2333\n",
      "Epoch 2481/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2784 - accuracy: 0.5014 - val_loss: 3.1510 - val_accuracy: 0.2433\n",
      "Epoch 2482/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2786 - accuracy: 0.4986 - val_loss: 3.1629 - val_accuracy: 0.2367\n",
      "Epoch 2483/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2792 - accuracy: 0.5000 - val_loss: 3.1267 - val_accuracy: 0.2400\n",
      "Epoch 2484/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2793 - accuracy: 0.4986 - val_loss: 3.1525 - val_accuracy: 0.2400\n",
      "Epoch 2485/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2791 - accuracy: 0.5029 - val_loss: 3.1348 - val_accuracy: 0.2333\n",
      "Epoch 2486/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2784 - accuracy: 0.5043 - val_loss: 3.1273 - val_accuracy: 0.2467\n",
      "Epoch 2487/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2785 - accuracy: 0.4971 - val_loss: 3.1741 - val_accuracy: 0.2433\n",
      "Epoch 2488/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 1.2786 - accuracy: 0.4957 - val_loss: 3.0929 - val_accuracy: 0.2467\n",
      "Epoch 2489/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2799 - accuracy: 0.5014 - val_loss: 3.1603 - val_accuracy: 0.2400\n",
      "Epoch 2490/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2783 - accuracy: 0.5029 - val_loss: 3.1238 - val_accuracy: 0.2500\n",
      "Epoch 2491/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2789 - accuracy: 0.4986 - val_loss: 3.1475 - val_accuracy: 0.2367\n",
      "Epoch 2492/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2796 - accuracy: 0.4986 - val_loss: 3.1347 - val_accuracy: 0.2467\n",
      "Epoch 2493/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2787 - accuracy: 0.5029 - val_loss: 3.1816 - val_accuracy: 0.2400\n",
      "Epoch 2494/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2785 - accuracy: 0.4943 - val_loss: 3.1316 - val_accuracy: 0.2433\n",
      "Epoch 2495/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2784 - accuracy: 0.5014 - val_loss: 3.2034 - val_accuracy: 0.2433\n",
      "Epoch 2496/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2791 - accuracy: 0.4986 - val_loss: 3.1675 - val_accuracy: 0.2433\n",
      "Epoch 2497/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2789 - accuracy: 0.5014 - val_loss: 3.1644 - val_accuracy: 0.2400\n",
      "Epoch 2498/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2785 - accuracy: 0.5029 - val_loss: 3.1862 - val_accuracy: 0.2433\n",
      "Epoch 2499/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2784 - accuracy: 0.5057 - val_loss: 3.1285 - val_accuracy: 0.2367\n",
      "Epoch 2500/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2776 - accuracy: 0.5057 - val_loss: 3.1201 - val_accuracy: 0.2533\n",
      "Epoch 2501/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2786 - accuracy: 0.5014 - val_loss: 3.2029 - val_accuracy: 0.2400\n",
      "Epoch 2502/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2781 - accuracy: 0.4971 - val_loss: 3.1570 - val_accuracy: 0.2433\n",
      "Epoch 2503/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2779 - accuracy: 0.4971 - val_loss: 3.1660 - val_accuracy: 0.2400\n",
      "Epoch 2504/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2779 - accuracy: 0.5071 - val_loss: 3.1453 - val_accuracy: 0.2467\n",
      "Epoch 2505/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2791 - accuracy: 0.4957 - val_loss: 3.1572 - val_accuracy: 0.2467\n",
      "Epoch 2506/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2778 - accuracy: 0.5043 - val_loss: 3.1533 - val_accuracy: 0.2400\n",
      "Epoch 2507/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2780 - accuracy: 0.4986 - val_loss: 3.1456 - val_accuracy: 0.2433\n",
      "Epoch 2508/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2777 - accuracy: 0.5014 - val_loss: 3.1998 - val_accuracy: 0.2467\n",
      "Epoch 2509/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2776 - accuracy: 0.5057 - val_loss: 3.1590 - val_accuracy: 0.2433\n",
      "Epoch 2510/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2775 - accuracy: 0.5014 - val_loss: 3.1713 - val_accuracy: 0.2367\n",
      "Epoch 2511/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2777 - accuracy: 0.4986 - val_loss: 3.1361 - val_accuracy: 0.2433\n",
      "Epoch 2512/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2774 - accuracy: 0.5043 - val_loss: 3.1758 - val_accuracy: 0.2467\n",
      "Epoch 2513/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2781 - accuracy: 0.5014 - val_loss: 3.1435 - val_accuracy: 0.2433\n",
      "Epoch 2514/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2770 - accuracy: 0.5000 - val_loss: 3.1296 - val_accuracy: 0.2400\n",
      "Epoch 2515/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2771 - accuracy: 0.5014 - val_loss: 3.1515 - val_accuracy: 0.2433\n",
      "Epoch 2516/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2771 - accuracy: 0.5000 - val_loss: 3.1822 - val_accuracy: 0.2433\n",
      "Epoch 2517/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2782 - accuracy: 0.5000 - val_loss: 3.1818 - val_accuracy: 0.2433\n",
      "Epoch 2518/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2775 - accuracy: 0.5043 - val_loss: 3.1639 - val_accuracy: 0.2433\n",
      "Epoch 2519/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2775 - accuracy: 0.5071 - val_loss: 3.1749 - val_accuracy: 0.2400\n",
      "Epoch 2520/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2769 - accuracy: 0.4971 - val_loss: 3.1710 - val_accuracy: 0.2367\n",
      "Epoch 2521/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2771 - accuracy: 0.4986 - val_loss: 3.1643 - val_accuracy: 0.2367\n",
      "Epoch 2522/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2778 - accuracy: 0.5014 - val_loss: 3.1515 - val_accuracy: 0.2367\n",
      "Epoch 2523/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2774 - accuracy: 0.5000 - val_loss: 3.1499 - val_accuracy: 0.2333\n",
      "Epoch 2524/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2769 - accuracy: 0.4986 - val_loss: 3.1515 - val_accuracy: 0.2433\n",
      "Epoch 2525/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2772 - accuracy: 0.5014 - val_loss: 3.1788 - val_accuracy: 0.2433\n",
      "Epoch 2526/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2769 - accuracy: 0.4986 - val_loss: 3.1544 - val_accuracy: 0.2333\n",
      "Epoch 2527/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2767 - accuracy: 0.5014 - val_loss: 3.1840 - val_accuracy: 0.2400\n",
      "Epoch 2528/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2766 - accuracy: 0.5014 - val_loss: 3.1740 - val_accuracy: 0.2333\n",
      "Epoch 2529/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2777 - accuracy: 0.5057 - val_loss: 3.1967 - val_accuracy: 0.2400\n",
      "Epoch 2530/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2763 - accuracy: 0.5000 - val_loss: 3.1729 - val_accuracy: 0.2367\n",
      "Epoch 2531/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2765 - accuracy: 0.5057 - val_loss: 3.1425 - val_accuracy: 0.2433\n",
      "Epoch 2532/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2766 - accuracy: 0.5071 - val_loss: 3.1751 - val_accuracy: 0.2433\n",
      "Epoch 2533/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2777 - accuracy: 0.5057 - val_loss: 3.1707 - val_accuracy: 0.2433\n",
      "Epoch 2534/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2768 - accuracy: 0.5014 - val_loss: 3.1882 - val_accuracy: 0.2367\n",
      "Epoch 2535/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2770 - accuracy: 0.5043 - val_loss: 3.1639 - val_accuracy: 0.2433\n",
      "Epoch 2536/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2768 - accuracy: 0.5043 - val_loss: 3.1994 - val_accuracy: 0.2400\n",
      "Epoch 2537/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2772 - accuracy: 0.5057 - val_loss: 3.1514 - val_accuracy: 0.2433\n",
      "Epoch 2538/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2762 - accuracy: 0.5029 - val_loss: 3.1809 - val_accuracy: 0.2400\n",
      "Epoch 2539/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2773 - accuracy: 0.4986 - val_loss: 3.2060 - val_accuracy: 0.2400\n",
      "Epoch 2540/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2770 - accuracy: 0.5014 - val_loss: 3.2081 - val_accuracy: 0.2467\n",
      "Epoch 2541/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2764 - accuracy: 0.5057 - val_loss: 3.1819 - val_accuracy: 0.2367\n",
      "Epoch 2542/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2760 - accuracy: 0.5057 - val_loss: 3.1716 - val_accuracy: 0.2433\n",
      "Epoch 2543/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2766 - accuracy: 0.5043 - val_loss: 3.1804 - val_accuracy: 0.2333\n",
      "Epoch 2544/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2768 - accuracy: 0.4986 - val_loss: 3.1759 - val_accuracy: 0.2333\n",
      "Epoch 2545/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2763 - accuracy: 0.5086 - val_loss: 3.2089 - val_accuracy: 0.2400\n",
      "Epoch 2546/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2768 - accuracy: 0.5057 - val_loss: 3.2078 - val_accuracy: 0.2400\n",
      "Epoch 2547/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2767 - accuracy: 0.5043 - val_loss: 3.1964 - val_accuracy: 0.2433\n",
      "Epoch 2548/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2759 - accuracy: 0.5029 - val_loss: 3.1845 - val_accuracy: 0.2433\n",
      "Epoch 2549/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2761 - accuracy: 0.5000 - val_loss: 3.1644 - val_accuracy: 0.2367\n",
      "Epoch 2550/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2762 - accuracy: 0.5043 - val_loss: 3.1715 - val_accuracy: 0.2367\n",
      "Epoch 2551/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2755 - accuracy: 0.4986 - val_loss: 3.2068 - val_accuracy: 0.2433\n",
      "Epoch 2552/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2758 - accuracy: 0.5043 - val_loss: 3.1591 - val_accuracy: 0.2333\n",
      "Epoch 2553/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2754 - accuracy: 0.5000 - val_loss: 3.1693 - val_accuracy: 0.2367\n",
      "Epoch 2554/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2756 - accuracy: 0.4986 - val_loss: 3.1594 - val_accuracy: 0.2333\n",
      "Epoch 2555/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2763 - accuracy: 0.5000 - val_loss: 3.1993 - val_accuracy: 0.2433\n",
      "Epoch 2556/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2762 - accuracy: 0.5000 - val_loss: 3.1612 - val_accuracy: 0.2400\n",
      "Epoch 2557/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2754 - accuracy: 0.5000 - val_loss: 3.2042 - val_accuracy: 0.2433\n",
      "Epoch 2558/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2757 - accuracy: 0.4986 - val_loss: 3.2016 - val_accuracy: 0.2433\n",
      "Epoch 2559/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2758 - accuracy: 0.5043 - val_loss: 3.1937 - val_accuracy: 0.2400\n",
      "Epoch 2560/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2762 - accuracy: 0.5000 - val_loss: 3.1953 - val_accuracy: 0.2400\n",
      "Epoch 2561/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2757 - accuracy: 0.5057 - val_loss: 3.1768 - val_accuracy: 0.2333\n",
      "Epoch 2562/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2751 - accuracy: 0.5000 - val_loss: 3.1692 - val_accuracy: 0.2433\n",
      "Epoch 2563/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2753 - accuracy: 0.5029 - val_loss: 3.1907 - val_accuracy: 0.2467\n",
      "Epoch 2564/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2761 - accuracy: 0.5029 - val_loss: 3.1934 - val_accuracy: 0.2400\n",
      "Epoch 2565/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2755 - accuracy: 0.5043 - val_loss: 3.1817 - val_accuracy: 0.2400\n",
      "Epoch 2566/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2760 - accuracy: 0.5014 - val_loss: 3.1976 - val_accuracy: 0.2400\n",
      "Epoch 2567/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2759 - accuracy: 0.5057 - val_loss: 3.1804 - val_accuracy: 0.2433\n",
      "Epoch 2568/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2754 - accuracy: 0.5043 - val_loss: 3.1809 - val_accuracy: 0.2333\n",
      "Epoch 2569/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2742 - accuracy: 0.5000 - val_loss: 3.1647 - val_accuracy: 0.2433\n",
      "Epoch 2570/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2750 - accuracy: 0.4986 - val_loss: 3.2062 - val_accuracy: 0.2433\n",
      "Epoch 2571/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2750 - accuracy: 0.5043 - val_loss: 3.1963 - val_accuracy: 0.2400\n",
      "Epoch 2572/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2752 - accuracy: 0.5086 - val_loss: 3.2094 - val_accuracy: 0.2433\n",
      "Epoch 2573/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2743 - accuracy: 0.5043 - val_loss: 3.2451 - val_accuracy: 0.2433\n",
      "Epoch 2574/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2754 - accuracy: 0.4971 - val_loss: 3.1492 - val_accuracy: 0.2433\n",
      "Epoch 2575/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2748 - accuracy: 0.5029 - val_loss: 3.2267 - val_accuracy: 0.2433\n",
      "Epoch 2576/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2747 - accuracy: 0.5071 - val_loss: 3.2081 - val_accuracy: 0.2433\n",
      "Epoch 2577/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2749 - accuracy: 0.5029 - val_loss: 3.2051 - val_accuracy: 0.2433\n",
      "Epoch 2578/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2746 - accuracy: 0.5014 - val_loss: 3.1948 - val_accuracy: 0.2433\n",
      "Epoch 2579/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2749 - accuracy: 0.5029 - val_loss: 3.1872 - val_accuracy: 0.2367\n",
      "Epoch 2580/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2746 - accuracy: 0.5014 - val_loss: 3.1996 - val_accuracy: 0.2433\n",
      "Epoch 2581/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2741 - accuracy: 0.5029 - val_loss: 3.1650 - val_accuracy: 0.2367\n",
      "Epoch 2582/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2747 - accuracy: 0.5043 - val_loss: 3.2219 - val_accuracy: 0.2367\n",
      "Epoch 2583/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2749 - accuracy: 0.5043 - val_loss: 3.2027 - val_accuracy: 0.2433\n",
      "Epoch 2584/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2745 - accuracy: 0.5086 - val_loss: 3.2029 - val_accuracy: 0.2400\n",
      "Epoch 2585/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2741 - accuracy: 0.5014 - val_loss: 3.1934 - val_accuracy: 0.2400\n",
      "Epoch 2586/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2742 - accuracy: 0.5071 - val_loss: 3.1815 - val_accuracy: 0.2433\n",
      "Epoch 2587/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2744 - accuracy: 0.5057 - val_loss: 3.2214 - val_accuracy: 0.2400\n",
      "Epoch 2588/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2745 - accuracy: 0.5014 - val_loss: 3.1965 - val_accuracy: 0.2367\n",
      "Epoch 2589/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2743 - accuracy: 0.5014 - val_loss: 3.1901 - val_accuracy: 0.2367\n",
      "Epoch 2590/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2736 - accuracy: 0.5014 - val_loss: 3.1920 - val_accuracy: 0.2333\n",
      "Epoch 2591/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2738 - accuracy: 0.5029 - val_loss: 3.1714 - val_accuracy: 0.2433\n",
      "Epoch 2592/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2743 - accuracy: 0.5071 - val_loss: 3.2311 - val_accuracy: 0.2400\n",
      "Epoch 2593/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2740 - accuracy: 0.4986 - val_loss: 3.1688 - val_accuracy: 0.2433\n",
      "Epoch 2594/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2739 - accuracy: 0.5043 - val_loss: 3.2245 - val_accuracy: 0.2400\n",
      "Epoch 2595/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2745 - accuracy: 0.4971 - val_loss: 3.2038 - val_accuracy: 0.2333\n",
      "Epoch 2596/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2748 - accuracy: 0.5071 - val_loss: 3.1949 - val_accuracy: 0.2367\n",
      "Epoch 2597/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2739 - accuracy: 0.5043 - val_loss: 3.1998 - val_accuracy: 0.2433\n",
      "Epoch 2598/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 97us/step - loss: 1.2733 - accuracy: 0.4986 - val_loss: 3.2180 - val_accuracy: 0.2467\n",
      "Epoch 2599/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2740 - accuracy: 0.5029 - val_loss: 3.1791 - val_accuracy: 0.2367\n",
      "Epoch 2600/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2734 - accuracy: 0.5057 - val_loss: 3.2008 - val_accuracy: 0.2433\n",
      "Epoch 2601/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2734 - accuracy: 0.5029 - val_loss: 3.1994 - val_accuracy: 0.2433\n",
      "Epoch 2602/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2745 - accuracy: 0.5086 - val_loss: 3.2144 - val_accuracy: 0.2433\n",
      "Epoch 2603/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2737 - accuracy: 0.5057 - val_loss: 3.1867 - val_accuracy: 0.2433\n",
      "Epoch 2604/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2734 - accuracy: 0.5057 - val_loss: 3.2175 - val_accuracy: 0.2400\n",
      "Epoch 2605/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2739 - accuracy: 0.5014 - val_loss: 3.2092 - val_accuracy: 0.2367\n",
      "Epoch 2606/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2739 - accuracy: 0.5014 - val_loss: 3.2013 - val_accuracy: 0.2333\n",
      "Epoch 2607/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2733 - accuracy: 0.5000 - val_loss: 3.1853 - val_accuracy: 0.2400\n",
      "Epoch 2608/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2736 - accuracy: 0.5000 - val_loss: 3.2379 - val_accuracy: 0.2400\n",
      "Epoch 2609/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2734 - accuracy: 0.4986 - val_loss: 3.1981 - val_accuracy: 0.2400\n",
      "Epoch 2610/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2736 - accuracy: 0.5029 - val_loss: 3.1858 - val_accuracy: 0.2433\n",
      "Epoch 2611/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2736 - accuracy: 0.5014 - val_loss: 3.1876 - val_accuracy: 0.2400\n",
      "Epoch 2612/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2737 - accuracy: 0.5029 - val_loss: 3.2261 - val_accuracy: 0.2400\n",
      "Epoch 2613/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2733 - accuracy: 0.5057 - val_loss: 3.2148 - val_accuracy: 0.2433\n",
      "Epoch 2614/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2729 - accuracy: 0.5043 - val_loss: 3.2341 - val_accuracy: 0.2433\n",
      "Epoch 2615/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2731 - accuracy: 0.5043 - val_loss: 3.2059 - val_accuracy: 0.2433\n",
      "Epoch 2616/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2733 - accuracy: 0.5043 - val_loss: 3.2451 - val_accuracy: 0.2400\n",
      "Epoch 2617/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2737 - accuracy: 0.5043 - val_loss: 3.2205 - val_accuracy: 0.2400\n",
      "Epoch 2618/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2737 - accuracy: 0.4986 - val_loss: 3.1915 - val_accuracy: 0.2367\n",
      "Epoch 2619/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2733 - accuracy: 0.5043 - val_loss: 3.2209 - val_accuracy: 0.2367\n",
      "Epoch 2620/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2732 - accuracy: 0.5057 - val_loss: 3.2249 - val_accuracy: 0.2367\n",
      "Epoch 2621/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2730 - accuracy: 0.5057 - val_loss: 3.2217 - val_accuracy: 0.2333\n",
      "Epoch 2622/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2736 - accuracy: 0.5000 - val_loss: 3.1888 - val_accuracy: 0.2400\n",
      "Epoch 2623/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2729 - accuracy: 0.5029 - val_loss: 3.2267 - val_accuracy: 0.2400\n",
      "Epoch 2624/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2723 - accuracy: 0.5029 - val_loss: 3.1944 - val_accuracy: 0.2333\n",
      "Epoch 2625/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2725 - accuracy: 0.5043 - val_loss: 3.2388 - val_accuracy: 0.2433\n",
      "Epoch 2626/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2729 - accuracy: 0.5000 - val_loss: 3.2409 - val_accuracy: 0.2433\n",
      "Epoch 2627/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2727 - accuracy: 0.5014 - val_loss: 3.2240 - val_accuracy: 0.2367\n",
      "Epoch 2628/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2724 - accuracy: 0.5043 - val_loss: 3.2312 - val_accuracy: 0.2367\n",
      "Epoch 2629/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2725 - accuracy: 0.5029 - val_loss: 3.2195 - val_accuracy: 0.2367\n",
      "Epoch 2630/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2722 - accuracy: 0.5029 - val_loss: 3.1707 - val_accuracy: 0.2433\n",
      "Epoch 2631/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2726 - accuracy: 0.5057 - val_loss: 3.2321 - val_accuracy: 0.2367\n",
      "Epoch 2632/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2733 - accuracy: 0.4986 - val_loss: 3.2187 - val_accuracy: 0.2433\n",
      "Epoch 2633/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2720 - accuracy: 0.5043 - val_loss: 3.2203 - val_accuracy: 0.2367\n",
      "Epoch 2634/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2718 - accuracy: 0.5086 - val_loss: 3.2083 - val_accuracy: 0.2367\n",
      "Epoch 2635/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2730 - accuracy: 0.5043 - val_loss: 3.2457 - val_accuracy: 0.2367\n",
      "Epoch 2636/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2725 - accuracy: 0.5014 - val_loss: 3.2223 - val_accuracy: 0.2367\n",
      "Epoch 2637/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2727 - accuracy: 0.5057 - val_loss: 3.2285 - val_accuracy: 0.2400\n",
      "Epoch 2638/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2721 - accuracy: 0.5000 - val_loss: 3.2379 - val_accuracy: 0.2433\n",
      "Epoch 2639/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2724 - accuracy: 0.5043 - val_loss: 3.1877 - val_accuracy: 0.2467\n",
      "Epoch 2640/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2721 - accuracy: 0.5071 - val_loss: 3.2542 - val_accuracy: 0.2467\n",
      "Epoch 2641/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2720 - accuracy: 0.5086 - val_loss: 3.3056 - val_accuracy: 0.2467\n",
      "Epoch 2642/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2719 - accuracy: 0.4986 - val_loss: 3.1854 - val_accuracy: 0.2400\n",
      "Epoch 2643/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2720 - accuracy: 0.5129 - val_loss: 3.2231 - val_accuracy: 0.2433\n",
      "Epoch 2644/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2720 - accuracy: 0.5000 - val_loss: 3.2263 - val_accuracy: 0.2433\n",
      "Epoch 2645/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2718 - accuracy: 0.5029 - val_loss: 3.2218 - val_accuracy: 0.2433\n",
      "Epoch 2646/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2724 - accuracy: 0.5057 - val_loss: 3.2380 - val_accuracy: 0.2467\n",
      "Epoch 2647/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2722 - accuracy: 0.5043 - val_loss: 3.2414 - val_accuracy: 0.2467\n",
      "Epoch 2648/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2719 - accuracy: 0.5029 - val_loss: 3.2479 - val_accuracy: 0.2433\n",
      "Epoch 2649/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2721 - accuracy: 0.5043 - val_loss: 3.2017 - val_accuracy: 0.2400\n",
      "Epoch 2650/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2714 - accuracy: 0.5014 - val_loss: 3.2057 - val_accuracy: 0.2400\n",
      "Epoch 2651/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2711 - accuracy: 0.5014 - val_loss: 3.2178 - val_accuracy: 0.2433\n",
      "Epoch 2652/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2714 - accuracy: 0.5100 - val_loss: 3.2037 - val_accuracy: 0.2500\n",
      "Epoch 2653/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2721 - accuracy: 0.5086 - val_loss: 3.2682 - val_accuracy: 0.2433\n",
      "Epoch 2654/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2720 - accuracy: 0.5014 - val_loss: 3.2231 - val_accuracy: 0.2400\n",
      "Epoch 2655/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2713 - accuracy: 0.5043 - val_loss: 3.2401 - val_accuracy: 0.2367\n",
      "Epoch 2656/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2717 - accuracy: 0.5057 - val_loss: 3.2517 - val_accuracy: 0.2400\n",
      "Epoch 2657/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2710 - accuracy: 0.5014 - val_loss: 3.1837 - val_accuracy: 0.2367\n",
      "Epoch 2658/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2713 - accuracy: 0.5029 - val_loss: 3.2474 - val_accuracy: 0.2400\n",
      "Epoch 2659/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2710 - accuracy: 0.4971 - val_loss: 3.2049 - val_accuracy: 0.2367\n",
      "Epoch 2660/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2716 - accuracy: 0.5000 - val_loss: 3.2713 - val_accuracy: 0.2433\n",
      "Epoch 2661/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2724 - accuracy: 0.5000 - val_loss: 3.2303 - val_accuracy: 0.2367\n",
      "Epoch 2662/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2721 - accuracy: 0.5029 - val_loss: 3.2267 - val_accuracy: 0.2400\n",
      "Epoch 2663/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2708 - accuracy: 0.5071 - val_loss: 3.2114 - val_accuracy: 0.2367\n",
      "Epoch 2664/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2708 - accuracy: 0.5043 - val_loss: 3.2271 - val_accuracy: 0.2367\n",
      "Epoch 2665/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2715 - accuracy: 0.5043 - val_loss: 3.2102 - val_accuracy: 0.2367\n",
      "Epoch 2666/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2715 - accuracy: 0.5057 - val_loss: 3.2198 - val_accuracy: 0.2367\n",
      "Epoch 2667/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2706 - accuracy: 0.5114 - val_loss: 3.2256 - val_accuracy: 0.2433\n",
      "Epoch 2668/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2713 - accuracy: 0.5057 - val_loss: 3.2807 - val_accuracy: 0.2500\n",
      "Epoch 2669/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2707 - accuracy: 0.5086 - val_loss: 3.2578 - val_accuracy: 0.2433\n",
      "Epoch 2670/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2710 - accuracy: 0.5043 - val_loss: 3.2652 - val_accuracy: 0.2433\n",
      "Epoch 2671/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2712 - accuracy: 0.5071 - val_loss: 3.2614 - val_accuracy: 0.2400\n",
      "Epoch 2672/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2707 - accuracy: 0.5071 - val_loss: 3.2680 - val_accuracy: 0.2467\n",
      "Epoch 2673/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2713 - accuracy: 0.5086 - val_loss: 3.2224 - val_accuracy: 0.2433\n",
      "Epoch 2674/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2708 - accuracy: 0.5014 - val_loss: 3.2473 - val_accuracy: 0.2433\n",
      "Epoch 2675/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2707 - accuracy: 0.5029 - val_loss: 3.2115 - val_accuracy: 0.2367\n",
      "Epoch 2676/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2712 - accuracy: 0.5043 - val_loss: 3.2497 - val_accuracy: 0.2400\n",
      "Epoch 2677/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2711 - accuracy: 0.5014 - val_loss: 3.2751 - val_accuracy: 0.2467\n",
      "Epoch 2678/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2713 - accuracy: 0.5086 - val_loss: 3.2473 - val_accuracy: 0.2367\n",
      "Epoch 2679/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2710 - accuracy: 0.5029 - val_loss: 3.2511 - val_accuracy: 0.2467\n",
      "Epoch 2680/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2735 - accuracy: 0.5071 - val_loss: 3.2232 - val_accuracy: 0.2367\n",
      "Epoch 2681/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2709 - accuracy: 0.4986 - val_loss: 3.2741 - val_accuracy: 0.2367\n",
      "Epoch 2682/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2702 - accuracy: 0.5029 - val_loss: 3.2300 - val_accuracy: 0.2400\n",
      "Epoch 2683/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2708 - accuracy: 0.5029 - val_loss: 3.2582 - val_accuracy: 0.2433\n",
      "Epoch 2684/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2699 - accuracy: 0.5043 - val_loss: 3.2648 - val_accuracy: 0.2433\n",
      "Epoch 2685/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2706 - accuracy: 0.5043 - val_loss: 3.2406 - val_accuracy: 0.2400\n",
      "Epoch 2686/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2704 - accuracy: 0.5071 - val_loss: 3.2465 - val_accuracy: 0.2400\n",
      "Epoch 2687/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2700 - accuracy: 0.5014 - val_loss: 3.2375 - val_accuracy: 0.2333\n",
      "Epoch 2688/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2703 - accuracy: 0.5071 - val_loss: 3.2737 - val_accuracy: 0.2433\n",
      "Epoch 2689/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2697 - accuracy: 0.5071 - val_loss: 3.2548 - val_accuracy: 0.2433\n",
      "Epoch 2690/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2707 - accuracy: 0.5071 - val_loss: 3.1897 - val_accuracy: 0.2400\n",
      "Epoch 2691/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2706 - accuracy: 0.5029 - val_loss: 3.2644 - val_accuracy: 0.2467\n",
      "Epoch 2692/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2697 - accuracy: 0.5029 - val_loss: 3.2541 - val_accuracy: 0.2367\n",
      "Epoch 2693/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2698 - accuracy: 0.5057 - val_loss: 3.2791 - val_accuracy: 0.2433\n",
      "Epoch 2694/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2701 - accuracy: 0.5029 - val_loss: 3.2400 - val_accuracy: 0.2433\n",
      "Epoch 2695/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2691 - accuracy: 0.5071 - val_loss: 3.2574 - val_accuracy: 0.2467\n",
      "Epoch 2696/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2696 - accuracy: 0.5086 - val_loss: 3.2422 - val_accuracy: 0.2367\n",
      "Epoch 2697/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2706 - accuracy: 0.5057 - val_loss: 3.2268 - val_accuracy: 0.2400\n",
      "Epoch 2698/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2699 - accuracy: 0.5057 - val_loss: 3.2648 - val_accuracy: 0.2367\n",
      "Epoch 2699/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2700 - accuracy: 0.5057 - val_loss: 3.2811 - val_accuracy: 0.2467\n",
      "Epoch 2700/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2696 - accuracy: 0.5043 - val_loss: 3.2638 - val_accuracy: 0.2467\n",
      "Epoch 2701/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2701 - accuracy: 0.5057 - val_loss: 3.2801 - val_accuracy: 0.2433\n",
      "Epoch 2702/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2697 - accuracy: 0.5071 - val_loss: 3.2794 - val_accuracy: 0.2367\n",
      "Epoch 2703/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2693 - accuracy: 0.5057 - val_loss: 3.2559 - val_accuracy: 0.2433\n",
      "Epoch 2704/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2691 - accuracy: 0.5043 - val_loss: 3.2291 - val_accuracy: 0.2433\n",
      "Epoch 2705/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2694 - accuracy: 0.5043 - val_loss: 3.2502 - val_accuracy: 0.2467\n",
      "Epoch 2706/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2700 - accuracy: 0.5057 - val_loss: 3.2647 - val_accuracy: 0.2467\n",
      "Epoch 2707/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2702 - accuracy: 0.5043 - val_loss: 3.2682 - val_accuracy: 0.2400\n",
      "Epoch 2708/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 86us/step - loss: 1.2695 - accuracy: 0.5029 - val_loss: 3.2695 - val_accuracy: 0.2400\n",
      "Epoch 2709/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2690 - accuracy: 0.5043 - val_loss: 3.2455 - val_accuracy: 0.2367\n",
      "Epoch 2710/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2696 - accuracy: 0.5000 - val_loss: 3.2431 - val_accuracy: 0.2367\n",
      "Epoch 2711/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2698 - accuracy: 0.5057 - val_loss: 3.2415 - val_accuracy: 0.2433\n",
      "Epoch 2712/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2690 - accuracy: 0.5014 - val_loss: 3.2078 - val_accuracy: 0.2400\n",
      "Epoch 2713/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2695 - accuracy: 0.5071 - val_loss: 3.2908 - val_accuracy: 0.2500\n",
      "Epoch 2714/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2691 - accuracy: 0.5029 - val_loss: 3.2943 - val_accuracy: 0.2467\n",
      "Epoch 2715/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2697 - accuracy: 0.5071 - val_loss: 3.2615 - val_accuracy: 0.2433\n",
      "Epoch 2716/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2691 - accuracy: 0.5057 - val_loss: 3.2411 - val_accuracy: 0.2433\n",
      "Epoch 2717/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2690 - accuracy: 0.5057 - val_loss: 3.2610 - val_accuracy: 0.2433\n",
      "Epoch 2718/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2695 - accuracy: 0.5057 - val_loss: 3.2803 - val_accuracy: 0.2467\n",
      "Epoch 2719/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2692 - accuracy: 0.5057 - val_loss: 3.2434 - val_accuracy: 0.2433\n",
      "Epoch 2720/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2693 - accuracy: 0.5043 - val_loss: 3.2631 - val_accuracy: 0.2400\n",
      "Epoch 2721/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2695 - accuracy: 0.4986 - val_loss: 3.2488 - val_accuracy: 0.2367\n",
      "Epoch 2722/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2690 - accuracy: 0.5043 - val_loss: 3.2687 - val_accuracy: 0.2467\n",
      "Epoch 2723/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2695 - accuracy: 0.5057 - val_loss: 3.2878 - val_accuracy: 0.2467\n",
      "Epoch 2724/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2692 - accuracy: 0.5029 - val_loss: 3.2782 - val_accuracy: 0.2467\n",
      "Epoch 2725/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2685 - accuracy: 0.5057 - val_loss: 3.2927 - val_accuracy: 0.2467\n",
      "Epoch 2726/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2684 - accuracy: 0.5029 - val_loss: 3.3024 - val_accuracy: 0.2467\n",
      "Epoch 2727/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2683 - accuracy: 0.5071 - val_loss: 3.2825 - val_accuracy: 0.2433\n",
      "Epoch 2728/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2679 - accuracy: 0.5014 - val_loss: 3.2271 - val_accuracy: 0.2433\n",
      "Epoch 2729/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2685 - accuracy: 0.5057 - val_loss: 3.2757 - val_accuracy: 0.2433\n",
      "Epoch 2730/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2684 - accuracy: 0.5086 - val_loss: 3.2483 - val_accuracy: 0.2400\n",
      "Epoch 2731/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2682 - accuracy: 0.5029 - val_loss: 3.2691 - val_accuracy: 0.2400\n",
      "Epoch 2732/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2694 - accuracy: 0.5057 - val_loss: 3.2951 - val_accuracy: 0.2433\n",
      "Epoch 2733/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2699 - accuracy: 0.5029 - val_loss: 3.2470 - val_accuracy: 0.2367\n",
      "Epoch 2734/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2678 - accuracy: 0.5129 - val_loss: 3.2634 - val_accuracy: 0.2433\n",
      "Epoch 2735/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2682 - accuracy: 0.5057 - val_loss: 3.2759 - val_accuracy: 0.2400\n",
      "Epoch 2736/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2681 - accuracy: 0.5114 - val_loss: 3.2153 - val_accuracy: 0.2367\n",
      "Epoch 2737/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2677 - accuracy: 0.5129 - val_loss: 3.3035 - val_accuracy: 0.2500\n",
      "Epoch 2738/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2681 - accuracy: 0.5086 - val_loss: 3.2889 - val_accuracy: 0.2367\n",
      "Epoch 2739/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2678 - accuracy: 0.5100 - val_loss: 3.3000 - val_accuracy: 0.2433\n",
      "Epoch 2740/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2686 - accuracy: 0.5043 - val_loss: 3.2489 - val_accuracy: 0.2400\n",
      "Epoch 2741/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2690 - accuracy: 0.5029 - val_loss: 3.3021 - val_accuracy: 0.2400\n",
      "Epoch 2742/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2691 - accuracy: 0.5029 - val_loss: 3.2899 - val_accuracy: 0.2400\n",
      "Epoch 2743/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2683 - accuracy: 0.5000 - val_loss: 3.2713 - val_accuracy: 0.2400\n",
      "Epoch 2744/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2688 - accuracy: 0.5029 - val_loss: 3.2881 - val_accuracy: 0.2433\n",
      "Epoch 2745/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2683 - accuracy: 0.5014 - val_loss: 3.2947 - val_accuracy: 0.2433\n",
      "Epoch 2746/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2684 - accuracy: 0.5071 - val_loss: 3.2999 - val_accuracy: 0.2433\n",
      "Epoch 2747/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2686 - accuracy: 0.5014 - val_loss: 3.2655 - val_accuracy: 0.2367\n",
      "Epoch 2748/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2681 - accuracy: 0.5057 - val_loss: 3.3114 - val_accuracy: 0.2467\n",
      "Epoch 2749/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2682 - accuracy: 0.5029 - val_loss: 3.2902 - val_accuracy: 0.2433\n",
      "Epoch 2750/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2677 - accuracy: 0.5071 - val_loss: 3.3078 - val_accuracy: 0.2467\n",
      "Epoch 2751/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2679 - accuracy: 0.5057 - val_loss: 3.2918 - val_accuracy: 0.2433\n",
      "Epoch 2752/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2674 - accuracy: 0.5100 - val_loss: 3.2849 - val_accuracy: 0.2367\n",
      "Epoch 2753/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2673 - accuracy: 0.5057 - val_loss: 3.2983 - val_accuracy: 0.2500\n",
      "Epoch 2754/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2682 - accuracy: 0.5071 - val_loss: 3.2634 - val_accuracy: 0.2400\n",
      "Epoch 2755/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2668 - accuracy: 0.5029 - val_loss: 3.2423 - val_accuracy: 0.2433\n",
      "Epoch 2756/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2676 - accuracy: 0.5057 - val_loss: 3.3065 - val_accuracy: 0.2467\n",
      "Epoch 2757/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2685 - accuracy: 0.5043 - val_loss: 3.2728 - val_accuracy: 0.2433\n",
      "Epoch 2758/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2683 - accuracy: 0.5057 - val_loss: 3.2149 - val_accuracy: 0.2367\n",
      "Epoch 2759/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2678 - accuracy: 0.5086 - val_loss: 3.3059 - val_accuracy: 0.2433\n",
      "Epoch 2760/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2676 - accuracy: 0.5071 - val_loss: 3.2988 - val_accuracy: 0.2467\n",
      "Epoch 2761/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2672 - accuracy: 0.5014 - val_loss: 3.2880 - val_accuracy: 0.2467\n",
      "Epoch 2762/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2672 - accuracy: 0.5129 - val_loss: 3.2748 - val_accuracy: 0.2367\n",
      "Epoch 2763/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2680 - accuracy: 0.5057 - val_loss: 3.3126 - val_accuracy: 0.2400\n",
      "Epoch 2764/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2662 - accuracy: 0.5000 - val_loss: 3.3193 - val_accuracy: 0.2467\n",
      "Epoch 2765/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2673 - accuracy: 0.5029 - val_loss: 3.2818 - val_accuracy: 0.2433\n",
      "Epoch 2766/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2666 - accuracy: 0.5100 - val_loss: 3.3025 - val_accuracy: 0.2433\n",
      "Epoch 2767/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2676 - accuracy: 0.5129 - val_loss: 3.3060 - val_accuracy: 0.2400\n",
      "Epoch 2768/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2670 - accuracy: 0.5114 - val_loss: 3.3141 - val_accuracy: 0.2467\n",
      "Epoch 2769/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2664 - accuracy: 0.5071 - val_loss: 3.3091 - val_accuracy: 0.2433\n",
      "Epoch 2770/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2668 - accuracy: 0.5071 - val_loss: 3.2770 - val_accuracy: 0.2367\n",
      "Epoch 2771/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2662 - accuracy: 0.5100 - val_loss: 3.2704 - val_accuracy: 0.2367\n",
      "Epoch 2772/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2694 - accuracy: 0.5071 - val_loss: 3.2732 - val_accuracy: 0.2400\n",
      "Epoch 2773/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2670 - accuracy: 0.5057 - val_loss: 3.2934 - val_accuracy: 0.2400\n",
      "Epoch 2774/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2668 - accuracy: 0.5043 - val_loss: 3.3001 - val_accuracy: 0.2467\n",
      "Epoch 2775/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2668 - accuracy: 0.5043 - val_loss: 3.2830 - val_accuracy: 0.2400\n",
      "Epoch 2776/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2671 - accuracy: 0.5071 - val_loss: 3.2994 - val_accuracy: 0.2433\n",
      "Epoch 2777/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2674 - accuracy: 0.5057 - val_loss: 3.3273 - val_accuracy: 0.2467\n",
      "Epoch 2778/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2672 - accuracy: 0.5043 - val_loss: 3.3110 - val_accuracy: 0.2400\n",
      "Epoch 2779/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2660 - accuracy: 0.5100 - val_loss: 3.2880 - val_accuracy: 0.2433\n",
      "Epoch 2780/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2666 - accuracy: 0.5029 - val_loss: 3.3233 - val_accuracy: 0.2467\n",
      "Epoch 2781/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2675 - accuracy: 0.5014 - val_loss: 3.3073 - val_accuracy: 0.2433\n",
      "Epoch 2782/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2665 - accuracy: 0.5071 - val_loss: 3.2525 - val_accuracy: 0.2367\n",
      "Epoch 2783/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2664 - accuracy: 0.5043 - val_loss: 3.3217 - val_accuracy: 0.2467\n",
      "Epoch 2784/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2659 - accuracy: 0.5029 - val_loss: 3.3161 - val_accuracy: 0.2467\n",
      "Epoch 2785/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2665 - accuracy: 0.5086 - val_loss: 3.2930 - val_accuracy: 0.2400\n",
      "Epoch 2786/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2668 - accuracy: 0.5100 - val_loss: 3.2067 - val_accuracy: 0.2433\n",
      "Epoch 2787/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2670 - accuracy: 0.5057 - val_loss: 3.3028 - val_accuracy: 0.2433\n",
      "Epoch 2788/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2662 - accuracy: 0.5057 - val_loss: 3.3421 - val_accuracy: 0.2433\n",
      "Epoch 2789/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2661 - accuracy: 0.5043 - val_loss: 3.3268 - val_accuracy: 0.2400\n",
      "Epoch 2790/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2663 - accuracy: 0.5057 - val_loss: 3.3288 - val_accuracy: 0.2433\n",
      "Epoch 2791/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2668 - accuracy: 0.5043 - val_loss: 3.2641 - val_accuracy: 0.2400\n",
      "Epoch 2792/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2661 - accuracy: 0.5029 - val_loss: 3.2729 - val_accuracy: 0.2400\n",
      "Epoch 2793/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2659 - accuracy: 0.5057 - val_loss: 3.2618 - val_accuracy: 0.2367\n",
      "Epoch 2794/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2668 - accuracy: 0.5057 - val_loss: 3.3166 - val_accuracy: 0.2467\n",
      "Epoch 2795/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2657 - accuracy: 0.5057 - val_loss: 3.2778 - val_accuracy: 0.2333\n",
      "Epoch 2796/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2659 - accuracy: 0.5057 - val_loss: 3.3176 - val_accuracy: 0.2467\n",
      "Epoch 2797/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2662 - accuracy: 0.5057 - val_loss: 3.3043 - val_accuracy: 0.2400\n",
      "Epoch 2798/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2653 - accuracy: 0.5114 - val_loss: 3.3345 - val_accuracy: 0.2433\n",
      "Epoch 2799/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2657 - accuracy: 0.5071 - val_loss: 3.2826 - val_accuracy: 0.2400\n",
      "Epoch 2800/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2667 - accuracy: 0.5014 - val_loss: 3.3126 - val_accuracy: 0.2433\n",
      "Epoch 2801/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2663 - accuracy: 0.5086 - val_loss: 3.3535 - val_accuracy: 0.2400\n",
      "Epoch 2802/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2661 - accuracy: 0.5071 - val_loss: 3.3291 - val_accuracy: 0.2433\n",
      "Epoch 2803/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2659 - accuracy: 0.5086 - val_loss: 3.3064 - val_accuracy: 0.2433\n",
      "Epoch 2804/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2655 - accuracy: 0.5043 - val_loss: 3.3189 - val_accuracy: 0.2467\n",
      "Epoch 2805/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2655 - accuracy: 0.5057 - val_loss: 3.3457 - val_accuracy: 0.2433\n",
      "Epoch 2806/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2657 - accuracy: 0.5029 - val_loss: 3.3388 - val_accuracy: 0.2467\n",
      "Epoch 2807/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2658 - accuracy: 0.5057 - val_loss: 3.3205 - val_accuracy: 0.2500\n",
      "Epoch 2808/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2651 - accuracy: 0.5071 - val_loss: 3.2964 - val_accuracy: 0.2467\n",
      "Epoch 2809/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2653 - accuracy: 0.5043 - val_loss: 3.3302 - val_accuracy: 0.2467\n",
      "Epoch 2810/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2653 - accuracy: 0.5057 - val_loss: 3.3129 - val_accuracy: 0.2467\n",
      "Epoch 2811/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2648 - accuracy: 0.5029 - val_loss: 3.3305 - val_accuracy: 0.2467\n",
      "Epoch 2812/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2657 - accuracy: 0.5071 - val_loss: 3.3072 - val_accuracy: 0.2433\n",
      "Epoch 2813/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2659 - accuracy: 0.5129 - val_loss: 3.3457 - val_accuracy: 0.2433\n",
      "Epoch 2814/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2652 - accuracy: 0.5043 - val_loss: 3.3085 - val_accuracy: 0.2367\n",
      "Epoch 2815/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2656 - accuracy: 0.5071 - val_loss: 3.3446 - val_accuracy: 0.2433\n",
      "Epoch 2816/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2658 - accuracy: 0.5071 - val_loss: 3.3064 - val_accuracy: 0.2433\n",
      "Epoch 2817/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2651 - accuracy: 0.5057 - val_loss: 3.3311 - val_accuracy: 0.2433\n",
      "Epoch 2818/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 94us/step - loss: 1.2654 - accuracy: 0.5057 - val_loss: 3.3211 - val_accuracy: 0.2433\n",
      "Epoch 2819/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2651 - accuracy: 0.5071 - val_loss: 3.3147 - val_accuracy: 0.2467\n",
      "Epoch 2820/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2657 - accuracy: 0.5057 - val_loss: 3.2952 - val_accuracy: 0.2367\n",
      "Epoch 2821/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2656 - accuracy: 0.5029 - val_loss: 3.3052 - val_accuracy: 0.2400\n",
      "Epoch 2822/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2652 - accuracy: 0.5100 - val_loss: 3.3329 - val_accuracy: 0.2400\n",
      "Epoch 2823/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2646 - accuracy: 0.5057 - val_loss: 3.3397 - val_accuracy: 0.2400\n",
      "Epoch 2824/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2645 - accuracy: 0.5086 - val_loss: 3.3356 - val_accuracy: 0.2400\n",
      "Epoch 2825/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2650 - accuracy: 0.5071 - val_loss: 3.3444 - val_accuracy: 0.2467\n",
      "Epoch 2826/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2643 - accuracy: 0.5086 - val_loss: 3.3495 - val_accuracy: 0.2433\n",
      "Epoch 2827/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2654 - accuracy: 0.5043 - val_loss: 3.3040 - val_accuracy: 0.2367\n",
      "Epoch 2828/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2654 - accuracy: 0.5071 - val_loss: 3.3586 - val_accuracy: 0.2433\n",
      "Epoch 2829/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2652 - accuracy: 0.5043 - val_loss: 3.3067 - val_accuracy: 0.2400\n",
      "Epoch 2830/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2638 - accuracy: 0.5057 - val_loss: 3.3115 - val_accuracy: 0.2433\n",
      "Epoch 2831/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2652 - accuracy: 0.5143 - val_loss: 3.2955 - val_accuracy: 0.2433\n",
      "Epoch 2832/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2644 - accuracy: 0.5114 - val_loss: 3.3699 - val_accuracy: 0.2467\n",
      "Epoch 2833/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2645 - accuracy: 0.5086 - val_loss: 3.3226 - val_accuracy: 0.2433\n",
      "Epoch 2834/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2648 - accuracy: 0.5029 - val_loss: 3.3242 - val_accuracy: 0.2400\n",
      "Epoch 2835/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2643 - accuracy: 0.5014 - val_loss: 3.3545 - val_accuracy: 0.2433\n",
      "Epoch 2836/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2647 - accuracy: 0.5057 - val_loss: 3.3259 - val_accuracy: 0.2400\n",
      "Epoch 2837/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2642 - accuracy: 0.5086 - val_loss: 3.3462 - val_accuracy: 0.2433\n",
      "Epoch 2838/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2648 - accuracy: 0.5057 - val_loss: 3.2648 - val_accuracy: 0.2400\n",
      "Epoch 2839/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2644 - accuracy: 0.5100 - val_loss: 3.3333 - val_accuracy: 0.2433\n",
      "Epoch 2840/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2645 - accuracy: 0.5029 - val_loss: 3.3324 - val_accuracy: 0.2400\n",
      "Epoch 2841/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2641 - accuracy: 0.5029 - val_loss: 3.3327 - val_accuracy: 0.2467\n",
      "Epoch 2842/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2642 - accuracy: 0.5071 - val_loss: 3.3189 - val_accuracy: 0.2433\n",
      "Epoch 2843/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2644 - accuracy: 0.5057 - val_loss: 3.3272 - val_accuracy: 0.2367\n",
      "Epoch 2844/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2637 - accuracy: 0.5057 - val_loss: 3.3435 - val_accuracy: 0.2467\n",
      "Epoch 2845/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2646 - accuracy: 0.5086 - val_loss: 3.3650 - val_accuracy: 0.2433\n",
      "Epoch 2846/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2636 - accuracy: 0.5071 - val_loss: 3.3953 - val_accuracy: 0.2467\n",
      "Epoch 2847/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2643 - accuracy: 0.5057 - val_loss: 3.3488 - val_accuracy: 0.2433\n",
      "Epoch 2848/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2635 - accuracy: 0.5086 - val_loss: 3.3164 - val_accuracy: 0.2400\n",
      "Epoch 2849/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2641 - accuracy: 0.5100 - val_loss: 3.3499 - val_accuracy: 0.2400\n",
      "Epoch 2850/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2641 - accuracy: 0.5086 - val_loss: 3.3427 - val_accuracy: 0.2367\n",
      "Epoch 2851/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2641 - accuracy: 0.5057 - val_loss: 3.3421 - val_accuracy: 0.2367\n",
      "Epoch 2852/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2640 - accuracy: 0.5071 - val_loss: 3.3851 - val_accuracy: 0.2467\n",
      "Epoch 2853/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2638 - accuracy: 0.5043 - val_loss: 3.3501 - val_accuracy: 0.2467\n",
      "Epoch 2854/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2641 - accuracy: 0.5057 - val_loss: 3.3043 - val_accuracy: 0.2400\n",
      "Epoch 2855/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2637 - accuracy: 0.5086 - val_loss: 3.3529 - val_accuracy: 0.2400\n",
      "Epoch 2856/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2635 - accuracy: 0.5043 - val_loss: 3.3563 - val_accuracy: 0.2367\n",
      "Epoch 2857/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2635 - accuracy: 0.5086 - val_loss: 3.3665 - val_accuracy: 0.2467\n",
      "Epoch 2858/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2634 - accuracy: 0.5057 - val_loss: 3.3732 - val_accuracy: 0.2467\n",
      "Epoch 2859/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2632 - accuracy: 0.5029 - val_loss: 3.3128 - val_accuracy: 0.2400\n",
      "Epoch 2860/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2638 - accuracy: 0.5129 - val_loss: 3.2872 - val_accuracy: 0.2400\n",
      "Epoch 2861/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2636 - accuracy: 0.5100 - val_loss: 3.3611 - val_accuracy: 0.2433\n",
      "Epoch 2862/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2631 - accuracy: 0.5000 - val_loss: 3.3506 - val_accuracy: 0.2433\n",
      "Epoch 2863/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2631 - accuracy: 0.5043 - val_loss: 3.3461 - val_accuracy: 0.2433\n",
      "Epoch 2864/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2633 - accuracy: 0.5014 - val_loss: 3.3307 - val_accuracy: 0.2433\n",
      "Epoch 2865/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2639 - accuracy: 0.5143 - val_loss: 3.3578 - val_accuracy: 0.2400\n",
      "Epoch 2866/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2635 - accuracy: 0.5129 - val_loss: 3.3671 - val_accuracy: 0.2433\n",
      "Epoch 2867/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2631 - accuracy: 0.5100 - val_loss: 3.3584 - val_accuracy: 0.2467\n",
      "Epoch 2868/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2641 - accuracy: 0.5057 - val_loss: 3.3063 - val_accuracy: 0.2433\n",
      "Epoch 2869/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2631 - accuracy: 0.5057 - val_loss: 3.3450 - val_accuracy: 0.2467\n",
      "Epoch 2870/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2627 - accuracy: 0.5057 - val_loss: 3.4149 - val_accuracy: 0.2467\n",
      "Epoch 2871/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2637 - accuracy: 0.5086 - val_loss: 3.3790 - val_accuracy: 0.2467\n",
      "Epoch 2872/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2632 - accuracy: 0.5057 - val_loss: 3.3612 - val_accuracy: 0.2433\n",
      "Epoch 2873/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2630 - accuracy: 0.5129 - val_loss: 3.3120 - val_accuracy: 0.2400\n",
      "Epoch 2874/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2633 - accuracy: 0.5186 - val_loss: 3.3161 - val_accuracy: 0.2433\n",
      "Epoch 2875/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2629 - accuracy: 0.5086 - val_loss: 3.3516 - val_accuracy: 0.2467\n",
      "Epoch 2876/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2643 - accuracy: 0.5057 - val_loss: 3.3909 - val_accuracy: 0.2467\n",
      "Epoch 2877/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2633 - accuracy: 0.5043 - val_loss: 3.3774 - val_accuracy: 0.2433\n",
      "Epoch 2878/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2627 - accuracy: 0.5086 - val_loss: 3.3443 - val_accuracy: 0.2433\n",
      "Epoch 2879/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2619 - accuracy: 0.5071 - val_loss: 3.3599 - val_accuracy: 0.2467\n",
      "Epoch 2880/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2623 - accuracy: 0.5071 - val_loss: 3.3822 - val_accuracy: 0.2400\n",
      "Epoch 2881/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2636 - accuracy: 0.5071 - val_loss: 3.3618 - val_accuracy: 0.2400\n",
      "Epoch 2882/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2630 - accuracy: 0.5057 - val_loss: 3.3054 - val_accuracy: 0.2400\n",
      "Epoch 2883/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2621 - accuracy: 0.5100 - val_loss: 3.2554 - val_accuracy: 0.2433\n",
      "Epoch 2884/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2629 - accuracy: 0.5071 - val_loss: 3.3988 - val_accuracy: 0.2433\n",
      "Epoch 2885/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2626 - accuracy: 0.5043 - val_loss: 3.3304 - val_accuracy: 0.2367\n",
      "Epoch 2886/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2627 - accuracy: 0.5086 - val_loss: 3.3512 - val_accuracy: 0.2433\n",
      "Epoch 2887/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2626 - accuracy: 0.5114 - val_loss: 3.3845 - val_accuracy: 0.2467\n",
      "Epoch 2888/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2623 - accuracy: 0.5029 - val_loss: 3.3403 - val_accuracy: 0.2467\n",
      "Epoch 2889/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2628 - accuracy: 0.5129 - val_loss: 3.3105 - val_accuracy: 0.2400\n",
      "Epoch 2890/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2627 - accuracy: 0.5114 - val_loss: 3.3306 - val_accuracy: 0.2433\n",
      "Epoch 2891/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2628 - accuracy: 0.5043 - val_loss: 3.3622 - val_accuracy: 0.2467\n",
      "Epoch 2892/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2626 - accuracy: 0.5043 - val_loss: 3.3681 - val_accuracy: 0.2467\n",
      "Epoch 2893/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2636 - accuracy: 0.5057 - val_loss: 3.3630 - val_accuracy: 0.2433\n",
      "Epoch 2894/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2626 - accuracy: 0.5057 - val_loss: 3.4042 - val_accuracy: 0.2467\n",
      "Epoch 2895/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2620 - accuracy: 0.5086 - val_loss: 3.3810 - val_accuracy: 0.2400\n",
      "Epoch 2896/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2625 - accuracy: 0.5086 - val_loss: 3.3710 - val_accuracy: 0.2433\n",
      "Epoch 2897/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2627 - accuracy: 0.5114 - val_loss: 3.4127 - val_accuracy: 0.2400\n",
      "Epoch 2898/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2622 - accuracy: 0.5071 - val_loss: 3.3813 - val_accuracy: 0.2400\n",
      "Epoch 2899/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2624 - accuracy: 0.5100 - val_loss: 3.3686 - val_accuracy: 0.2433\n",
      "Epoch 2900/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2616 - accuracy: 0.5100 - val_loss: 3.3612 - val_accuracy: 0.2433\n",
      "Epoch 2901/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2619 - accuracy: 0.5114 - val_loss: 3.3752 - val_accuracy: 0.2400\n",
      "Epoch 2902/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2625 - accuracy: 0.5100 - val_loss: 3.4206 - val_accuracy: 0.2467\n",
      "Epoch 2903/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2625 - accuracy: 0.5086 - val_loss: 3.3530 - val_accuracy: 0.2400\n",
      "Epoch 2904/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2620 - accuracy: 0.5100 - val_loss: 3.3491 - val_accuracy: 0.2400\n",
      "Epoch 2905/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2617 - accuracy: 0.5114 - val_loss: 3.3764 - val_accuracy: 0.2433\n",
      "Epoch 2906/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2619 - accuracy: 0.5071 - val_loss: 3.3757 - val_accuracy: 0.2467\n",
      "Epoch 2907/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2611 - accuracy: 0.5057 - val_loss: 3.3800 - val_accuracy: 0.2467\n",
      "Epoch 2908/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2615 - accuracy: 0.5171 - val_loss: 3.4058 - val_accuracy: 0.2400\n",
      "Epoch 2909/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2618 - accuracy: 0.5029 - val_loss: 3.3454 - val_accuracy: 0.2433\n",
      "Epoch 2910/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2617 - accuracy: 0.5143 - val_loss: 3.3665 - val_accuracy: 0.2433\n",
      "Epoch 2911/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2620 - accuracy: 0.5029 - val_loss: 3.3131 - val_accuracy: 0.2333\n",
      "Epoch 2912/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2621 - accuracy: 0.5057 - val_loss: 3.3230 - val_accuracy: 0.2367\n",
      "Epoch 2913/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2621 - accuracy: 0.5043 - val_loss: 3.3574 - val_accuracy: 0.2433\n",
      "Epoch 2914/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2616 - accuracy: 0.5057 - val_loss: 3.3507 - val_accuracy: 0.2400\n",
      "Epoch 2915/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2620 - accuracy: 0.5071 - val_loss: 3.3117 - val_accuracy: 0.2367\n",
      "Epoch 2916/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2619 - accuracy: 0.5071 - val_loss: 3.4026 - val_accuracy: 0.2467\n",
      "Epoch 2917/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2614 - accuracy: 0.5114 - val_loss: 3.3731 - val_accuracy: 0.2467\n",
      "Epoch 2918/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2616 - accuracy: 0.5129 - val_loss: 3.3862 - val_accuracy: 0.2467\n",
      "Epoch 2919/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2611 - accuracy: 0.5100 - val_loss: 3.3899 - val_accuracy: 0.2433\n",
      "Epoch 2920/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2608 - accuracy: 0.5071 - val_loss: 3.3499 - val_accuracy: 0.2367\n",
      "Epoch 2921/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2613 - accuracy: 0.5100 - val_loss: 3.3484 - val_accuracy: 0.2400\n",
      "Epoch 2922/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2610 - accuracy: 0.5057 - val_loss: 3.3905 - val_accuracy: 0.2400\n",
      "Epoch 2923/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2609 - accuracy: 0.5129 - val_loss: 3.3561 - val_accuracy: 0.2467\n",
      "Epoch 2924/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2613 - accuracy: 0.5114 - val_loss: 3.3779 - val_accuracy: 0.2467\n",
      "Epoch 2925/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2608 - accuracy: 0.5100 - val_loss: 3.4046 - val_accuracy: 0.2433\n",
      "Epoch 2926/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2613 - accuracy: 0.5114 - val_loss: 3.3811 - val_accuracy: 0.2433\n",
      "Epoch 2927/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2618 - accuracy: 0.5086 - val_loss: 3.4173 - val_accuracy: 0.2467\n",
      "Epoch 2928/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 104us/step - loss: 1.2611 - accuracy: 0.5100 - val_loss: 3.3681 - val_accuracy: 0.2433\n",
      "Epoch 2929/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2606 - accuracy: 0.5086 - val_loss: 3.3886 - val_accuracy: 0.2467\n",
      "Epoch 2930/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2604 - accuracy: 0.5057 - val_loss: 3.4308 - val_accuracy: 0.2467\n",
      "Epoch 2931/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2609 - accuracy: 0.5071 - val_loss: 3.4096 - val_accuracy: 0.2433\n",
      "Epoch 2932/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2608 - accuracy: 0.5043 - val_loss: 3.3770 - val_accuracy: 0.2433\n",
      "Epoch 2933/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2604 - accuracy: 0.5129 - val_loss: 3.3914 - val_accuracy: 0.2400\n",
      "Epoch 2934/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2614 - accuracy: 0.5100 - val_loss: 3.4000 - val_accuracy: 0.2467\n",
      "Epoch 2935/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2613 - accuracy: 0.5114 - val_loss: 3.3797 - val_accuracy: 0.2400\n",
      "Epoch 2936/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2602 - accuracy: 0.5129 - val_loss: 3.3810 - val_accuracy: 0.2467\n",
      "Epoch 2937/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2610 - accuracy: 0.5114 - val_loss: 3.4107 - val_accuracy: 0.2433\n",
      "Epoch 2938/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2619 - accuracy: 0.5086 - val_loss: 3.3753 - val_accuracy: 0.2467\n",
      "Epoch 2939/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2610 - accuracy: 0.5086 - val_loss: 3.3962 - val_accuracy: 0.2467\n",
      "Epoch 2940/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2604 - accuracy: 0.5100 - val_loss: 3.4034 - val_accuracy: 0.2400\n",
      "Epoch 2941/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2597 - accuracy: 0.5071 - val_loss: 3.3383 - val_accuracy: 0.2400\n",
      "Epoch 2942/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2626 - accuracy: 0.5100 - val_loss: 3.3910 - val_accuracy: 0.2433\n",
      "Epoch 2943/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2603 - accuracy: 0.5114 - val_loss: 3.4167 - val_accuracy: 0.2433\n",
      "Epoch 2944/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2603 - accuracy: 0.5114 - val_loss: 3.3795 - val_accuracy: 0.2433\n",
      "Epoch 2945/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2602 - accuracy: 0.5114 - val_loss: 3.4175 - val_accuracy: 0.2467\n",
      "Epoch 2946/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2602 - accuracy: 0.5071 - val_loss: 3.4193 - val_accuracy: 0.2433\n",
      "Epoch 2947/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2605 - accuracy: 0.5100 - val_loss: 3.3645 - val_accuracy: 0.2433\n",
      "Epoch 2948/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2601 - accuracy: 0.5071 - val_loss: 3.4020 - val_accuracy: 0.2433\n",
      "Epoch 2949/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2612 - accuracy: 0.5114 - val_loss: 3.3740 - val_accuracy: 0.2367\n",
      "Epoch 2950/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2602 - accuracy: 0.5157 - val_loss: 3.3758 - val_accuracy: 0.2433\n",
      "Epoch 2951/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2606 - accuracy: 0.5114 - val_loss: 3.4402 - val_accuracy: 0.2400\n",
      "Epoch 2952/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2603 - accuracy: 0.5100 - val_loss: 3.4025 - val_accuracy: 0.2367\n",
      "Epoch 2953/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2600 - accuracy: 0.5100 - val_loss: 3.4009 - val_accuracy: 0.2467\n",
      "Epoch 2954/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2619 - accuracy: 0.5071 - val_loss: 3.3987 - val_accuracy: 0.2433\n",
      "Epoch 2955/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2600 - accuracy: 0.5086 - val_loss: 3.3483 - val_accuracy: 0.2400\n",
      "Epoch 2956/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2604 - accuracy: 0.5071 - val_loss: 3.3517 - val_accuracy: 0.2367\n",
      "Epoch 2957/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2601 - accuracy: 0.5129 - val_loss: 3.4081 - val_accuracy: 0.2433\n",
      "Epoch 2958/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2607 - accuracy: 0.5086 - val_loss: 3.3981 - val_accuracy: 0.2433\n",
      "Epoch 2959/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2602 - accuracy: 0.5057 - val_loss: 3.3814 - val_accuracy: 0.2433\n",
      "Epoch 2960/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2604 - accuracy: 0.5143 - val_loss: 3.3939 - val_accuracy: 0.2400\n",
      "Epoch 2961/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2596 - accuracy: 0.5171 - val_loss: 3.3864 - val_accuracy: 0.2400\n",
      "Epoch 2962/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2601 - accuracy: 0.5071 - val_loss: 3.4121 - val_accuracy: 0.2433\n",
      "Epoch 2963/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2595 - accuracy: 0.5114 - val_loss: 3.3911 - val_accuracy: 0.2433\n",
      "Epoch 2964/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2598 - accuracy: 0.5057 - val_loss: 3.3788 - val_accuracy: 0.2400\n",
      "Epoch 2965/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2599 - accuracy: 0.5129 - val_loss: 3.3494 - val_accuracy: 0.2400\n",
      "Epoch 2966/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2597 - accuracy: 0.5086 - val_loss: 3.3748 - val_accuracy: 0.2367\n",
      "Epoch 2967/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2599 - accuracy: 0.5057 - val_loss: 3.3782 - val_accuracy: 0.2433\n",
      "Epoch 2968/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2596 - accuracy: 0.5043 - val_loss: 3.4237 - val_accuracy: 0.2433\n",
      "Epoch 2969/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2599 - accuracy: 0.5143 - val_loss: 3.4195 - val_accuracy: 0.2433\n",
      "Epoch 2970/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2588 - accuracy: 0.5129 - val_loss: 3.4507 - val_accuracy: 0.2433\n",
      "Epoch 2971/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2598 - accuracy: 0.5086 - val_loss: 3.3750 - val_accuracy: 0.2467\n",
      "Epoch 2972/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2598 - accuracy: 0.5129 - val_loss: 3.3832 - val_accuracy: 0.2433\n",
      "Epoch 2973/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2595 - accuracy: 0.5086 - val_loss: 3.3602 - val_accuracy: 0.2400\n",
      "Epoch 2974/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2591 - accuracy: 0.5129 - val_loss: 3.3969 - val_accuracy: 0.2433\n",
      "Epoch 2975/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2595 - accuracy: 0.5100 - val_loss: 3.4095 - val_accuracy: 0.2433\n",
      "Epoch 2976/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2595 - accuracy: 0.5100 - val_loss: 3.4135 - val_accuracy: 0.2433\n",
      "Epoch 2977/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2589 - accuracy: 0.5100 - val_loss: 3.4090 - val_accuracy: 0.2400\n",
      "Epoch 2978/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2587 - accuracy: 0.5143 - val_loss: 3.4170 - val_accuracy: 0.2467\n",
      "Epoch 2979/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2591 - accuracy: 0.5129 - val_loss: 3.3656 - val_accuracy: 0.2467\n",
      "Epoch 2980/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2588 - accuracy: 0.5071 - val_loss: 3.4359 - val_accuracy: 0.2467\n",
      "Epoch 2981/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2594 - accuracy: 0.5114 - val_loss: 3.4116 - val_accuracy: 0.2467\n",
      "Epoch 2982/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2595 - accuracy: 0.5114 - val_loss: 3.3728 - val_accuracy: 0.2433\n",
      "Epoch 2983/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2593 - accuracy: 0.5114 - val_loss: 3.4204 - val_accuracy: 0.2433\n",
      "Epoch 2984/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2587 - accuracy: 0.5129 - val_loss: 3.4150 - val_accuracy: 0.2467\n",
      "Epoch 2985/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2592 - accuracy: 0.5114 - val_loss: 3.4272 - val_accuracy: 0.2467\n",
      "Epoch 2986/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2587 - accuracy: 0.5129 - val_loss: 3.4170 - val_accuracy: 0.2433\n",
      "Epoch 2987/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2592 - accuracy: 0.5114 - val_loss: 3.4234 - val_accuracy: 0.2433\n",
      "Epoch 2988/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2591 - accuracy: 0.5143 - val_loss: 3.4228 - val_accuracy: 0.2400\n",
      "Epoch 2989/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2587 - accuracy: 0.5071 - val_loss: 3.4008 - val_accuracy: 0.2433\n",
      "Epoch 2990/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2586 - accuracy: 0.5129 - val_loss: 3.4220 - val_accuracy: 0.2433\n",
      "Epoch 2991/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2596 - accuracy: 0.5143 - val_loss: 3.3987 - val_accuracy: 0.2433\n",
      "Epoch 2992/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2594 - accuracy: 0.5114 - val_loss: 3.4029 - val_accuracy: 0.2467\n",
      "Epoch 2993/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2589 - accuracy: 0.5086 - val_loss: 3.4200 - val_accuracy: 0.2433\n",
      "Epoch 2994/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2589 - accuracy: 0.5100 - val_loss: 3.3714 - val_accuracy: 0.2467\n",
      "Epoch 2995/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2583 - accuracy: 0.5071 - val_loss: 3.4406 - val_accuracy: 0.2467\n",
      "Epoch 2996/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2586 - accuracy: 0.5114 - val_loss: 3.4515 - val_accuracy: 0.2467\n",
      "Epoch 2997/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2585 - accuracy: 0.5100 - val_loss: 3.3971 - val_accuracy: 0.2400\n",
      "Epoch 2998/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2587 - accuracy: 0.5114 - val_loss: 3.4285 - val_accuracy: 0.2433\n",
      "Epoch 2999/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2585 - accuracy: 0.5071 - val_loss: 3.4221 - val_accuracy: 0.2433\n",
      "Epoch 3000/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2591 - accuracy: 0.5086 - val_loss: 3.4185 - val_accuracy: 0.2467\n"
     ]
    }
   ],
   "source": [
    "#모델 학습\n",
    "hist = model.fit(xTrain,yTrain,epochs=3000, batch_size=10, validation_data=(xVal,yVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#시각화\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figs, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'r',label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'],'b',label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'],'g',label='val acc')\n",
    "\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='lower left')\n",
    "loss_ax.legend(loc='upper left')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 15us/step\n",
      "cost:3.706244239425659\n",
      "accuracy:0.2597000002861023\n"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(xTest, yTest, batch_size=32)\n",
    "print(\"cost:\"+ str(res[0]))\n",
    "print(\"accuracy:\"+ str(res[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#조기 종료: earlystopping\n",
    "#callback (함수): 어떤 상황이 되었을 때(val loss가 떨어지다가 다시 올라가기 시작한 시점), \n",
    "#함수 내에서 또 다른 어떤 함수를 호출하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2585 - accuracy: 0.5114 - val_loss: 3.4252 - val_accuracy: 0.2433\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2583 - accuracy: 0.5143 - val_loss: 3.4071 - val_accuracy: 0.2433\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2588 - accuracy: 0.5114 - val_loss: 3.3381 - val_accuracy: 0.2400\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2589 - accuracy: 0.5086 - val_loss: 3.3982 - val_accuracy: 0.2433\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2585 - accuracy: 0.5100 - val_loss: 3.4151 - val_accuracy: 0.2367\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2581 - accuracy: 0.5143 - val_loss: 3.4095 - val_accuracy: 0.2433\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2587 - accuracy: 0.5171 - val_loss: 3.3927 - val_accuracy: 0.2367\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2587 - accuracy: 0.5157 - val_loss: 3.4531 - val_accuracy: 0.2467\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2578 - accuracy: 0.5143 - val_loss: 3.4132 - val_accuracy: 0.2433\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2585 - accuracy: 0.5114 - val_loss: 3.4323 - val_accuracy: 0.2367\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2579 - accuracy: 0.5143 - val_loss: 3.4505 - val_accuracy: 0.2433\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2577 - accuracy: 0.5086 - val_loss: 3.4505 - val_accuracy: 0.2467\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2580 - accuracy: 0.5057 - val_loss: 3.4440 - val_accuracy: 0.2400\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2581 - accuracy: 0.5086 - val_loss: 3.4225 - val_accuracy: 0.2433\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2576 - accuracy: 0.5086 - val_loss: 3.4250 - val_accuracy: 0.2400\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2586 - accuracy: 0.5057 - val_loss: 3.4298 - val_accuracy: 0.2467\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2576 - accuracy: 0.5129 - val_loss: 3.4208 - val_accuracy: 0.2367\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2587 - accuracy: 0.5100 - val_loss: 3.4510 - val_accuracy: 0.2433\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2578 - accuracy: 0.5057 - val_loss: 3.4008 - val_accuracy: 0.2433\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2580 - accuracy: 0.5014 - val_loss: 3.4282 - val_accuracy: 0.2400\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2570 - accuracy: 0.5071 - val_loss: 3.4172 - val_accuracy: 0.2433\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2582 - accuracy: 0.5071 - val_loss: 3.3821 - val_accuracy: 0.2433\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2581 - accuracy: 0.5071 - val_loss: 3.3811 - val_accuracy: 0.2367\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2584 - accuracy: 0.5057 - val_loss: 3.4647 - val_accuracy: 0.2467\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2574 - accuracy: 0.5057 - val_loss: 3.4375 - val_accuracy: 0.2400\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2571 - accuracy: 0.5086 - val_loss: 3.4656 - val_accuracy: 0.2400\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2580 - accuracy: 0.5086 - val_loss: 3.4427 - val_accuracy: 0.2467\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2583 - accuracy: 0.5114 - val_loss: 3.4186 - val_accuracy: 0.2400\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2578 - accuracy: 0.5071 - val_loss: 3.4367 - val_accuracy: 0.2433\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2568 - accuracy: 0.5100 - val_loss: 3.4315 - val_accuracy: 0.2433\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2574 - accuracy: 0.5157 - val_loss: 3.4621 - val_accuracy: 0.2433\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2573 - accuracy: 0.5114 - val_loss: 3.4327 - val_accuracy: 0.2467\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2579 - accuracy: 0.5114 - val_loss: 3.4361 - val_accuracy: 0.2400\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(xTrain,yTrain,epochs=3000, batch_size=10, validation_data=(xVal,yVal), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figs, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'r',label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'],'b',label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'],'g',label='val acc')\n",
    "\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='lower left')\n",
    "loss_ax.legend(loc='upper left')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = np.loadtxt(\"dataset (1)/ThoraricSurgery.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(470, 18)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[:,0:17]\n",
    "y = dataset[:,17] #1: 수술 후 생존, 0: 사망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=17, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "470/470 [==============================] - 0s 447us/step - loss: 0.6485 - accuracy: 0.3234\n",
      "Epoch 2/30\n",
      "470/470 [==============================] - 0s 89us/step - loss: 0.1497 - accuracy: 0.8489\n",
      "Epoch 3/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1486 - accuracy: 0.8511\n",
      "Epoch 4/30\n",
      "470/470 [==============================] - 0s 87us/step - loss: 0.1481 - accuracy: 0.8511\n",
      "Epoch 5/30\n",
      "470/470 [==============================] - 0s 87us/step - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 6/30\n",
      "470/470 [==============================] - 0s 87us/step - loss: 0.1485 - accuracy: 0.8511\n",
      "Epoch 7/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 8/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.1486 - accuracy: 0.8511\n",
      "Epoch 9/30\n",
      "470/470 [==============================] - 0s 89us/step - loss: 0.1478 - accuracy: 0.8532\n",
      "Epoch 10/30\n",
      "470/470 [==============================] - 0s 87us/step - loss: 0.1474 - accuracy: 0.8532\n",
      "Epoch 11/30\n",
      "470/470 [==============================] - 0s 91us/step - loss: 0.1480 - accuracy: 0.8511\n",
      "Epoch 12/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1475 - accuracy: 0.8511\n",
      "Epoch 13/30\n",
      "470/470 [==============================] - 0s 89us/step - loss: 0.1481 - accuracy: 0.8511\n",
      "Epoch 14/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1472 - accuracy: 0.8532\n",
      "Epoch 15/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.1475 - accuracy: 0.8532\n",
      "Epoch 16/30\n",
      "470/470 [==============================] - 0s 79us/step - loss: 0.1472 - accuracy: 0.8532\n",
      "Epoch 17/30\n",
      "470/470 [==============================] - 0s 87us/step - loss: 0.1477 - accuracy: 0.8511\n",
      "Epoch 18/30\n",
      "470/470 [==============================] - 0s 87us/step - loss: 0.1474 - accuracy: 0.8532\n",
      "Epoch 19/30\n",
      "470/470 [==============================] - 0s 77us/step - loss: 0.1476 - accuracy: 0.8511\n",
      "Epoch 20/30\n",
      "470/470 [==============================] - 0s 79us/step - loss: 0.1479 - accuracy: 0.8511\n",
      "Epoch 21/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.1470 - accuracy: 0.8532\n",
      "Epoch 22/30\n",
      "470/470 [==============================] - 0s 79us/step - loss: 0.1483 - accuracy: 0.8489\n",
      "Epoch 23/30\n",
      "470/470 [==============================] - 0s 77us/step - loss: 0.1486 - accuracy: 0.8511\n",
      "Epoch 24/30\n",
      "470/470 [==============================] - 0s 79us/step - loss: 0.1485 - accuracy: 0.8511\n",
      "Epoch 25/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1475 - accuracy: 0.8511\n",
      "Epoch 26/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1446 - accuracy: 0.8511\n",
      "Epoch 27/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1434 - accuracy: 0.8489\n",
      "Epoch 28/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1457 - accuracy: 0.8511\n",
      "Epoch 29/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1451 - accuracy: 0.8532\n",
      "Epoch 30/30\n",
      "470/470 [==============================] - 0s 79us/step - loss: 0.1437 - accuracy: 0.8511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x210ac694108>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y, epochs=30, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 0s 21us/step\n",
      "0.8510638475418091\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x,y)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.294118 ,  0.487437 ,  0.180328 , ..., -0.53117  , -0.0333333,\n",
       "         0.       ],\n",
       "       [-0.882353 , -0.145729 ,  0.0819672, ..., -0.766866 , -0.666667 ,\n",
       "         1.       ],\n",
       "       [-0.0588235,  0.839196 ,  0.0491803, ..., -0.492741 , -0.633333 ,\n",
       "         0.       ],\n",
       "       ...,\n",
       "       [-0.411765 ,  0.21608  ,  0.180328 , ..., -0.857387 , -0.7      ,\n",
       "         1.       ],\n",
       "       [-0.882353 ,  0.266332 , -0.0163934, ..., -0.768574 , -0.133333 ,\n",
       "         0.       ],\n",
       "       [-0.882353 , -0.0653266,  0.147541 , ..., -0.797609 , -0.933333 ,\n",
       "         1.       ]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy = np.loadtxt(\"실습데이터/실습데이터/data-03-diabetes.csv\", delimiter=\",\")\n",
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = xy[:,0:-1]\n",
    "ydata = xy[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 8) (759, 1)\n"
     ]
    }
   ],
   "source": [
    "print(xdata.shape, ydata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([8,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "x = tf.placeholder(tf.float32, shape=[None,8])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = tf.sigmoid(tf.matmul(x,w)+b)\n",
    "cost = -tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hf>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8359697\n",
      "200 0.80319196\n",
      "400 0.7740957\n",
      "600 0.7479811\n",
      "800 0.7245134\n",
      "1000 0.70343196\n",
      "1200 0.6844999\n",
      "1400 0.66749644\n",
      "1600 0.6522184\n",
      "1800 0.638479\n",
      "2000 0.6261095\n",
      "2200 0.614958\n",
      "2400 0.60488886\n",
      "2600 0.59578115\n",
      "2800 0.5875278\n",
      "3000 0.58003426\n",
      "3200 0.57321656\n",
      "3400 0.56700087\n",
      "3600 0.56132257\n",
      "3800 0.5561241\n",
      "4000 0.55135506\n",
      "4200 0.5469711\n",
      "4400 0.54293287\n",
      "4600 0.539206\n",
      "4800 0.53575975\n",
      "5000 0.53256726\n",
      "5200 0.5296044\n",
      "5400 0.52685\n",
      "5600 0.524285\n",
      "5800 0.5218928\n",
      "6000 0.5196582\n",
      "6200 0.5175677\n",
      "6400 0.51560926\n",
      "6600 0.51377225\n",
      "6800 0.51204664\n",
      "7000 0.51042366\n",
      "7200 0.5088955\n",
      "7400 0.5074549\n",
      "7600 0.5060953\n",
      "7800 0.50481075\n",
      "8000 0.5035959\n",
      "8200 0.5024457\n",
      "8400 0.5013559\n",
      "8600 0.50032204\n",
      "8800 0.4993406\n",
      "9000 0.49840805\n",
      "9200 0.49752116\n",
      "9400 0.49667695\n",
      "9600 0.49587294\n",
      "9800 0.4951064\n",
      "10000 0.4943751\n",
      "[[0.4230725 ]\n",
      " [0.914369  ]\n",
      " [0.14699051]\n",
      " [0.94097066]\n",
      " [0.2386195 ]\n",
      " [0.6912104 ]\n",
      " [0.94149905]\n",
      " [0.6192848 ]\n",
      " [0.22873637]\n",
      " [0.52304906]\n",
      " [0.7228858 ]\n",
      " [0.18578693]\n",
      " [0.20333445]\n",
      " [0.29197645]\n",
      " [0.7200069 ]\n",
      " [0.5596808 ]\n",
      " [0.6967195 ]\n",
      " [0.91246235]\n",
      " [0.8255722 ]\n",
      " [0.6181627 ]\n",
      " [0.69197416]\n",
      " [0.1148724 ]\n",
      " [0.6137438 ]\n",
      " [0.6679759 ]\n",
      " [0.41361412]\n",
      " [0.9122215 ]\n",
      " [0.45929202]\n",
      " [0.6336385 ]\n",
      " [0.7555078 ]\n",
      " [0.39732856]\n",
      " [0.94110143]\n",
      " [0.7853086 ]\n",
      " [0.5428752 ]\n",
      " [0.77118295]\n",
      " [0.3513832 ]\n",
      " [0.6575571 ]\n",
      " [0.8550167 ]\n",
      " [0.58495146]\n",
      " [0.44854644]\n",
      " [0.4129784 ]\n",
      " [0.78068584]\n",
      " [0.21398133]\n",
      " [0.34370983]\n",
      " [0.07198992]\n",
      " [0.53725094]\n",
      " [0.92325544]\n",
      " [0.7698746 ]\n",
      " [0.717465  ]\n",
      " [0.89787936]\n",
      " [0.9159502 ]\n",
      " [0.91162205]\n",
      " [0.2305533 ]\n",
      " [0.3648944 ]\n",
      " [0.9621988 ]\n",
      " [0.23019388]\n",
      " [0.5739669 ]\n",
      " [0.15091828]\n",
      " [0.77187485]\n",
      " [0.8874912 ]\n",
      " [0.49481267]\n",
      " [0.9369968 ]\n",
      " [0.63356096]\n",
      " [0.6657622 ]\n",
      " [0.84036267]\n",
      " [0.5898247 ]\n",
      " [0.6644412 ]\n",
      " [0.933225  ]\n",
      " [0.6364888 ]\n",
      " [0.85983634]\n",
      " [0.61714894]\n",
      " [0.33620304]\n",
      " [0.72937495]\n",
      " [0.9182645 ]\n",
      " [0.91459894]\n",
      " [0.883294  ]\n",
      " [0.8257558 ]\n",
      " [0.51237917]\n",
      " [0.83447266]\n",
      " [0.8720162 ]\n",
      " [0.92351496]\n",
      " [0.85182595]\n",
      " [0.7808575 ]\n",
      " [0.48308566]\n",
      " [0.806779  ]\n",
      " [0.57195973]\n",
      " [0.89719987]\n",
      " [0.4595641 ]\n",
      " [0.8817462 ]\n",
      " [0.9139867 ]\n",
      " [0.76924306]\n",
      " [0.88180894]\n",
      " [0.58890045]\n",
      " [0.65304327]\n",
      " [0.5922367 ]\n",
      " [0.9069594 ]\n",
      " [0.96655023]\n",
      " [0.8814665 ]\n",
      " [0.7187626 ]\n",
      " [0.2716311 ]\n",
      " [0.5687622 ]\n",
      " [0.5048679 ]\n",
      " [0.95088834]\n",
      " [0.81472117]\n",
      " [0.75117004]\n",
      " [0.80885315]\n",
      " [0.6663033 ]\n",
      " [0.9291595 ]\n",
      " [0.83837724]\n",
      " [0.4700927 ]\n",
      " [0.37949198]\n",
      " [0.92551625]\n",
      " [0.8809451 ]\n",
      " [0.40772152]\n",
      " [0.41511077]\n",
      " [0.63680446]\n",
      " [0.8496694 ]\n",
      " [0.85524696]\n",
      " [0.9028442 ]\n",
      " [0.22935599]\n",
      " [0.73790514]\n",
      " [0.852175  ]\n",
      " [0.5855722 ]\n",
      " [0.61458635]\n",
      " [0.92036927]\n",
      " [0.77541506]\n",
      " [0.84054613]\n",
      " [0.82296187]\n",
      " [0.57838625]\n",
      " [0.47348064]\n",
      " [0.40948522]\n",
      " [0.42848575]\n",
      " [0.8242445 ]\n",
      " [0.9035864 ]\n",
      " [0.8467825 ]\n",
      " [0.79023623]\n",
      " [0.83311284]\n",
      " [0.4099282 ]\n",
      " [0.82809097]\n",
      " [0.64437485]\n",
      " [0.78395104]\n",
      " [0.88452756]\n",
      " [0.6366031 ]\n",
      " [0.5586158 ]\n",
      " [0.73295176]\n",
      " [0.9164841 ]\n",
      " [0.7254159 ]\n",
      " [0.4719787 ]\n",
      " [0.92341626]\n",
      " [0.64667535]\n",
      " [0.7001949 ]\n",
      " [0.25451273]\n",
      " [0.43187976]\n",
      " [0.17217323]\n",
      " [0.36208677]\n",
      " [0.90263134]\n",
      " [0.8443297 ]\n",
      " [0.934667  ]\n",
      " [0.13724849]\n",
      " [0.4695118 ]\n",
      " [0.80664814]\n",
      " [0.70104986]\n",
      " [0.87491   ]\n",
      " [0.37571514]\n",
      " [0.7957814 ]\n",
      " [0.6112356 ]\n",
      " [0.60450643]\n",
      " [0.7143158 ]\n",
      " [0.84056246]\n",
      " [0.7473415 ]\n",
      " [0.64081454]\n",
      " [0.880496  ]\n",
      " [0.91657555]\n",
      " [0.94926554]\n",
      " [0.20000115]\n",
      " [0.8108421 ]\n",
      " [0.50101894]\n",
      " [0.5015225 ]\n",
      " [0.4348961 ]\n",
      " [0.8339046 ]\n",
      " [0.6841214 ]\n",
      " [0.9169986 ]\n",
      " [0.89169073]\n",
      " [0.536215  ]\n",
      " [0.15145823]\n",
      " [0.18281746]\n",
      " [0.5500579 ]\n",
      " [0.68125576]\n",
      " [0.5959459 ]\n",
      " [0.78602016]\n",
      " [0.61052805]\n",
      " [0.32368302]\n",
      " [0.3664883 ]\n",
      " [0.88961565]\n",
      " [0.4118702 ]\n",
      " [0.84079194]\n",
      " [0.8619199 ]\n",
      " [0.7206218 ]\n",
      " [0.6315391 ]\n",
      " [0.62762207]\n",
      " [0.61336267]\n",
      " [0.6770707 ]\n",
      " [0.91857   ]\n",
      " [0.81540215]\n",
      " [0.75767195]\n",
      " [0.1528678 ]\n",
      " [0.33309776]\n",
      " [0.9183607 ]\n",
      " [0.212785  ]\n",
      " [0.9297596 ]\n",
      " [0.3220175 ]\n",
      " [0.26233393]\n",
      " [0.5565806 ]\n",
      " [0.71155477]\n",
      " [0.26138216]\n",
      " [0.7684562 ]\n",
      " [0.6943912 ]\n",
      " [0.7914647 ]\n",
      " [0.71880186]\n",
      " [0.1644932 ]\n",
      " [0.33326712]\n",
      " [0.6487431 ]\n",
      " [0.50726295]\n",
      " [0.89834714]\n",
      " [0.93992925]\n",
      " [0.70789075]\n",
      " [0.40534028]\n",
      " [0.0379031 ]\n",
      " [0.74102724]\n",
      " [0.4226802 ]\n",
      " [0.58858514]\n",
      " [0.9318685 ]\n",
      " [0.64819473]\n",
      " [0.94420123]\n",
      " [0.28328967]\n",
      " [0.1764591 ]\n",
      " [0.2468616 ]\n",
      " [0.621454  ]\n",
      " [0.9192471 ]\n",
      " [0.8804463 ]\n",
      " [0.5736537 ]\n",
      " [0.6280307 ]\n",
      " [0.6238228 ]\n",
      " [0.1298329 ]\n",
      " [0.5365406 ]\n",
      " [0.22799355]\n",
      " [0.603983  ]\n",
      " [0.85592616]\n",
      " [0.67449075]\n",
      " [0.64057803]\n",
      " [0.93247116]\n",
      " [0.8355576 ]\n",
      " [0.7585257 ]\n",
      " [0.7908238 ]\n",
      " [0.7601992 ]\n",
      " [0.8477539 ]\n",
      " [0.3326198 ]\n",
      " [0.38730147]\n",
      " [0.47645828]\n",
      " [0.8158208 ]\n",
      " [0.6848355 ]\n",
      " [0.68243676]\n",
      " [0.8238605 ]\n",
      " [0.335005  ]\n",
      " [0.5510768 ]\n",
      " [0.5523377 ]\n",
      " [0.56847066]\n",
      " [0.53134054]\n",
      " [0.88697875]\n",
      " [0.6826369 ]\n",
      " [0.9319986 ]\n",
      " [0.5804217 ]\n",
      " [0.810167  ]\n",
      " [0.7905505 ]\n",
      " [0.7914951 ]\n",
      " [0.6123989 ]\n",
      " [0.8326267 ]\n",
      " [0.37729922]\n",
      " [0.6080841 ]\n",
      " [0.67383754]\n",
      " [0.32098395]\n",
      " [0.7803385 ]\n",
      " [0.32076716]\n",
      " [0.70204663]\n",
      " [0.9095465 ]\n",
      " [0.79875064]\n",
      " [0.8738531 ]\n",
      " [0.7187885 ]\n",
      " [0.5699978 ]\n",
      " [0.71813416]\n",
      " [0.33276373]\n",
      " [0.47391334]\n",
      " [0.59085435]\n",
      " [0.58036584]\n",
      " [0.6869159 ]\n",
      " [0.5402045 ]\n",
      " [0.18920666]\n",
      " [0.6661607 ]\n",
      " [0.9140148 ]\n",
      " [0.65738714]\n",
      " [0.4983361 ]\n",
      " [0.80171883]\n",
      " [0.40173468]\n",
      " [0.67563343]\n",
      " [0.46672794]\n",
      " [0.7057992 ]\n",
      " [0.8860199 ]\n",
      " [0.7029438 ]\n",
      " [0.63072664]\n",
      " [0.8580796 ]\n",
      " [0.5832638 ]\n",
      " [0.8644224 ]\n",
      " [0.9075004 ]\n",
      " [0.25863704]\n",
      " [0.81879497]\n",
      " [0.17929411]\n",
      " [0.750846  ]\n",
      " [0.8060317 ]\n",
      " [0.66542584]\n",
      " [0.27131832]\n",
      " [0.8246201 ]\n",
      " [0.67136395]\n",
      " [0.76493657]\n",
      " [0.18258703]\n",
      " [0.87241745]\n",
      " [0.8430375 ]\n",
      " [0.4869205 ]\n",
      " [0.9479584 ]\n",
      " [0.34315327]\n",
      " [0.60797817]\n",
      " [0.93334407]\n",
      " [0.30756053]\n",
      " [0.487853  ]\n",
      " [0.67263436]\n",
      " [0.31403306]\n",
      " [0.2016721 ]\n",
      " [0.8045496 ]\n",
      " [0.897108  ]\n",
      " [0.85723364]\n",
      " [0.61663914]\n",
      " [0.7189776 ]\n",
      " [0.61715364]\n",
      " [0.7490456 ]\n",
      " [0.74963385]\n",
      " [0.90665555]\n",
      " [0.8041326 ]\n",
      " [0.82222193]\n",
      " [0.5437006 ]\n",
      " [0.9468833 ]\n",
      " [0.9323759 ]\n",
      " [0.8124977 ]\n",
      " [0.23436838]\n",
      " [0.6977007 ]\n",
      " [0.43960202]\n",
      " [0.77801687]\n",
      " [0.20443201]\n",
      " [0.2249119 ]\n",
      " [0.40820986]\n",
      " [0.7496979 ]\n",
      " [0.44370347]\n",
      " [0.582623  ]\n",
      " [0.85915864]\n",
      " [0.5870754 ]\n",
      " [0.8131379 ]\n",
      " [0.93468416]\n",
      " [0.7409258 ]\n",
      " [0.09159499]\n",
      " [0.4871723 ]\n",
      " [0.8731228 ]\n",
      " [0.8713479 ]\n",
      " [0.7085031 ]\n",
      " [0.33251685]\n",
      " [0.84026325]\n",
      " [0.91343534]\n",
      " [0.42280343]\n",
      " [0.67705226]\n",
      " [0.824265  ]\n",
      " [0.7737602 ]\n",
      " [0.85441506]\n",
      " [0.8772963 ]\n",
      " [0.8303044 ]\n",
      " [0.89175355]\n",
      " [0.6827914 ]\n",
      " [0.7001184 ]\n",
      " [0.5582385 ]\n",
      " [0.83150756]\n",
      " [0.8848978 ]\n",
      " [0.31099555]\n",
      " [0.78023875]\n",
      " [0.8280441 ]\n",
      " [0.30159193]\n",
      " [0.5699862 ]\n",
      " [0.8339083 ]\n",
      " [0.55554086]\n",
      " [0.86677176]\n",
      " [0.27355313]\n",
      " [0.83489037]\n",
      " [0.6174633 ]\n",
      " [0.8818001 ]\n",
      " [0.35695797]\n",
      " [0.7839563 ]\n",
      " [0.6946746 ]\n",
      " [0.70582056]\n",
      " [0.06611347]\n",
      " [0.28378725]\n",
      " [0.68790007]\n",
      " [0.8263866 ]\n",
      " [0.53240126]\n",
      " [0.7501354 ]\n",
      " [0.52412015]\n",
      " [0.35995758]\n",
      " [0.8211469 ]\n",
      " [0.50614125]\n",
      " [0.86618686]\n",
      " [0.7751214 ]\n",
      " [0.74805516]\n",
      " [0.90795547]\n",
      " [0.74049574]\n",
      " [0.81427515]\n",
      " [0.41327047]\n",
      " [0.29061556]\n",
      " [0.7591909 ]\n",
      " [0.44063652]\n",
      " [0.49085677]\n",
      " [0.910507  ]\n",
      " [0.8528256 ]\n",
      " [0.9100565 ]\n",
      " [0.94664   ]\n",
      " [0.609091  ]\n",
      " [0.87172246]\n",
      " [0.4529848 ]\n",
      " [0.39538896]\n",
      " [0.4253993 ]\n",
      " [0.91653705]\n",
      " [0.61095107]\n",
      " [0.15738735]\n",
      " [0.9299943 ]\n",
      " [0.81829125]\n",
      " [0.5431637 ]\n",
      " [0.80346525]\n",
      " [0.0419026 ]\n",
      " [0.8986062 ]\n",
      " [0.7783656 ]\n",
      " [0.75116897]\n",
      " [0.7413169 ]\n",
      " [0.9488795 ]\n",
      " [0.57879776]\n",
      " [0.8218252 ]\n",
      " [0.65496814]\n",
      " [0.8858367 ]\n",
      " [0.19530094]\n",
      " [0.6039345 ]\n",
      " [0.9006679 ]\n",
      " [0.5682139 ]\n",
      " [0.6516615 ]\n",
      " [0.9187919 ]\n",
      " [0.86021245]\n",
      " [0.8664267 ]\n",
      " [0.3837297 ]\n",
      " [0.73138505]\n",
      " [0.9378091 ]\n",
      " [0.7735078 ]\n",
      " [0.6240611 ]\n",
      " [0.40485474]\n",
      " [0.5346304 ]\n",
      " [0.51799136]\n",
      " [0.67473304]\n",
      " [0.48092625]\n",
      " [0.74742794]\n",
      " [0.5347716 ]\n",
      " [0.772123  ]\n",
      " [0.7690745 ]\n",
      " [0.6708667 ]\n",
      " [0.6229638 ]\n",
      " [0.5169032 ]\n",
      " [0.5886049 ]\n",
      " [0.9285691 ]\n",
      " [0.8624175 ]\n",
      " [0.3441884 ]\n",
      " [0.51474637]\n",
      " [0.6094403 ]\n",
      " [0.17063624]\n",
      " [0.86475164]\n",
      " [0.11293536]\n",
      " [0.91658914]\n",
      " [0.88353676]\n",
      " [0.84189975]\n",
      " [0.6593369 ]\n",
      " [0.8965613 ]\n",
      " [0.30885392]\n",
      " [0.7212546 ]\n",
      " [0.9354614 ]\n",
      " [0.24113119]\n",
      " [0.38854846]\n",
      " [0.83855313]\n",
      " [0.8978633 ]\n",
      " [0.72212803]\n",
      " [0.8264264 ]\n",
      " [0.8460711 ]\n",
      " [0.80541027]\n",
      " [0.2722965 ]\n",
      " [0.7554804 ]\n",
      " [0.90899456]\n",
      " [0.5585538 ]\n",
      " [0.78679895]\n",
      " [0.6389134 ]\n",
      " [0.77199316]\n",
      " [0.8386824 ]\n",
      " [0.9181001 ]\n",
      " [0.58405495]\n",
      " [0.37241912]\n",
      " [0.7892805 ]\n",
      " [0.66632915]\n",
      " [0.9567685 ]\n",
      " [0.7548787 ]\n",
      " [0.7027654 ]\n",
      " [0.42149183]\n",
      " [0.7070221 ]\n",
      " [0.90698457]\n",
      " [0.9253936 ]\n",
      " [0.86584413]\n",
      " [0.6731804 ]\n",
      " [0.5760999 ]\n",
      " [0.79319495]\n",
      " [0.577784  ]\n",
      " [0.8573055 ]\n",
      " [0.784458  ]\n",
      " [0.9013772 ]\n",
      " [0.6069692 ]\n",
      " [0.66665393]\n",
      " [0.8702936 ]\n",
      " [0.49246517]\n",
      " [0.52392197]\n",
      " [0.7181438 ]\n",
      " [0.7209767 ]\n",
      " [0.69101226]\n",
      " [0.9213839 ]\n",
      " [0.92067355]\n",
      " [0.19115797]\n",
      " [0.19536659]\n",
      " [0.76595855]\n",
      " [0.50467724]\n",
      " [0.17176819]\n",
      " [0.8298005 ]\n",
      " [0.9019302 ]\n",
      " [0.6611012 ]\n",
      " [0.9318881 ]\n",
      " [0.9336409 ]\n",
      " [0.70387316]\n",
      " [0.8716784 ]\n",
      " [0.66227895]\n",
      " [0.7024957 ]\n",
      " [0.7413882 ]\n",
      " [0.6262063 ]\n",
      " [0.14916268]\n",
      " [0.91945577]\n",
      " [0.8629087 ]\n",
      " [0.69637996]\n",
      " [0.9030936 ]\n",
      " [0.8986735 ]\n",
      " [0.89201903]\n",
      " [0.5632142 ]\n",
      " [0.7070823 ]\n",
      " [0.890541  ]\n",
      " [0.62331235]\n",
      " [0.839575  ]\n",
      " [0.9218378 ]\n",
      " [0.5352216 ]\n",
      " [0.8272587 ]\n",
      " [0.79624754]\n",
      " [0.6504942 ]\n",
      " [0.4576444 ]\n",
      " [0.09075683]\n",
      " [0.32320893]\n",
      " [0.7959027 ]\n",
      " [0.6101089 ]\n",
      " [0.7281353 ]\n",
      " [0.5406319 ]\n",
      " [0.9189205 ]\n",
      " [0.46056163]\n",
      " [0.75140744]\n",
      " [0.2647856 ]\n",
      " [0.84543335]\n",
      " [0.46911094]\n",
      " [0.804011  ]\n",
      " [0.5843982 ]\n",
      " [0.84822464]\n",
      " [0.5778177 ]\n",
      " [0.20553645]\n",
      " [0.87030137]\n",
      " [0.94608116]\n",
      " [0.40605196]\n",
      " [0.90203846]\n",
      " [0.8391766 ]\n",
      " [0.8010332 ]\n",
      " [0.7784313 ]\n",
      " [0.44254264]\n",
      " [0.27378905]\n",
      " [0.75121975]\n",
      " [0.20155188]\n",
      " [0.91998446]\n",
      " [0.39469993]\n",
      " [0.90355086]\n",
      " [0.8820218 ]\n",
      " [0.4292792 ]\n",
      " [0.21796057]\n",
      " [0.6861094 ]\n",
      " [0.4738428 ]\n",
      " [0.785981  ]\n",
      " [0.6363847 ]\n",
      " [0.9688422 ]\n",
      " [0.5087153 ]\n",
      " [0.62386703]\n",
      " [0.8044995 ]\n",
      " [0.7422031 ]\n",
      " [0.08354011]\n",
      " [0.8365122 ]\n",
      " [0.811203  ]\n",
      " [0.8534825 ]\n",
      " [0.5643236 ]\n",
      " [0.458037  ]\n",
      " [0.61540926]\n",
      " [0.89206225]\n",
      " [0.578599  ]\n",
      " [0.7716627 ]\n",
      " [0.7725043 ]\n",
      " [0.825102  ]\n",
      " [0.7563535 ]\n",
      " [0.5460244 ]\n",
      " [0.77095056]\n",
      " [0.89477915]\n",
      " [0.75965035]\n",
      " [0.9305817 ]\n",
      " [0.76020616]\n",
      " [0.6198907 ]\n",
      " [0.44869864]\n",
      " [0.8069095 ]\n",
      " [0.81602925]\n",
      " [0.5405268 ]\n",
      " [0.5595857 ]\n",
      " [0.26626447]\n",
      " [0.49607903]\n",
      " [0.77915645]\n",
      " [0.93560743]\n",
      " [0.847402  ]\n",
      " [0.72334576]\n",
      " [0.71390676]\n",
      " [0.8928148 ]\n",
      " [0.5826893 ]\n",
      " [0.89747334]\n",
      " [0.6161086 ]\n",
      " [0.84436566]\n",
      " [0.2565821 ]\n",
      " [0.1074056 ]\n",
      " [0.27611652]\n",
      " [0.36881033]\n",
      " [0.72591126]\n",
      " [0.8247169 ]\n",
      " [0.6242893 ]\n",
      " [0.7121432 ]\n",
      " [0.8345103 ]\n",
      " [0.46885768]\n",
      " [0.39068994]\n",
      " [0.89797723]\n",
      " [0.896654  ]\n",
      " [0.6050008 ]\n",
      " [0.7144235 ]\n",
      " [0.15649158]\n",
      " [0.30101395]\n",
      " [0.76466984]\n",
      " [0.74251974]\n",
      " [0.87564147]\n",
      " [0.9709016 ]\n",
      " [0.30414295]\n",
      " [0.8049431 ]\n",
      " [0.5804358 ]\n",
      " [0.46232894]\n",
      " [0.7191883 ]\n",
      " [0.63700116]\n",
      " [0.8934251 ]\n",
      " [0.63314956]\n",
      " [0.6147001 ]\n",
      " [0.55347466]\n",
      " [0.17899126]\n",
      " [0.721832  ]\n",
      " [0.58153325]\n",
      " [0.8768815 ]\n",
      " [0.5414257 ]\n",
      " [0.52688193]\n",
      " [0.73171365]\n",
      " [0.72707176]\n",
      " [0.574578  ]\n",
      " [0.7697034 ]\n",
      " [0.6074804 ]\n",
      " [0.34405607]\n",
      " [0.6755252 ]\n",
      " [0.8638054 ]\n",
      " [0.87542564]\n",
      " [0.59540856]\n",
      " [0.81775725]\n",
      " [0.27562395]\n",
      " [0.87396765]\n",
      " [0.5896384 ]\n",
      " [0.7254236 ]\n",
      " [0.51112586]\n",
      " [0.6265376 ]\n",
      " [0.814144  ]\n",
      " [0.17961505]\n",
      " [0.27598047]\n",
      " [0.76630414]\n",
      " [0.8313229 ]\n",
      " [0.8297701 ]\n",
      " [0.898641  ]\n",
      " [0.83837026]\n",
      " [0.6722281 ]\n",
      " [0.7716393 ]\n",
      " [0.7624773 ]\n",
      " [0.7539706 ]\n",
      " [0.80828893]\n",
      " [0.45936513]\n",
      " [0.30214813]\n",
      " [0.8803084 ]\n",
      " [0.7606029 ]\n",
      " [0.563666  ]\n",
      " [0.3465441 ]\n",
      " [0.86832666]\n",
      " [0.7598106 ]\n",
      " [0.8609993 ]\n",
      " [0.61022377]\n",
      " [0.8941752 ]\n",
      " [0.90307736]\n",
      " [0.8238083 ]\n",
      " [0.50406504]\n",
      " [0.8984375 ]\n",
      " [0.90280116]\n",
      " [0.3010078 ]\n",
      " [0.18009445]\n",
      " [0.69320536]\n",
      " [0.5367485 ]\n",
      " [0.87248135]\n",
      " [0.35264015]\n",
      " [0.37303516]\n",
      " [0.38925943]\n",
      " [0.80318856]\n",
      " [0.8457115 ]\n",
      " [0.17539996]\n",
      " [0.369698  ]\n",
      " [0.61679137]\n",
      " [0.46816313]\n",
      " [0.56109655]\n",
      " [0.81339777]\n",
      " [0.16563323]\n",
      " [0.9055291 ]\n",
      " [0.26299754]\n",
      " [0.7927603 ]\n",
      " [0.73323697]\n",
      " [0.76679367]\n",
      " [0.78577495]\n",
      " [0.7106531 ]\n",
      " [0.89026535]] [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.7549407\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        cv,_ = sess.run([cost,train], feed_dict={x:xdata,y:ydata})\n",
    "        if step%200==0:\n",
    "            print(step,cv)\n",
    "    hv,pv,av = sess.run([hf,predicted,accuracy], feed_dict={x:xdata, y:ydata})\n",
    "    print(hv,pv,av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>cubicinches</th>\n",
       "      <th>hp</th>\n",
       "      <th>weightlbs</th>\n",
       "      <th>time-to-60</th>\n",
       "      <th>year</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350</td>\n",
       "      <td>165</td>\n",
       "      <td>4209</td>\n",
       "      <td>12</td>\n",
       "      <td>1972</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31.9</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>71</td>\n",
       "      <td>1925</td>\n",
       "      <td>14</td>\n",
       "      <td>1980</td>\n",
       "      <td>Europe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>11</td>\n",
       "      <td>1971</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400</td>\n",
       "      <td>150</td>\n",
       "      <td>3761</td>\n",
       "      <td>10</td>\n",
       "      <td>1971</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>30.5</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>63</td>\n",
       "      <td>2051</td>\n",
       "      <td>17</td>\n",
       "      <td>1978</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>305</td>\n",
       "      <td>130</td>\n",
       "      <td>3840</td>\n",
       "      <td>15</td>\n",
       "      <td>1980</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>36.1</td>\n",
       "      <td>4</td>\n",
       "      <td>91</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16</td>\n",
       "      <td>1979</td>\n",
       "      <td>Japan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232</td>\n",
       "      <td>112</td>\n",
       "      <td>2835</td>\n",
       "      <td>15</td>\n",
       "      <td>1983</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232</td>\n",
       "      <td>100</td>\n",
       "      <td>3288</td>\n",
       "      <td>16</td>\n",
       "      <td>1972</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>105</td>\n",
       "      <td>3353</td>\n",
       "      <td>15</td>\n",
       "      <td>1977</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg   cylinders  cubicinches   hp  weightlbs   time-to-60   year  \\\n",
       "0    14.0           8          350  165       4209           12   1972   \n",
       "1    31.9           4           89   71       1925           14   1980   \n",
       "2    17.0           8          302  140       3449           11   1971   \n",
       "3    15.0           8          400  150       3761           10   1971   \n",
       "4    30.5           4           98   63       2051           17   1978   \n",
       "..    ...         ...          ...  ...        ...          ...    ...   \n",
       "256  17.0           8          305  130       3840           15   1980   \n",
       "257  36.1           4           91   60       1800           16   1979   \n",
       "258  22.0           6          232  112       2835           15   1983   \n",
       "259  18.0           6          232  100       3288           16   1972   \n",
       "260  22.0           6          250  105       3353           15   1977   \n",
       "\n",
       "        brand  \n",
       "0         US.  \n",
       "1     Europe.  \n",
       "2         US.  \n",
       "3         US.  \n",
       "4         US.  \n",
       "..        ...  \n",
       "256       US.  \n",
       "257    Japan.  \n",
       "258       US.  \n",
       "259       US.  \n",
       "260       US.  \n",
       "\n",
       "[261 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car = pd.read_csv(\"carsdata/cars.csv\")\n",
    "car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = car[' cylinders']\n",
    "ytrain = car[' hp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = list(xtrain.values)\n",
    "ytrain = list(ytrain.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([1]))\n",
    "b = tf.Variable(tf.random_normal([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = xtrain*w+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델\n",
    "hf = xtrain*w+b\n",
    "cost = tf.reduce_mean(tf.square(hf-ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.GradientDescentOptimizer(0.01) #learning rante: 0.01\n",
    "train = opt.minimize(cost) #경사 하강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1569.7896 [13.26929] [0.9219017]\n",
      "100 468.97632 [18.939503] [0.9079638]\n",
      "200 468.36075 [19.066114] [0.13433558]\n",
      "300 467.92303 [19.17289] [-0.51808536]\n",
      "400 467.61172 [19.262936] [-1.0682861]\n",
      "500 467.39035 [19.338875] [-1.5322839]\n",
      "600 467.23288 [19.402916] [-1.9235836]\n",
      "700 467.12082 [19.456923] [-2.2535748]\n",
      "800 467.04123 [19.502466] [-2.5318666]\n",
      "900 466.9846 [19.540876] [-2.766555]\n",
      "1000 466.94437 [19.573267] [-2.964473]\n",
      "1100 466.91556 [19.600584] [-3.131383]\n",
      "1200 466.8953 [19.623621] [-3.2721405]\n",
      "1300 466.8808 [19.643047] [-3.3908463]\n",
      "1400 466.8705 [19.659431] [-3.4909523]\n",
      "1500 466.8632 [19.673248] [-3.575372]\n",
      "1600 466.858 [19.6849] [-3.6465683]\n",
      "1700 466.85422 [19.694725] [-3.7066085]\n",
      "1800 466.8516 [19.703012] [-3.757239]\n",
      "1900 466.84976 [19.710001] [-3.7999382]\n",
      "2000 466.8484 [19.715893] [-3.8359473]\n",
      "2100 466.8474 [19.720863] [-3.8663163]\n",
      "2200 466.8467 [19.725056] [-3.891927]\n",
      "2300 466.84628 [19.72859] [-3.9135258]\n",
      "2400 466.84598 [19.731571] [-3.9317403]\n",
      "2500 466.84567 [19.734085] [-3.9470985]\n",
      "2600 466.84552 [19.736204] [-3.9600518]\n",
      "2700 466.84546 [19.737993] [-3.9709764]\n",
      "2800 466.84534 [19.7395] [-3.9801888]\n",
      "2900 466.84525 [19.740772] [-3.9879594]\n",
      "3000 466.84515 [19.741844] [-3.9945123]\n",
      "3100 466.84515 [19.742748] [-4.0000362]\n",
      "3200 466.84525 [19.743511] [-4.0046945]\n",
      "3300 466.8451 [19.744154] [-4.008625]\n",
      "3400 466.8451 [19.744696] [-4.01194]\n",
      "3500 466.84512 [19.745153] [-4.0147357]\n",
      "3600 466.84512 [19.74554] [-4.017093]\n",
      "3700 466.84518 [19.745865] [-4.0190825]\n",
      "3800 466.84503 [19.74614] [-4.0207586]\n",
      "3900 466.84512 [19.74637] [-4.022169]\n",
      "4000 466.84512 [19.746567] [-4.023359]\n"
     ]
    }
   ],
   "source": [
    "for step in range(4001): #training: 3300\n",
    "    sess.run(train)\n",
    "    if step%100==0:\n",
    "        print(step, sess.run(cost), sess.run(w), sess.run(b))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
