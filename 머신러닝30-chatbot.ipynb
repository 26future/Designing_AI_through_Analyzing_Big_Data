{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbotData = pd.read_csv(\"ChatData.csv\", encoding='utf-8')\n",
    "question, answer = list(chatbotData['Q']), list(chatbotData['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = question[:100]\n",
    "answer = answer[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 12시 땡!\n",
      "답변: 하루가 또 가네요.\n",
      "\n",
      "질문: 1지망 학교 떨어졌어\n",
      "답변: 위로해 드립니다.\n",
      "\n",
      "질문: 3박4일 놀러가고 싶다\n",
      "답변: 여행은 언제나 좋죠.\n",
      "\n",
      "질문: 3박4일 정도 놀러가고 싶다\n",
      "답변: 여행은 언제나 좋죠.\n",
      "\n",
      "질문: PPL 심하네\n",
      "답변: 눈살이 찌푸려지죠.\n",
      "\n",
      "질문: SD카드 망가졌어\n",
      "답변: 다시 새로 사는 게 마음 편해요.\n",
      "\n",
      "질문: SD카드 안돼\n",
      "답변: 다시 새로 사는 게 마음 편해요.\n",
      "\n",
      "질문: SNS 맞팔 왜 안하지ㅠㅠ\n",
      "답변: 잘 모르고 있을 수도 있어요.\n",
      "\n",
      "질문: SNS 시간낭비인 거 아는데 매일 하는 중\n",
      "답변: 시간을 정하고 해보세요.\n",
      "\n",
      "질문: SNS 시간낭비인데 자꾸 보게됨\n",
      "답변: 시간을 정하고 해보세요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"질문:\", question[i])\n",
    "    print(\"답변:\", answer[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from konlpy.tag import Okt\n",
    "from keras import models, layers, optimizers, metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#태그 단어\n",
    "\n",
    "PAD = \"<PADDING>\" #패딩\n",
    "STA = \"<START>\" #시작\n",
    "END = \"<END>\" #끝\n",
    "OOV = \"<OOV>\" #out of vocabulary\n",
    "\n",
    "PAD_INDEX = 0\n",
    "STA_INDEX = 1\n",
    "END_INDEX = 2\n",
    "OOV_INDEX = 3\n",
    "\n",
    "ENCODER_INPUT = 0\n",
    "DECODER_INPUT = 1\n",
    "DECODER_TARGET = 2\n",
    "\n",
    "#한 문장에서 단어 시퀀스의 최대 개수\n",
    "maxSequences = 30\n",
    "\n",
    "#임베딩 벡터 차원\n",
    "embeddingDim = 100\n",
    "\n",
    "#LSTM 출력 차원\n",
    "lstmHiddenDim = 128\n",
    "\n",
    "#정규표현식 필터\n",
    "RE_FILTER = re.compile(\"[.,!?\\\"'~()]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#형태소 분석기\n",
    "def posTag(sentences):\n",
    "    \n",
    "    tagger = Okt()\n",
    "    \n",
    "    sentencePos=[]\n",
    "    for sentence in sentences:\n",
    "        #특수문자 제거\n",
    "        sentence = re.sub(RE_FILTER, \"\", sentence) #sentence에 있는 글자 중에서 RE_FILTER에 해당하는 글자 제거\n",
    "        sentence = \" \".join(tagger.morphs(sentence))\n",
    "        sentencePos.append(sentence)\n",
    "        \n",
    "    return sentencePos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = posTag(question)\n",
    "answer =posTag(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['하루 가 또 가네요',\n",
       " '위로 해 드립니다',\n",
       " '여행 은 언제나 좋죠',\n",
       " '여행 은 언제나 좋죠',\n",
       " '눈살 이 찌푸려지죠',\n",
       " '다시 새로 사는 게 마음 편해요',\n",
       " '다시 새로 사는 게 마음 편해요',\n",
       " '잘 모르고 있을 수도 있어요',\n",
       " '시간 을 정 하고 해보세요',\n",
       " '시간 을 정 하고 해보세요',\n",
       " '자랑 하는 자리 니까 요',\n",
       " '그 사람 도 그럴 거 예요',\n",
       " '그 사람 도 그럴 거 예요',\n",
       " '혼자 를 즐기세요',\n",
       " '돈 은 다시 들어올 거 예요',\n",
       " '땀 을 식혀주세요',\n",
       " '어서 잊고 새 출발 하세요',\n",
       " '빨리 집 에 돌아가서 끄고 나오세요',\n",
       " '빨리 집 에 돌아가서 끄고 나오세요',\n",
       " '다음 달 에는 더 절약 해봐요',\n",
       " '따뜻하게 사세요',\n",
       " '다음 달 에는 더 절약 해봐요',\n",
       " '가장 확실한 시간 은 오늘이 에요 어제 와 내일 을 놓고 고민 하느라 시간 을 낭비하지 마세요',\n",
       " '온 가족 이 모두 마음 에 드는 곳 으로 가보세요',\n",
       " '온 가족 이 모두 마음 에 드는 곳 으로 가보세요',\n",
       " '온 가족 이 모두 마음 에 드는 곳 으로 가보세요',\n",
       " '저 를 만들어 준 사람 을 부모님 저 랑 이야기 해 주는 사람 을 친구 로 생각 하고 있어요',\n",
       " '저 를 만들어 준 사람 을 부모님 저 랑 이야기 해 주는 사람 을 친구 로 생각 하고 있어요',\n",
       " '더 가까워질 기회 가 되겠네요',\n",
       " '저 도 요',\n",
       " '다 들 바빠서 이야기 할 시간 이 부족했나 봐요',\n",
       " '다 들 바빠서 이야기 할 시간 이 부족했나 봐요',\n",
       " '온 가족 이 모두 마음 에 드는 곳 으로 가보세요',\n",
       " '좋은 생각 이에요',\n",
       " '더 가까워질 기회 가 되겠네요',\n",
       " '저 를 만들어 준 사람 을 부모님 저 랑 이야기 해 주는 사람 을 친구 로 생각 하고 있어요',\n",
       " '좋은 생각 이에요',\n",
       " '정말 후회 할 습관 이에요',\n",
       " '무모한 결정 을 내 리지 마세요',\n",
       " '선생님 이나 기관 에 연락 해보세요',\n",
       " '떨리는 감정 은 그 자체 로 소중해요',\n",
       " '득템 했길 바라요',\n",
       " '휴식 도 필요하죠',\n",
       " '단 짠으로 두 개 사는게 진리 죠',\n",
       " '단 짠으로 두 개 사는게 진리 죠',\n",
       " '맛있게 드세요',\n",
       " '저 도 싫어요',\n",
       " '가세 요',\n",
       " '가세 요',\n",
       " '맛있게 드세요',\n",
       " '맛있게 드세요',\n",
       " '병원 가세 요',\n",
       " '이럴 때 잘 쉬는 게 중요해요',\n",
       " '이럴 때 잘 쉬는 게 중요해요',\n",
       " '이럴 때 잘 쉬는 게 중요해요',\n",
       " '따뜻하게 관리 하세요',\n",
       " '병원 가세 요',\n",
       " '병원 가세 요',\n",
       " '저 도 듣고 싶네요',\n",
       " '자신 을 더 사랑 해주세요',\n",
       " '그건 습관 이에요',\n",
       " '그건 습관 이에요',\n",
       " '콕 집어서 물어보세요',\n",
       " '좋은 생각 만 하세요',\n",
       " '마음 이 아픈가요',\n",
       " '갑작스러웠나 봐요',\n",
       " '관계 의 변화 가 왔나 봅니다',\n",
       " '처음 3초 가 중요해요 당신 의 매력 을 어필 해보세요',\n",
       " '책임질 수 있을 때 키워 보세요',\n",
       " '먼저 생활 패턴 을 살펴 보세요',\n",
       " '먼저 생활 패턴 을 살펴 보세요',\n",
       " '책임질 수 있을 때 키워 보세요',\n",
       " '아름다운 곳 이 죠',\n",
       " '안 될 것 도 없죠',\n",
       " '혼자 도 좋아요',\n",
       " '연인 은 살쪄도 잘 알아차리지 못 하고 알아차려도 싫어하지 않을 거 예요',\n",
       " '즐거운 시간 보내고 오세요',\n",
       " '질질 끌 지 마세요',\n",
       " '말 해보세요',\n",
       " '함께 하면 서로 를 더 많이 알 게 될 거 예요',\n",
       " '개시 해보세요',\n",
       " '개시 해보세요',\n",
       " '곧 방학 이 예요',\n",
       " '방학 이 참 짧죠',\n",
       " '벗어나는 게 좋겠네요',\n",
       " '벗어나는 게 좋겠네요',\n",
       " '세수 하고 오세요',\n",
       " '그게 제일 중요한 건데 요',\n",
       " '그게 제일 중요한 건데 요',\n",
       " '다음 부터는 더 많이 아세요',\n",
       " '갑작스러웠나 봐요',\n",
       " '공적 인 일 부터 하세요',\n",
       " '공적 인 일 부터 하세요',\n",
       " '낮잠 을 잠깐 자도 괜찮아요',\n",
       " '저 도 좋아해주세요',\n",
       " '친구 들 이 보고싶었나 봐요',\n",
       " '되도록 만나지 마세요',\n",
       " '당신 이 요',\n",
       " '당신 의 운 을 믿어 보세요',\n",
       " '일 못 하는 사람 이 있으면 옆 에 있는 사람 이 더 힘들죠']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#질문 + 대답 문장을 하나로 합치기\n",
    "sentences=[]\n",
    "sentences.extend(question) #append는 리스트로 추가\n",
    "sentences.extend(answer)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "966"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#단어 배열 생성\n",
    "words=[]\n",
    "for sentence in sentences:\n",
    "    for word in sentence.split():\n",
    "        words.append(word)\n",
    "len(words) #전체 단어의 개수 966개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words에서 길이가 0인 단어를 삭제\n",
    "words = [word for word in words if len(word)>0]\n",
    "#중복 단어 삭제\n",
    "words = list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[:0] = [PAD, STA, END, OOV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<PADDING>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PADDING>',\n",
       " '<START>',\n",
       " '<END>',\n",
       " '<OOV>',\n",
       " '싫어하지',\n",
       " '자랑',\n",
       " '자꾸',\n",
       " '고고',\n",
       " '아름다운',\n",
       " '박',\n",
       " '볼까',\n",
       " '해주세요',\n",
       " '있어',\n",
       " '예요',\n",
       " '해보여',\n",
       " '낮잠',\n",
       " '나온거',\n",
       " '수도',\n",
       " '땀',\n",
       " '걸리겠어']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)\n",
    "words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어에 대한 인덱스를 부여 -> 딕셔너리\n",
    "wordToIndex = {word:index for index, word in enumerate(words)}\n",
    "indexToWord = {index:word for index, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리\n",
    "#문장 -> 인덱스로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                  question, wordToIndex, ENCODER_INPUT\n",
    "def convertTextToIndex(sentences, voc, mytype):\n",
    "    \n",
    "    sentencesIndex=[]\n",
    "    for sentence in sentences:\n",
    "        \n",
    "        sentenceIndex=[]\n",
    "        if mytype==DECODER_INPUT:\n",
    "            sentenceIndex.extend([voc[STA]]) #1\n",
    "            \n",
    "        for word in sentence.split():\n",
    "            if voc.get(word) is not None:\n",
    "                sentenceIndex.extend([voc[word]]) #단어에 해당되는 인덱스가 추가\n",
    "                \n",
    "            else: #사전에 없는 단어의 경우 OOV 추가\n",
    "                sentenceIndex.extend([voc[OOV]])                    \n",
    "                \n",
    "        if mytype==DECODER_TARGET: #디코더 출력은 맨 마지막에 end 추가\n",
    "            if maxSequences <= len(sentenceIndex):\n",
    "                sentenceIndex = sentenceIndex[:maxSequences-1]+ [voc[END]]\n",
    "            else:\n",
    "                sentenceIndex+=[voc[END]]\n",
    "                \n",
    "        else:\n",
    "            if len(sentenceIndex) > maxSequences:\n",
    "                sentenceIndex = sentenceIndex[:maxSequences]\n",
    "        #0으로 채움\n",
    "        sentenceIndex+=[wordToIndex[PAD]]*(maxSequences-len(sentenceIndex))\n",
    "        sentencesIndex.append(sentenceIndex)\n",
    "        \n",
    "    return np.asarray(sentencesIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[413  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "[  1 124 424 192  32   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "[124 424 192  32   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "#인코더 입력, 디코더 입력, 디코더 출력 -> 인덱스 변환\n",
    "xEncoder = convertTextToIndex(question, wordToIndex, ENCODER_INPUT)\n",
    "print(xEncoder[0])\n",
    "\n",
    "xDecoder = convertTextToIndex(answer, wordToIndex, DECODER_INPUT)\n",
    "print(xDecoder[0])\n",
    "\n",
    "yDecoder = convertTextToIndex(answer, wordToIndex, DECODER_TARGET)\n",
    "print(yDecoder[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 인코더 입력: 12시 땡\n",
    "# 디코더 입력: START 하루 가  또      가네요\n",
    "# 디코더 출력: 하루  가   또  가네요  END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.zeros((2,3,4))\n",
    "oneHotData = np.zeros((len(yDecoder), maxSequences, len(words)))\n",
    "#100(답변개수), 30(최대 단어 개수), 454(전체 단어 집합 개수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(oneHotData)  #(100, 30, 454) 디코더 출력\n",
    "# 하루  가   또  가네요  END\n",
    "yDecoder.shape  #(100, 30)\n",
    "for i,seq in enumerate(yDecoder):\n",
    "    for j,index in enumerate(seq):\n",
    "        oneHotData[i,j,index]=1\n",
    "yDecoder = oneHotData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 454)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yDecoder[0].shape #첫번째 답변 내용의 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "# 인코더 정의\n",
    "# 입력 문장의 인덱스 sequence를 입력\n",
    "encoderInputs = layers.Input(shape=(None,))\n",
    "#임베딩 계층\n",
    "encoderOutputs = layers.Embedding(len(words), embeddingDim)(encoderInputs)\n",
    "\n",
    "encoderOutputs, stateH, stateC = layers.LSTM(lstmHiddenDim, return_state=True, dropout=0.2, recurrent_dropout=0.5)(encoderOutputs)\n",
    "\n",
    "#return_state=True  => 상태값 리턴\n",
    "#LSTM은 2개 상태 존재(cell, hidden state)\n",
    "\n",
    "encoderStates = [stateH, stateC]\n",
    "\n",
    "\n",
    "# 디코더 정의\n",
    "# 출력 문장의 인덱스 sequence를 입력\n",
    "decoderInputs = layers.Input(shape=(None,))\n",
    "#임베딩 계층\n",
    "decoderEmbedding = layers.Embedding(len(words), embeddingDim )\n",
    "decoderOutputs = decoderEmbedding(decoderInputs)\n",
    "\n",
    "decoderLSTM = layers.LSTM(lstmHiddenDim, return_state=True, return_sequences=True, dropout=0.2, recurrent_dropout=0.5)\n",
    "decoderOutputs, _, _ = decoderLSTM(decoderOutputs, initial_state=encoderStates)\n",
    "\n",
    "decoderDense = layers.Dense(len(words), activation='softmax')\n",
    "decoderOutputs = decoderDense(decoderOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model([encoderInputs,decoderInputs], decoderOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예측 모델 인코더 정의\n",
    "encoderModel = models.Model(encoderInputs, encoderStates)\n",
    "\n",
    "#예측 모델 디코더 정의\n",
    "#바로 앞에 있는 디코더의 출력(상태)을 입력 받아서 예측을 해야 함\n",
    "decoderStateInputH = layers.Input(shape=(lstmHiddenDim,))\n",
    "decoderStateInputC = layers.Input(shape=(lstmHiddenDim,))\n",
    "decoderStatesInputs = [decoderStateInputH, decoderStateInputC]\n",
    "\n",
    "#임베딩 계층\n",
    "decoderOutputs = decoderEmbedding(decoderInputs)\n",
    "#LSTM 계층\n",
    "decoderOutputs, stateH, stateC = decoderLSTM(decoderOutputs, initial_state=decoderStatesInputs)\n",
    "decoderStates = [stateH, stateC]\n",
    "\n",
    "#Dense계층을 통해 원핫 형식으로 예측 단어 인덱스를 추출\n",
    "decoderOutputs= decoderDense(decoderOutputs)\n",
    "\n",
    "#예측 모델 디코더 설정\n",
    "decoderModel = models.Model([decoderInputs]+decoderStatesInputs, [decoderOutputs]+decoderStates) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#인덱스를 문장으로 변환\n",
    "def convertIndextToText(indexs, voc):\n",
    "    sentence=''\n",
    "    for i in indexs:\n",
    "        if i==END_INDEX: #종료 인덱스\n",
    "            break\n",
    "        if voc.get(i) is not None:\n",
    "            sentence+=voc[i]\n",
    "        else:\n",
    "            sentence.extend([voc[OOV_INDEX]])\n",
    "        sentence+=\" \"\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total epoch: 1\n",
      "accuracy: [0.9033333, 0.90566665, 0.904, 0.9036667, 0.907, 0.9066667, 0.907, 0.9063333, 0.90966666, 0.9066667, 0.91033334, 0.9116667, 0.9123333, 0.91033334, 0.911, 0.915, 0.91533333, 0.9123333, 0.91433334, 0.915, 0.9166667, 0.914, 0.917, 0.916, 0.9173333, 0.91833335, 0.917, 0.92266667, 0.9213333, 0.9206667, 0.921, 0.92433333, 0.9216667, 0.92433333, 0.923, 0.925, 0.92733335, 0.925, 0.932, 0.931, 0.9303333, 0.93266666, 0.93133336, 0.934, 0.93666667, 0.933, 0.93766665, 0.932, 0.932, 0.936, 0.93766665, 0.93733335, 0.938, 0.93866664, 0.938, 0.94233334, 0.943, 0.941, 0.9406667, 0.9406667, 0.93833333, 0.945, 0.9446667, 0.945, 0.9446667, 0.9433333, 0.946, 0.9403333, 0.945, 0.9486667, 0.94633335, 0.94766665, 0.949, 0.9493333, 0.948, 0.948, 0.95066667, 0.952, 0.9483333, 0.952, 0.9493333, 0.95166665, 0.949, 0.95133334, 0.95166665, 0.95233333, 0.95166665, 0.955, 0.95133334, 0.9533333, 0.9546667, 0.9543333, 0.953, 0.9543333, 0.956, 0.956, 0.9576667, 0.95566666, 0.95566666, 0.95666665]\n",
      "loss: [0.44792978644371034, 0.4484253787994385, 0.4440684449672699, 0.4404238247871399, 0.4358613002300262, 0.43463117599487305, 0.4333131277561188, 0.42993183255195616, 0.42303085803985596, 0.4267665433883667, 0.42064489603042604, 0.41724745869636537, 0.41920963883399964, 0.41492313623428345, 0.41164063453674316, 0.4090318322181702, 0.4047950077056885, 0.40239206433296204, 0.3997316038608551, 0.3974583649635315, 0.3945937478542328, 0.39439634680747987, 0.38927141785621644, 0.3878274142742157, 0.3839076316356659, 0.3804857587814331, 0.37706649661064146, 0.37533724784851075, 0.3723431670665741, 0.3707190525531769, 0.37072723984718325, 0.36706255793571474, 0.3647378706932068, 0.36199798941612243, 0.3598207664489746, 0.3562776505947113, 0.35276803374290466, 0.3522531831264496, 0.347187784910202, 0.3431064164638519, 0.34641202569007873, 0.3395002377033234, 0.3377800190448761, 0.33499267578125, 0.3309434187412262, 0.33009764790534973, 0.32597088932991025, 0.3256988954544067, 0.3278960454463959, 0.3212784814834595, 0.31796586990356446, 0.32012231230735777, 0.31497452974319456, 0.3147766661643982, 0.30755546808242795, 0.3041858184337616, 0.3037195837497711, 0.30051007628440857, 0.3014688003063202, 0.3011434733867645, 0.30029740691185, 0.2943284237384796, 0.28977996587753296, 0.29170169472694396, 0.28638131022453306, 0.2884695029258728, 0.2840842127799988, 0.28688487529754636, 0.2794636368751526, 0.273908371925354, 0.2763568437099457, 0.2715436351299286, 0.2702107417583466, 0.26769912481307984, 0.2680657958984375, 0.26680509984493256, 0.26232869148254395, 0.26031263649463654, 0.2593104839324951, 0.2573857593536377, 0.2585374391078949, 0.25328770399093625, 0.2541253507137299, 0.2529904305934906, 0.25120641469955446, 0.24988382518291474, 0.24559082508087157, 0.24428834199905394, 0.24098606288433075, 0.24325589835643768, 0.2396145796775818, 0.237232266664505, 0.23633855402469636, 0.23217919886112212, 0.23177530467510224, 0.23252035081386566, 0.22837244153022765, 0.22702783703804016, 0.224481018781662, 0.2225994473695755]\n",
      "저 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 2\n",
      "accuracy: [0.958, 0.9576667, 0.95666665, 0.959, 0.95933336, 0.958, 0.9586667, 0.95933336, 0.95566666, 0.9573333, 0.9573333, 0.9623333, 0.96, 0.95966667, 0.96, 0.96166664, 0.9586667, 0.96, 0.96033335, 0.963, 0.96166664, 0.96133333, 0.9623333, 0.961, 0.961, 0.963, 0.96466666, 0.9623333, 0.96133333, 0.9633333, 0.9623333, 0.96066666, 0.965, 0.963, 0.964, 0.9636667, 0.9626667, 0.963, 0.964, 0.9626667, 0.964, 0.9633333, 0.966, 0.965, 0.96533334, 0.96433336, 0.9633333, 0.96533334, 0.96466666, 0.96466666, 0.9663333, 0.965, 0.966, 0.966, 0.9673333, 0.96466666, 0.966, 0.9663333, 0.96566665, 0.964, 0.96533334, 0.967, 0.96566665, 0.96433336, 0.9663333, 0.9676667, 0.96566665, 0.96566665, 0.9663333, 0.96666664, 0.96666664, 0.967, 0.9686667, 0.9663333, 0.96566665, 0.9673333, 0.967, 0.9683333, 0.9673333, 0.968, 0.9683333, 0.967, 0.9663333, 0.9673333, 0.9673333, 0.9686667, 0.9683333, 0.968, 0.968, 0.9683333, 0.96666664, 0.967, 0.9663333, 0.9683333, 0.9686667, 0.96666664, 0.9673333, 0.9686667, 0.9686667, 0.9676667]\n",
      "loss: [0.21971392929553984, 0.22135998845100402, 0.2189161968231201, 0.21432354629039765, 0.21482366681098938, 0.21391508877277374, 0.21263697922229766, 0.21158025443553924, 0.21780917584896087, 0.2077958583831787, 0.20833552181720733, 0.2046496242284775, 0.2026241010427475, 0.20402789175510405, 0.201471489071846, 0.19971404254436492, 0.19783744871616363, 0.1987083786725998, 0.195596079826355, 0.19266219913959504, 0.19471045672893525, 0.19330434381961822, 0.19132696330547333, 0.1898354858160019, 0.19033236026763917, 0.18787758350372313, 0.18525680601596833, 0.18600302696228027, 0.18591695189476012, 0.18333624601364135, 0.18561494648456572, 0.18366238057613374, 0.18069248676300048, 0.17933980226516724, 0.18183752357959748, 0.17660532534122467, 0.1767590820789337, 0.17435705304145813, 0.17398324608802795, 0.17308441042900086, 0.17210083246231078, 0.1718007230758667, 0.16923938035964967, 0.17117406249046327, 0.1662694025039673, 0.16681812226772308, 0.16655493199825286, 0.17022688329219818, 0.16665730774402618, 0.16453659057617187, 0.1620939415693283, 0.16502479076385498, 0.16153954803943635, 0.15918418645858765, 0.1589549046754837, 0.15980484664440156, 0.15662674903869628, 0.15768757104873657, 0.15820471107959747, 0.15650719583034514, 0.15505136013031007, 0.1532726913690567, 0.15143281996250152, 0.15466770470142366, 0.1508651679754257, 0.15104684829711915, 0.15156450510025024, 0.14927484214305878, 0.14872252106666564, 0.14912257850170135, 0.1464202171564102, 0.14698987543582917, 0.1460120403766632, 0.14796275675296783, 0.1455192357301712, 0.14336567521095275, 0.1428699243068695, 0.14192129731178282, 0.14071241915225982, 0.1416219824552536, 0.13971765995025634, 0.13975044906139375, 0.13996265232563018, 0.14205505967140197, 0.13786341428756713, 0.13865370869636537, 0.13791127264499664, 0.13777327954769134, 0.13666778445243835, 0.1366335290670395, 0.13510986983776094, 0.1369748204946518, 0.1368992245197296, 0.13619327068328857, 0.13283944368362427, 0.13335836231708526, 0.1345035356283188, 0.13158091127872468, 0.13122666120529175, 0.13224904626607895]\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 3\n",
      "accuracy: [0.968, 0.96666664, 0.9686667, 0.9683333, 0.9686667, 0.9683333, 0.969, 0.969, 0.96966666, 0.96933335, 0.9683333, 0.9686667, 0.9683333, 0.968, 0.968, 0.96966666, 0.96966666, 0.968, 0.97033334, 0.9683333, 0.96933335, 0.969, 0.9683333, 0.9683333, 0.969, 0.9683333, 0.9713333, 0.96966666, 0.9686667, 0.9686667, 0.9686667, 0.968, 0.9683333, 0.96966666, 0.96933335, 0.97, 0.96933335, 0.97033334, 0.97066665, 0.969, 0.96966666, 0.969, 0.9683333, 0.97, 0.97033334, 0.97033334, 0.971, 0.96966666, 0.96933335, 0.96933335, 0.971, 0.96933335, 0.971, 0.97033334, 0.97066665, 0.96966666, 0.96933335, 0.969, 0.97066665, 0.97033334, 0.97066665, 0.969, 0.969, 0.97, 0.9713333, 0.97, 0.9716667, 0.97033334, 0.97, 0.97066665, 0.97033334, 0.96966666, 0.97, 0.97066665, 0.97, 0.97033334, 0.971, 0.97, 0.97, 0.971, 0.97, 0.97066665, 0.9716667, 0.97, 0.969, 0.97033334, 0.971, 0.96966666, 0.97066665, 0.97066665, 0.972, 0.971, 0.96966666, 0.97066665, 0.97033334, 0.972, 0.96966666, 0.9716667, 0.97, 0.97]\n",
      "loss: [0.13204790771007538, 0.1294458895921707, 0.13088828861713409, 0.12992377072572708, 0.1301812469959259, 0.1286405825614929, 0.12768840849399565, 0.12864394545555113, 0.12617831707000732, 0.12599946528673173, 0.12474730670452118, 0.12644190192222596, 0.12635426193475724, 0.12700807690620422, 0.12576519429683686, 0.12463487178087235, 0.12531717002391815, 0.1246490466594696, 0.12418094038963318, 0.12394721925258637, 0.12312637746334076, 0.12278915345668792, 0.12402489870786666, 0.1208868795633316, 0.12150712430477142, 0.12016113817691804, 0.12163662731647491, 0.11946972817182541, 0.12014470934867859, 0.12067518532276153, 0.1203312760591507, 0.12185127139091492, 0.12125736117362976, 0.1191666305065155, 0.11671121627092361, 0.11752174079418182, 0.11858876824378967, 0.11842482417821884, 0.11695999532938003, 0.11721201717853547, 0.11641418874263763, 0.11648942291736603, 0.11691804885864258, 0.1143910950422287, 0.11637176603078841, 0.1148122125864029, 0.11411239266395569, 0.11828585833311081, 0.11634244471788406, 0.11406780779361725, 0.11233722478151321, 0.11350006341934205, 0.11310092359781265, 0.11491698801517486, 0.11244174152612686, 0.11201553255319595, 0.11224788665771485, 0.11234154909849167, 0.1110882356762886, 0.11039874494075776, 0.11116873860359192, 0.11118081569671631, 0.11530030041933059, 0.1087930902838707, 0.1105113935470581, 0.11160757899284363, 0.11095771431922913, 0.1105520886182785, 0.10935295820236206, 0.10835987091064453, 0.11058091968297959, 0.10972061961889266, 0.10946244180202484, 0.10869967371225357, 0.10866747707128525, 0.10852590769529342, 0.10754612773656845, 0.10735515534877776, 0.1082179605960846, 0.10826965719461441, 0.10704396426677704, 0.1069959869980812, 0.1049766606092453, 0.1081375116109848, 0.1076608008146286, 0.10772918790578842, 0.10500817090272903, 0.10558072328567505, 0.10570098161697387, 0.10413479387760162, 0.10449044287204742, 0.10590448945760728, 0.10598085641860962, 0.10416932344436645, 0.10410899013280868, 0.10450294852256775, 0.10367442458868027, 0.10387064874172211, 0.10272247761487961, 0.10353611528873444]\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: [0.973, 0.973, 0.9713333, 0.971, 0.96966666, 0.971, 0.97, 0.9723333, 0.9713333, 0.973, 0.97033334, 0.97, 0.97033334, 0.97066665, 0.971, 0.97066665, 0.97033334, 0.972, 0.9723333, 0.971, 0.972, 0.9726667, 0.9716667, 0.971, 0.9713333, 0.9713333, 0.9713333, 0.972, 0.9713333, 0.97, 0.9713333, 0.972, 0.9713333, 0.972, 0.9723333, 0.972, 0.9716667, 0.9723333, 0.972, 0.9716667, 0.9716667, 0.9713333, 0.97066665, 0.971, 0.972, 0.972, 0.971, 0.972, 0.9723333, 0.972, 0.9713333, 0.97, 0.9716667, 0.9713333, 0.9716667, 0.9723333, 0.9713333, 0.9723333, 0.971, 0.9726667, 0.9723333, 0.9716667, 0.9716667, 0.969, 0.9716667, 0.9716667, 0.97333336, 0.972, 0.9716667, 0.9726667, 0.9716667, 0.9723333, 0.9726667, 0.9716667, 0.97066665, 0.972, 0.972, 0.97066665, 0.9726667, 0.9726667, 0.973, 0.9726667, 0.9723333, 0.97066665, 0.9713333, 0.972, 0.9716667, 0.972, 0.972, 0.9726667, 0.971, 0.973, 0.973, 0.9726667, 0.9716667, 0.9713333, 0.9713333, 0.9723333, 0.9716667, 0.9713333]\n",
      "loss: [0.10228588134050369, 0.10239667564630509, 0.10185999244451523, 0.10278934627771377, 0.10153143614530563, 0.10223274171352387, 0.10720768868923188, 0.10235948085784913, 0.10111819177865983, 0.10055500507354737, 0.10223625987768173, 0.10169611930847168, 0.10266034662723542, 0.09996623039245606, 0.10120190590620042, 0.1010056409239769, 0.10122641354799271, 0.09957055121660233, 0.09960742175579071, 0.10013153672218322, 0.09982144325971604, 0.09768881887197495, 0.09941382616758347, 0.09952649503946304, 0.0989193508028984, 0.09901759356260299, 0.09960885882377625, 0.09803437709808349, 0.09820509821176529, 0.10267311662435531, 0.10025225162506103, 0.0977758041024208, 0.09751511216163636, 0.09727034568786622, 0.09786715507507324, 0.09694624036550521, 0.09809309303760529, 0.09755602478981018, 0.09745335638523102, 0.09963999301195145, 0.09744901895523071, 0.09709185093641282, 0.09721739321947098, 0.09667831689119338, 0.09688627690076829, 0.09537510395050049, 0.09676129549741745, 0.09636798202991485, 0.09584718704223633, 0.09541836887598037, 0.09667975693941117, 0.10084403365850449, 0.09571350753307342, 0.09619328469038009, 0.09572426438331604, 0.09484381139278412, 0.09745993912220001, 0.09582043409347535, 0.09545195043087006, 0.09448635250329972, 0.09519352287054061, 0.09376083940267563, 0.09427321255207062, 0.09960830122232438, 0.09380287796258927, 0.09378855913877487, 0.09324131965637207, 0.0945425695180893, 0.09399864256381989, 0.09323606014251709, 0.09493526071310043, 0.09273367404937743, 0.09262013584375381, 0.09242651581764222, 0.09579183071851731, 0.09221505463123321, 0.09180019646883011, 0.0934543451666832, 0.09518535584211349, 0.09258153915405273, 0.09113323718309402, 0.09196836054325104, 0.09282616853713989, 0.093010533452034, 0.09295366913080215, 0.09159226179122924, 0.09105119317770004, 0.09093179166316986, 0.09103014141321182, 0.09063786834478378, 0.09234849274158478, 0.09143042623996735, 0.09197135478258132, 0.0900636312365532, 0.09079737275838852, 0.09127295821905136, 0.09168599426746368, 0.09023209989070892, 0.09142504930496216, 0.0942742595076561]\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 5\n",
      "accuracy: [0.9716667, 0.974, 0.9713333, 0.973, 0.9726667, 0.9726667, 0.9723333, 0.972, 0.9726667, 0.9716667, 0.973, 0.974, 0.9723333, 0.97333336, 0.971, 0.9723333, 0.9726667, 0.972, 0.973, 0.97333336, 0.97333336, 0.9716667, 0.973, 0.9723333, 0.97333336, 0.97, 0.9726667, 0.97333336, 0.971, 0.9726667, 0.9726667, 0.9723333, 0.972, 0.9723333, 0.9723333, 0.97333336, 0.9716667, 0.97366667, 0.9726667, 0.9716667, 0.9723333, 0.9726667, 0.97333336, 0.974, 0.973, 0.9723333, 0.9723333, 0.973, 0.9723333, 0.97333336, 0.972, 0.9726667, 0.9723333, 0.972, 0.9726667, 0.972, 0.974, 0.973, 0.9726667, 0.9726667, 0.974, 0.97433335, 0.9723333, 0.97333336, 0.9716667, 0.9716667, 0.974, 0.97333336, 0.97333336, 0.971, 0.973, 0.97433335, 0.9723333, 0.972, 0.97433335, 0.9723333, 0.97366667, 0.9713333, 0.974, 0.972, 0.973, 0.9716667, 0.97466666, 0.972, 0.97366667, 0.972, 0.972, 0.973, 0.9723333, 0.97366667, 0.97366667, 0.9716667, 0.97433335, 0.974, 0.9726667, 0.97366667, 0.97433335, 0.974, 0.97433335, 0.9723333]\n",
      "loss: [0.09260263979434967, 0.08982356607913972, 0.08973044157028198, 0.0921645149588585, 0.08957174062728882, 0.0900419670343399, 0.09005568772554398, 0.09038980603218079, 0.0890954890847206, 0.08954154133796692, 0.08982419550418853, 0.08975132763385772, 0.08962899804115296, 0.08934757381677627, 0.09169704377651215, 0.09165486007928848, 0.09037493973970413, 0.08853477627038955, 0.0881895861029625, 0.08782237321138382, 0.0919661420583725, 0.09178581416606903, 0.08813994616270066, 0.08858011573553086, 0.08947011649608612, 0.09089202642440795, 0.08933835536241531, 0.08811687648296357, 0.08866741299629212, 0.08946330666542053, 0.08829472959041595, 0.08790658324956895, 0.08910629898309708, 0.0872962674498558, 0.0900208941102028, 0.08848898768424988, 0.0892340412735939, 0.0887702751159668, 0.08820762842893601, 0.08805148869752884, 0.0882806819677353, 0.08930923283100128, 0.08610384374856948, 0.0862627711892128, 0.08727216243743896, 0.08753926724195481, 0.08624615550041198, 0.0867045822739601, 0.08858829587697983, 0.08628348112106324, 0.08656853318214416, 0.08840792208909988, 0.08664136290550233, 0.08853095084428787, 0.08645537048578263, 0.08563734143972397, 0.08680787444114685, 0.08931914746761321, 0.085896717607975, 0.08589852601289749, 0.08521633207798004, 0.08652232646942139, 0.08597856938838959, 0.08538534581661224, 0.0870959734916687, 0.08717852741479874, 0.08416002780199051, 0.08484349310398102, 0.08555085062980652, 0.08788334250450135, 0.08507874757051467, 0.08496846348047256, 0.08477849572896957, 0.08520875424146652, 0.084847951233387, 0.0858403429389, 0.08518030941486358, 0.08417305380105972, 0.08431733459234238, 0.08459073603153229, 0.08502031743526459, 0.08515089809894562, 0.08457036375999451, 0.09050205409526825, 0.08481913208961486, 0.08457876950502395, 0.08554763436317443, 0.08465370386838914, 0.08501418173313141, 0.08269044488668442, 0.0830924379825592, 0.08641889154911041, 0.08336303383111954, 0.0844097912311554, 0.08539864540100098, 0.08335067212581634, 0.08337964683771133, 0.08322695642709732, 0.08409004479646683, 0.08633075624704362]\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 6\n",
      "accuracy: [0.973, 0.9726667, 0.97366667, 0.97366667, 0.9716667, 0.97466666, 0.973, 0.9713333, 0.973, 0.97466666, 0.97366667, 0.97366667, 0.973, 0.97333336, 0.97066665, 0.9713333, 0.973, 0.97366667, 0.972, 0.974, 0.97366667, 0.97333336, 0.973, 0.9723333, 0.9723333, 0.97366667, 0.972, 0.9716667, 0.97366667, 0.97466666, 0.97366667, 0.974, 0.97333336, 0.97366667, 0.97433335, 0.97466666, 0.9716667, 0.97366667, 0.9716667, 0.97366667, 0.973, 0.974, 0.972, 0.97366667, 0.9726667, 0.9716667, 0.97433335, 0.97366667, 0.97333336, 0.97333336, 0.9716667, 0.97433335, 0.97366667, 0.972, 0.972, 0.973, 0.973, 0.973, 0.97366667, 0.9723333, 0.9723333, 0.97333336, 0.97366667, 0.9723333, 0.9763333, 0.97366667, 0.97433335, 0.9726667, 0.97466666, 0.974, 0.97366667, 0.97333336, 0.9723333, 0.97433335, 0.9716667, 0.97466666, 0.97566664, 0.973, 0.97333336, 0.9726667, 0.97433335, 0.974, 0.97333336, 0.97333336, 0.97366667, 0.97433335, 0.974, 0.972, 0.97433335, 0.97433335, 0.97466666, 0.974, 0.97466666, 0.976, 0.9726667, 0.974, 0.9716667, 0.97566664, 0.97466666, 0.97433335]\n",
      "loss: [0.08439962327480316, 0.08381851106882095, 0.08241659492254257, 0.08484846353530884, 0.0870645958185196, 0.08386312544345856, 0.08598677009344101, 0.08512717723846436, 0.08383200198411941, 0.08217624336481094, 0.08341355681419373, 0.08538378596305847, 0.0863417488336563, 0.08295674383640289, 0.08591282933950424, 0.08609474867582322, 0.08301885336637498, 0.08247819125652313, 0.08374124735593796, 0.08217660874128342, 0.08307407945394515, 0.08312311589717865, 0.08289855599403381, 0.08159454107284546, 0.08420670360326767, 0.08759326577186584, 0.08719639956951142, 0.08156774044036866, 0.08075302749872208, 0.08297551363706589, 0.08136381983757018, 0.08302572578191757, 0.08526121377944947, 0.08275119721889496, 0.08243816316127778, 0.08199718475341797, 0.08638906329870225, 0.08182821899652482, 0.08531144678592682, 0.08330642193555832, 0.08137740314006806, 0.08107006132602691, 0.08392936110496521, 0.08077163875102997, 0.08201374948024749, 0.08530916005373002, 0.08100130468606949, 0.08213866263628006, 0.08031653702259063, 0.08056454747915268, 0.08181312084197997, 0.08206533223390579, 0.08127751141786575, 0.08314644485712051, 0.08446260452270508, 0.08235165864229202, 0.0802286496758461, 0.08171682834625243, 0.08048606216907501, 0.08289642870426178, 0.08245741426944733, 0.08036059588193893, 0.0793562325835228, 0.08192112863063812, 0.07992458701133728, 0.08165497303009034, 0.07946294158697129, 0.08132473826408386, 0.0802067294716835, 0.07852189064025879, 0.07990276724100114, 0.08136626064777375, 0.08154418557882309, 0.07958530753850937, 0.08385372340679169, 0.07912117332220077, 0.07903902143239976, 0.08032768607139587, 0.07997972577810288, 0.08178957402706147, 0.08070492655038834, 0.07993411630392075, 0.08013106495141983, 0.08042584717273712, 0.07862812519073487, 0.08043168336153031, 0.07922461092472076, 0.08070151686668396, 0.07971130043268204, 0.07743815392255783, 0.07929376691579819, 0.0809718894958496, 0.0807390022277832, 0.07854325771331787, 0.08003517627716064, 0.07814189106225967, 0.08386940032243728, 0.07805482685565948, 0.07793138802051544, 0.07907740324735642]\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: [0.9766667, 0.9763333, 0.97433335, 0.97333336, 0.97466666, 0.97533333, 0.97533333, 0.97366667, 0.97366667, 0.97566664, 0.9723333, 0.97333336, 0.9726667, 0.974, 0.975, 0.973, 0.976, 0.975, 0.9726667, 0.972, 0.973, 0.9726667, 0.97333336, 0.97333336, 0.975, 0.97333336, 0.97433335, 0.9723333, 0.973, 0.97333336, 0.97333336, 0.975, 0.97366667, 0.97333336, 0.974, 0.97333336, 0.97466666, 0.976, 0.97433335, 0.97366667, 0.975, 0.97566664, 0.97466666, 0.97466666, 0.97433335, 0.97533333, 0.975, 0.97366667, 0.9726667, 0.974, 0.973, 0.97533333, 0.97466666, 0.975, 0.97566664, 0.975, 0.97533333, 0.97433335, 0.97366667, 0.975, 0.97433335, 0.97466666, 0.97566664, 0.974, 0.97333336, 0.97466666, 0.9726667, 0.97466666, 0.975, 0.9763333, 0.97566664, 0.97566664, 0.97566664, 0.973, 0.973, 0.974, 0.976, 0.976, 0.974, 0.97366667, 0.97533333, 0.97566664, 0.974, 0.97466666, 0.97466666, 0.97433335, 0.9726667, 0.97533333, 0.97533333, 0.977, 0.975, 0.97533333, 0.976, 0.97466666, 0.976, 0.97566664, 0.976, 0.97433335, 0.97533333, 0.97433335]\n",
      "loss: [0.07808388769626617, 0.07792701989412308, 0.08045591711997986, 0.07916440457105636, 0.07745467931032181, 0.07866529494524002, 0.07787800371646882, 0.07941226720809937, 0.07859879523515702, 0.07924890547990798, 0.08167876422405243, 0.07921736508607864, 0.07935530215501785, 0.07732007533311844, 0.0766405388712883, 0.07968660235404969, 0.07647217571735382, 0.07829185098409652, 0.07947425454854966, 0.08361498594284057, 0.0789293697476387, 0.07939974933862687, 0.07897831737995148, 0.07913522601127625, 0.07664715260267257, 0.07737470924854278, 0.078518867790699, 0.0836784929037094, 0.08313832223415375, 0.07949923723936081, 0.07676057368516923, 0.07678251504898072, 0.0764677408337593, 0.07617170125246048, 0.0765576821565628, 0.07662010997533798, 0.07718475937843322, 0.0760309225320816, 0.07722747266292572, 0.0778069618344307, 0.07643104583024979, 0.07596216261386872, 0.07638847678899766, 0.07657624185085296, 0.07655153810977935, 0.07698502331972122, 0.07646222144365311, 0.07847839683294296, 0.07752985358238221, 0.07764421314001084, 0.07855614453554154, 0.07467589735984802, 0.0767336505651474, 0.07499278664588928, 0.07493334472179412, 0.0753160873055458, 0.07651401460170745, 0.0802695095539093, 0.07780549943447113, 0.07490275084972381, 0.07622446924448013, 0.07642403930425644, 0.07514035880565643, 0.07552527010440827, 0.077142254114151, 0.07631916731595993, 0.0781800302863121, 0.0752618870139122, 0.07622720301151276, 0.07650022327899933, 0.07384505987167359, 0.07444673329591751, 0.07755434542894363, 0.07761903077363969, 0.07672560125589371, 0.07791022062301636, 0.07466815680265426, 0.07509680241346359, 0.07525008350610733, 0.07689851462841034, 0.07539349943399429, 0.0737683641910553, 0.07563001930713653, 0.07674658238887787, 0.0742677080631256, 0.0788509750366211, 0.07978682428598403, 0.07398610889911651, 0.07549412101507187, 0.07500950187444687, 0.07633585929870605, 0.0732989662885666, 0.07350242882966995, 0.07631567984819412, 0.07334127515554428, 0.07484009593725205, 0.07446501135826111, 0.07608332604169846, 0.07358784466981888, 0.07604009866714477]\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 8\n",
      "accuracy: [0.97433335, 0.975, 0.97466666, 0.974, 0.97566664, 0.973, 0.975, 0.973, 0.97566664, 0.97566664, 0.975, 0.97533333, 0.97466666, 0.97433335, 0.97366667, 0.975, 0.97533333, 0.97533333, 0.97466666, 0.97433335, 0.97533333, 0.974, 0.97433335, 0.974, 0.972, 0.97566664, 0.97433335, 0.976, 0.97466666, 0.97533333, 0.97566664, 0.9763333, 0.975, 0.97433335, 0.97366667, 0.97566664, 0.97533333, 0.974, 0.97533333, 0.97533333, 0.97366667, 0.97433335, 0.97433335, 0.97566664, 0.97533333, 0.976, 0.9763333, 0.9763333, 0.9763333, 0.97533333, 0.97366667, 0.97466666, 0.97533333, 0.97533333, 0.97433335, 0.9723333, 0.97566664, 0.97533333, 0.9763333, 0.97533333, 0.975, 0.97566664, 0.97533333, 0.97533333, 0.97466666, 0.975, 0.97333336, 0.97566664, 0.976, 0.97533333, 0.97533333, 0.97533333, 0.975, 0.9763333, 0.97466666, 0.97466666, 0.976, 0.975, 0.97533333, 0.97566664, 0.9773333, 0.975, 0.975, 0.976, 0.974, 0.976, 0.97566664, 0.97533333, 0.976, 0.97533333, 0.97566664, 0.9763333, 0.97566664, 0.97433335, 0.973, 0.9763333, 0.9766667, 0.977, 0.97433335, 0.975]\n",
      "loss: [0.07523627668619155, 0.07456753611564636, 0.0735911849141121, 0.0760627555847168, 0.07421147257089615, 0.07813546270132064, 0.07587084710597992, 0.07455445349216461, 0.07420253306627274, 0.07321226090192795, 0.07436234712600708, 0.07313450872898102, 0.07382508754730224, 0.08014182835817336, 0.07639994472265244, 0.07530355751514435, 0.0763265922665596, 0.07194149702787399, 0.07397019058465958, 0.07433515667915344, 0.07367071181535721, 0.07573941767215729, 0.07433747738599777, 0.07477308243513107, 0.07758199959993363, 0.07460949450731277, 0.07254555732011796, 0.07351766347885132, 0.07423215866088867, 0.07486776500940323, 0.07187104761600495, 0.07356928318738937, 0.07307341247797013, 0.07372907519340516, 0.07396508306264878, 0.07177994251251221, 0.07361487925052643, 0.07415960282087326, 0.07298031598329544, 0.07113558471202851, 0.07283505618572235, 0.07826264470815658, 0.07358331352472305, 0.07127852141857147, 0.07326755762100219, 0.07161196917295456, 0.07077575445175172, 0.07288859009742737, 0.07193062007427216, 0.07494003862142563, 0.07300354033708573, 0.07524928539991378, 0.07291638106107712, 0.07258840084075928, 0.0727411961555481, 0.07291685402393341, 0.0725908100605011, 0.07222941875457764, 0.07230620950460434, 0.07212742507457733, 0.07094082534313202, 0.07308053642511368, 0.07174688190221787, 0.07268546670675277, 0.0721800285577774, 0.07178595662117004, 0.07398780584335327, 0.06961021512746811, 0.07434097498655319, 0.07160312414169312, 0.07469732761383056, 0.07084045499563217, 0.07293325334787369, 0.07454166620969772, 0.07195556849241257, 0.07149054378271102, 0.0719027653336525, 0.07204828768968582, 0.07172436684370041, 0.07111980020999908, 0.07188378810882569, 0.07227073669433594, 0.0708239108324051, 0.07097414165735244, 0.07456094712018967, 0.07051818490028382, 0.07198137432336807, 0.0721918797492981, 0.07152968853712081, 0.0720620509982109, 0.07037991464138031, 0.06895127356052398, 0.071245137155056, 0.07047016024589539, 0.07275830745697022, 0.07026444971561432, 0.07074740022420883, 0.068865684568882, 0.07064575344324112, 0.07156337589025498]\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 9\n",
      "accuracy: [0.976, 0.975, 0.97566664, 0.9766667, 0.97533333, 0.973, 0.97466666, 0.9763333, 0.97466666, 0.97333336, 0.97566664, 0.97433335, 0.97433335, 0.976, 0.974, 0.97533333, 0.975, 0.9776667, 0.97566664, 0.9723333, 0.975, 0.976, 0.97433335, 0.9763333, 0.975, 0.97566664, 0.9763333, 0.9763333, 0.976, 0.97566664, 0.97566664, 0.97466666, 0.976, 0.977, 0.976, 0.976, 0.97466666, 0.977, 0.97366667, 0.97566664, 0.976, 0.9773333, 0.9763333, 0.9766667, 0.977, 0.97366667, 0.9773333, 0.976, 0.9766667, 0.974, 0.9776667, 0.97566664, 0.9763333, 0.9763333, 0.975, 0.9766667, 0.9763333, 0.97533333, 0.9763333, 0.975, 0.97566664, 0.97533333, 0.9763333, 0.975, 0.9766667, 0.978, 0.9763333, 0.977, 0.97566664, 0.97333336, 0.976, 0.97833335, 0.9763333, 0.976, 0.9763333, 0.975, 0.9773333, 0.9766667, 0.9766667, 0.975, 0.9763333, 0.9763333, 0.975, 0.975, 0.9763333, 0.9773333, 0.977, 0.97466666, 0.97566664, 0.9776667, 0.9766667, 0.978, 0.97566664, 0.9766667, 0.97566664, 0.9776667, 0.9776667, 0.9776667, 0.9763333, 0.97433335]\n",
      "loss: [0.07003382354974746, 0.0712381899356842, 0.06954752504825593, 0.06971604824066162, 0.06956545561552048, 0.07067816734313964, 0.07172870725393295, 0.06957800567150116, 0.07087010264396668, 0.07097319126129151, 0.07157560735940934, 0.0689956784248352, 0.0730737203359604, 0.06985898286104203, 0.07068243891000747, 0.0725107091665268, 0.06898687362670898, 0.06808794260025025, 0.07003964066505432, 0.07231495946645737, 0.07189506024122239, 0.06853100150823593, 0.07134841233491898, 0.07098711252212525, 0.07083499014377594, 0.0699104779958725, 0.06849864155054092, 0.07030094742774963, 0.06892652809619904, 0.06881605714559555, 0.06926092505455017, 0.07101574629545211, 0.07008217543363571, 0.06779685348272324, 0.06851026087999344, 0.06874411523342133, 0.07137664556503295, 0.06842547297477722, 0.07167782455682754, 0.0695723608136177, 0.06899702310562134, 0.06749370813369751, 0.06755216956138611, 0.06902665793895721, 0.07000610291957855, 0.06833339631557464, 0.0684442812204361, 0.06900139242410659, 0.06958895862102508, 0.06957729518413544, 0.06744578868150711, 0.06862359434366226, 0.06734383434057235, 0.07017706990242005, 0.06978609532117844, 0.06654220461845398, 0.0706427350640297, 0.06845693320035934, 0.06928671807050706, 0.06944868922233581, 0.07194528102874756, 0.0710987988114357, 0.06866715550422668, 0.06933932453393936, 0.068210539072752, 0.06832968562841416, 0.06785224974155427, 0.06726827949285508, 0.06912756383419037, 0.07324431210756302, 0.06893655478954315, 0.06717064648866654, 0.06983248025178909, 0.06831384629011154, 0.06647332668304444, 0.06773884117603302, 0.06823999166488648, 0.06707157880067825, 0.06596874117851258, 0.07033334612846374, 0.06831226617097855, 0.06642692267894745, 0.07149185627698898, 0.0691590142250061, 0.06866619020700454, 0.06615503311157227, 0.06733131438493728, 0.0754671761393547, 0.06782141655683517, 0.06542076766490937, 0.06622206687927246, 0.06503174886107445, 0.07100862383842468, 0.06901208311319351, 0.06702238112688065, 0.06664406180381775, 0.06749377995729447, 0.06559589058160782, 0.06643795490264892, 0.06847712188959122]\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: [0.97533333, 0.97866666, 0.978, 0.977, 0.97433335, 0.974, 0.977, 0.977, 0.9776667, 0.97833335, 0.9776667, 0.9763333, 0.9766667, 0.977, 0.977, 0.97533333, 0.97566664, 0.9773333, 0.9773333, 0.9776667, 0.97566664, 0.97566664, 0.9773333, 0.9776667, 0.976, 0.9763333, 0.97833335, 0.9776667, 0.9776667, 0.97533333, 0.978, 0.97833335, 0.97566664, 0.976, 0.9763333, 0.9766667, 0.976, 0.978, 0.9776667, 0.979, 0.97866666, 0.97833335, 0.97866666, 0.97866666, 0.9773333, 0.9766667, 0.976, 0.9773333, 0.97833335, 0.97366667, 0.979, 0.9776667, 0.978, 0.979, 0.9776667, 0.977, 0.97833335, 0.97833335, 0.97833335, 0.97933334, 0.97833335, 0.9766667, 0.97866666, 0.9773333, 0.97866666, 0.9776667, 0.978, 0.9773333, 0.9766667, 0.9773333, 0.978, 0.9766667, 0.97833335, 0.97866666, 0.9776667, 0.97866666, 0.97933334, 0.979, 0.97966665, 0.97833335, 0.9773333, 0.97833335, 0.9776667, 0.97833335, 0.9803333, 0.9776667, 0.979, 0.977, 0.9766667, 0.977, 0.97866666, 0.97866666, 0.97966665, 0.97933334, 0.97833335, 0.9766667, 0.978, 0.9773333, 0.979, 0.9776667]\n",
      "loss: [0.06732421338558198, 0.06347543746232986, 0.06580498725175858, 0.0660340702533722, 0.07226649284362793, 0.07076829344034195, 0.06521166145801544, 0.06530036062002181, 0.06522726774215698, 0.06694295197725296, 0.06496275931596757, 0.06974518120288849, 0.06758290499448777, 0.06574147373437882, 0.06568189680576325, 0.06402919977903367, 0.06658694922924041, 0.06678047060966491, 0.06558481931686401, 0.06643860548734665, 0.06653181582689285, 0.06530312091112137, 0.06512993514537811, 0.0666857722401619, 0.06496477216482162, 0.06890519589185715, 0.06421860277652741, 0.06606553375720978, 0.06543676853179932, 0.06571606814861297, 0.06455561757087708, 0.06450203508138656, 0.06756897240877152, 0.06601729184389114, 0.06628602266311645, 0.06733616322278976, 0.06571483045816422, 0.0630129623413086, 0.06625136405229569, 0.06331335991621018, 0.0649362713098526, 0.06390693724155426, 0.06293277770280838, 0.06311533853411674, 0.06267158448696136, 0.06374515295028686, 0.06728497862815858, 0.06386263132095336, 0.06495117634534836, 0.07570775121450424, 0.062471921890974044, 0.07201995328068733, 0.06308496698737144, 0.06452320516109467, 0.06551387667655945, 0.06450791671872139, 0.06391368210315704, 0.06253205269575118, 0.06216106921434403, 0.06291567534208298, 0.06641352534294129, 0.06569010406732559, 0.06184007525444031, 0.06498051166534424, 0.06320641815662384, 0.06219551920890808, 0.06392238616943359, 0.06360803753137588, 0.06749259322881698, 0.06633689999580383, 0.06412523090839387, 0.06458574831485749, 0.06379292592406273, 0.06341026753187179, 0.06323353290557861, 0.06566255748271942, 0.06265097618103027, 0.06207262307405472, 0.06154273882508278, 0.06262980222702026, 0.06414420038461685, 0.0636039873957634, 0.06275960490107536, 0.06306231796741485, 0.06131751611828804, 0.06318627506494522, 0.06218335583806038, 0.06358395010232926, 0.06810959249734878, 0.06457620084285737, 0.06131994396448135, 0.06207199573516846, 0.0615771296620369, 0.06075519621372223, 0.06804738700389862, 0.06851182907819747, 0.064130519926548, 0.06364082872867584, 0.06262181669473649, 0.06489665895700454]\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 11\n",
      "accuracy: [0.98, 0.979, 0.977, 0.979, 0.97833335, 0.97833335, 0.979, 0.977, 0.97833335, 0.978, 0.97866666, 0.9776667, 0.97833335, 0.978, 0.9813333, 0.97833335, 0.979, 0.9776667, 0.9776667, 0.9776667, 0.97833335, 0.97866666, 0.9776667, 0.97933334, 0.97966665, 0.9803333, 0.9766667, 0.979, 0.9776667, 0.97866666, 0.9776667, 0.97866666, 0.9766667, 0.97833335, 0.9773333, 0.9776667, 0.978, 0.97966665, 0.97966665, 0.97833335, 0.9776667, 0.98, 0.9803333, 0.97933334, 0.97866666, 0.97933334, 0.97833335, 0.97833335, 0.97833335, 0.9773333, 0.97966665, 0.97966665, 0.9773333, 0.9773333, 0.97933334, 0.98, 0.9803333, 0.978, 0.98, 0.98, 0.98066664, 0.97966665, 0.97866666, 0.979, 0.98, 0.9773333, 0.98, 0.979, 0.9803333, 0.97966665, 0.9763333, 0.97866666, 0.981, 0.98, 0.97933334, 0.979, 0.979, 0.97933334, 0.983, 0.979, 0.97866666, 0.978, 0.981, 0.97966665, 0.97866666, 0.97966665, 0.97566664, 0.97933334, 0.98066664, 0.97966665, 0.97933334, 0.98066664, 0.98066664, 0.979, 0.9773333, 0.97933334, 0.9826667, 0.98066664, 0.979, 0.9803333]\n",
      "loss: [0.06414408385753631, 0.06100510850548744, 0.06401489347219468, 0.06353612661361695, 0.06126583352684975, 0.062430763989686965, 0.06251460999250412, 0.06455792874097824, 0.06178432136774063, 0.06603264257311821, 0.06182551294565201, 0.06256678700447083, 0.060839371979236605, 0.06198364704847336, 0.0586537903547287, 0.060567938685417176, 0.06180036813020706, 0.062041574120521546, 0.06559947445988655, 0.06807891070842743, 0.061244100630283356, 0.05992377907037735, 0.06260110467672347, 0.06042871683835983, 0.059205097556114195, 0.06092285513877869, 0.06187400311231613, 0.06084707081317901, 0.06237928614020347, 0.058635359108448026, 0.06827012747526169, 0.06012857615947723, 0.06498203486204147, 0.06121300220489502, 0.06220311343669891, 0.0637871041893959, 0.06410246610641479, 0.0623780483007431, 0.05897190168499947, 0.059096872061491015, 0.06142954707145691, 0.05982682168483734, 0.061820681095123294, 0.05944388747215271, 0.06006913602352142, 0.05929268643260002, 0.06049756810069084, 0.06186001420021057, 0.06284309267997741, 0.06132207542657852, 0.05861274003982544, 0.05933789700269699, 0.06242357939481735, 0.06089776933193207, 0.05918792143464088, 0.05910658836364746, 0.05822771579027176, 0.06287281289696693, 0.05819789588451386, 0.058598853051662445, 0.06088077664375305, 0.060079338401556014, 0.058637642115354535, 0.06155264973640442, 0.05662513807415962, 0.06019425243139267, 0.05996100455522537, 0.05998936533927918, 0.057077433168888095, 0.058874640762805935, 0.06314313262701035, 0.06017718702554703, 0.057043305337429046, 0.059056167304515836, 0.06103940919041634, 0.057898390591144565, 0.05741758078336716, 0.058377608954906464, 0.05759310632944107, 0.05714758008718491, 0.058137902915477754, 0.06298377484083176, 0.05642553254961968, 0.057262055575847626, 0.05759312152862549, 0.05657256707549095, 0.0638317620754242, 0.05802248269319534, 0.056266505867242814, 0.057510187178850175, 0.05753920778632164, 0.05904815390706062, 0.058754151463508604, 0.05853919118642807, 0.059159728288650515, 0.0606321020424366, 0.054685541242361066, 0.06041896611452103, 0.05706268772482872, 0.058156922459602356]\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 12\n",
      "accuracy: [0.9803333, 0.979, 0.9803333, 0.97933334, 0.98233336, 0.98, 0.98, 0.9773333, 0.9773333, 0.98233336, 0.9803333, 0.97933334, 0.98066664, 0.97966665, 0.9816667, 0.9816667, 0.9816667, 0.9766667, 0.9813333, 0.98066664, 0.978, 0.98, 0.98, 0.98066664, 0.9803333, 0.98, 0.9803333, 0.98, 0.981, 0.98066664, 0.983, 0.981, 0.98333335, 0.98233336, 0.9813333, 0.98066664, 0.9803333, 0.981, 0.98066664, 0.9816667, 0.97933334, 0.98, 0.981, 0.981, 0.98066664, 0.981, 0.978, 0.98066664, 0.983, 0.98333335, 0.9813333, 0.9826667, 0.9826667, 0.98066664, 0.98233336, 0.9803333, 0.9803333, 0.98066664, 0.983, 0.98066664, 0.982, 0.983, 0.982, 0.982, 0.979, 0.984, 0.98233336, 0.983, 0.98, 0.98233336, 0.98333335, 0.981, 0.982, 0.9816667, 0.981, 0.981, 0.9813333, 0.9813333, 0.98, 0.9803333, 0.98233336, 0.9803333, 0.9803333, 0.98, 0.9816667, 0.9813333, 0.98, 0.9813333, 0.98366666, 0.98433334, 0.983, 0.9826667, 0.982, 0.9826667, 0.98233336, 0.983, 0.97933334, 0.98233336, 0.981, 0.982]\n",
      "loss: [0.056607910096645356, 0.05665617734193802, 0.05649576097726822, 0.05747808694839478, 0.055957647264003756, 0.05690406784415245, 0.05494704321026802, 0.06193292215466499, 0.06246156007051468, 0.0535055322945118, 0.05600629106163978, 0.055769843757152555, 0.0555479983985424, 0.05512087002396584, 0.05312481343746185, 0.05529348254203796, 0.05374291479587555, 0.061268561631441114, 0.0548053777217865, 0.055401088446378706, 0.05666686192154884, 0.05487520322203636, 0.05714490905404091, 0.05572257101535797, 0.0568001127243042, 0.05618638798594475, 0.054142697155475615, 0.05347509756684303, 0.054093144834041595, 0.05568822994828224, 0.05675469100475311, 0.052538043558597564, 0.05327963382005692, 0.051431913077831265, 0.055409611463546754, 0.054171309322118756, 0.05397950887680054, 0.05644382148981095, 0.053285413831472395, 0.05394802868366241, 0.05418568298220634, 0.05108488485217094, 0.05473398938775063, 0.05423865631222725, 0.05552425369620323, 0.05359786719083786, 0.05688159331679344, 0.05272172525525093, 0.0514696978032589, 0.050269124656915666, 0.053440075814723965, 0.054136151373386385, 0.05174311459064484, 0.05357687756419182, 0.050188459753990174, 0.05647504255175591, 0.05454368561506271, 0.05634180277585983, 0.05426268592476845, 0.05149005353450775, 0.05007045477628708, 0.04969875141978264, 0.05262105107307434, 0.050587543547153474, 0.059313805550336836, 0.048801293969154357, 0.05307088315486908, 0.04935946375131607, 0.061631973385810855, 0.05440036863088608, 0.0488247948884964, 0.05250242039561272, 0.051789831072092056, 0.0510750986635685, 0.051359222531318666, 0.051871217340230945, 0.053942326456308365, 0.05110936969518662, 0.05267490983009338, 0.05289633005857468, 0.050419270843267444, 0.051762328147888184, 0.051399295181035996, 0.057726816534996034, 0.05022782802581787, 0.052977900803089145, 0.05318527519702911, 0.05172967627644539, 0.049939106404781344, 0.050090794563293455, 0.04829569727182388, 0.05086590498685837, 0.054003224074840546, 0.050944749116897586, 0.04979052230715752, 0.049127873331308365, 0.05311969101428986, 0.05048755437135696, 0.051171753853559494, 0.05100839614868164]\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: [0.9816667, 0.98466665, 0.982, 0.98233336, 0.982, 0.983, 0.98433334, 0.98233336, 0.982, 0.9826667, 0.9816667, 0.983, 0.98366666, 0.98366666, 0.984, 0.983, 0.9813333, 0.981, 0.983, 0.98333335, 0.9826667, 0.98, 0.982, 0.984, 0.9826667, 0.98333335, 0.98, 0.983, 0.983, 0.98333335, 0.98233336, 0.98466665, 0.984, 0.98333335, 0.98233336, 0.981, 0.97966665, 0.983, 0.982, 0.98366666, 0.9826667, 0.9853333, 0.985, 0.98233336, 0.98233336, 0.982, 0.9826667, 0.9813333, 0.98433334, 0.9853333, 0.985, 0.98333335, 0.98366666, 0.9816667, 0.98366666, 0.98433334, 0.9813333, 0.9826667, 0.982, 0.9816667, 0.983, 0.9816667, 0.98333335, 0.984, 0.9856667, 0.983, 0.98433334, 0.98333335, 0.9863333, 0.981, 0.98366666, 0.98433334, 0.98433334, 0.986, 0.98333335, 0.98, 0.9826667, 0.9826667, 0.985, 0.98433334, 0.98366666, 0.98233336, 0.985, 0.98333335, 0.985, 0.98433334, 0.98366666, 0.9853333, 0.98433334, 0.984, 0.9853333, 0.985, 0.98466665, 0.98433334, 0.984, 0.985, 0.98233336, 0.986, 0.983, 0.984]\n",
      "loss: [0.05061079010367393, 0.04745777368545532, 0.05209871783852577, 0.05203443810343742, 0.04935074806213379, 0.04920794352889061, 0.0480641770362854, 0.04958174526691437, 0.049200473129749296, 0.050564096570014955, 0.05643350899219513, 0.04922947764396667, 0.04703881621360779, 0.046864232271909716, 0.046573008298873904, 0.051136786490678786, 0.05630795955657959, 0.05039273783564568, 0.04667087331414223, 0.04733799308538437, 0.04741492703557015, 0.05431107521057129, 0.04855541810393334, 0.045764190107584, 0.04655038192868233, 0.05037520736455917, 0.053685321360826495, 0.04780659183859825, 0.05160083755850792, 0.045544490963220594, 0.04619047909975052, 0.04601465970277786, 0.046864203363657, 0.05208108216524124, 0.05012135922908783, 0.04886149942874909, 0.050527014434337617, 0.04779097467660904, 0.046171249002218244, 0.04965998932719231, 0.04750214397907257, 0.045099779069423675, 0.04537763386964798, 0.05007489606738091, 0.047751384526491164, 0.051051192581653596, 0.04670768767595291, 0.048091186434030535, 0.043818303644657136, 0.04335214376449585, 0.04446161240339279, 0.04476362720131874, 0.046455889195203784, 0.047581068426370624, 0.045202303230762485, 0.046798586547374725, 0.04627723440527916, 0.04591307207942009, 0.052892507910728456, 0.04588476970791817, 0.047011232674121856, 0.04545572966337204, 0.04707891345024109, 0.04527627974748612, 0.04337924689054489, 0.0466689059138298, 0.045351289063692096, 0.044097687155008315, 0.04360802456736565, 0.04739152655005455, 0.04669103980064392, 0.04329363986849785, 0.04215504214167595, 0.04259652644395828, 0.04282418444752693, 0.04931269586086273, 0.045212817639112474, 0.04490354493260384, 0.04372360691428184, 0.043693922311067585, 0.0422086475789547, 0.04621582895517349, 0.04391342237591744, 0.048715585619211195, 0.04429909527301788, 0.043850430995225904, 0.04778746470808983, 0.04162342995405197, 0.042560733556747436, 0.041487394273281096, 0.04262252390384674, 0.042208220660686496, 0.04172258898615837, 0.04151727095246315, 0.043363870680332185, 0.041675287038087844, 0.04589774012565613, 0.04622162312269211, 0.04494421601295471, 0.042149183750152586]\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-c91414d9406f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"total epoch:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxEncoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxDecoder\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myDecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loss:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#에폭\n",
    "for epoch in range(20):\n",
    "    print(\"total epoch:\", epoch+1)\n",
    "    history = model.fit([xEncoder, xDecoder], yDecoder, epochs=100, batch_size=64, verbose=0)\n",
    "    print(\"accuracy:\", history.history['accuracy'])\n",
    "    print(\"loss:\", history.history['loss'])\n",
    "    #문장 예측\n",
    "    #3박 4일 놀러 가고 싶다 -> 여행은 언제나 좋죠\n",
    "    \n",
    "    inputEncoder = xEncoder[2].reshape(1, xEncoder[2].shape[0]) #(30,) => (1,30)\n",
    "    inputDecoder = xDecoder[2].reshape(1, xDecoder[2].shape[0]) #(30,) => (1,30)\n",
    "    \n",
    "    results = model.predict([inputEncoder, inputDecoder])\n",
    "    \n",
    "    #결과값에 대해서 가장 큰 값의 위치를 구함\n",
    "    index = np.argmax(results[0], 1)\n",
    "    #인덱스 -> 문장으로 변환\n",
    "    sentence = convertIndextToText(index, indexToWord)\n",
    "    print(sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"3박4일 놀러가고 싶다\"  #여행은 언제나 좋죠\n",
    "# \"3박4일 같이 놀러가고 싶다\"  #여행은 언제나 좋죠\n",
    "# '4박5일 놀러가고 싶다' ???\n",
    "# '3박4일 동안 동해로 놀러가고 싶다' ???\n",
    "# '3박4일 동안 동해로 놀러가려고'  ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#문장 입력 \n",
    "#[[320, 157, ....19, 0,0,0,....0]]\n",
    "def makePredictInput(sentence):\n",
    "    sentences=[]\n",
    "    sentences.append(sentence)\n",
    "    sentences = posTag(sentences)\n",
    "    inputSeq = convertTextToIndex(sentences, wordToIndex, ENCODER_INPUT)\n",
    "    return inputSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#에측 답변 생성\n",
    "def generateText(inputSeq):\n",
    "    #입력을 인코더에 넣고 마지막 상태 구함\n",
    "    states = encoderModel.predict(inputSeq)\n",
    "    \n",
    "    #목표 시퀀스 초기화\n",
    "    targetSeq = np.zeros((1,1)) \n",
    "    #<START> 시그널을 추가\n",
    "    targetSeq[0,0] = STA_INDEX\n",
    "    #인덱스 초기화\n",
    "    indexs=[]\n",
    "    \n",
    "    #디코더 반복\n",
    "    while 1:\n",
    "        decoderOutputs, stateH, stateC = decoderModel.predict([targetSeq]+states)\n",
    "        #결과를 원핫인코딩 형식으로 변환\n",
    "        index = np.argmax(decoderOutputs[0,0,:])\n",
    "        indexs.append(index)\n",
    "        #종료 체크\n",
    "        if index==END_INDEX or len(indexs) >= maxSequences:\n",
    "            break\n",
    "        #targetSeq를 이전 출력으로 설정\n",
    "        targetSeq = np.zeros((1,1)) \n",
    "        targetSeq[0,0] = index\n",
    "        \n",
    "        #디코더의 이전 상태를 다음 디코더 예측에 사용\n",
    "        states = [stateH, stateC]\n",
    "        \n",
    "    #인덱스를 문장으로 변환\n",
    "    sentence = convertIndextToText(indexs, indexToWord) \n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#입력문장 -> 인덱스\n",
    "inputSeq = makePredictInput(\"3박4일 같이 놀러가고 싶다\")\n",
    "#[[320, 157, ....19, 0,0,0,....0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'여행 은 언제나 좋죠 '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = generateText(inputSeq)\n",
    "sentence #여행은 언제나 좋죠"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
