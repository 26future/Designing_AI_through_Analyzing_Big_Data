{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = np.arange(7*5*2).reshape(7,5,2) #(7, 5, 2)\n",
    "np.transpose(ct).shape #(2, 5, 7)\n",
    "# m*n -> transpose -> n*m\n",
    "# i*j*k -> transpose -> ikj, jik, jki, kij, kji... (6가지)\n",
    "np.transpose(ct, [1,2,0]).shape #(5, 2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [i for i in range(1,25)]\n",
    "t = tf.reshape(t,[2,3,4])\n",
    "t = t[-1]\n",
    "print(sess.run(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case study 1 : 네 글자로 구성된 단어 -> 학습\n",
    "#단어의 앞 3글자 입력 -> 마지막 글자 예측\n",
    "# wood -> 학습 -> 모델\n",
    "# woo 입력 -----> 모델 -> d 예측\n",
    "# wop 입력 -----> 모델 -> d 예측 (오타가 있을때도 예측 가능)\n",
    "\n",
    "char_arr = [chr(i) for i in range(97,123)]  #'a':97 ~ 'z':122, chr(97) -> 'a'\n",
    "char_arr  \n",
    "num_dic = {n:i for i,n in enumerate(char_arr)}  #{\"a\":0, 'b':1...'z':25}\n",
    "dic_len = len(num_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = ['word','wood','deep','dive','cold','cool','load','love','kiss','kind']\n",
    "# x:wor -> y:d\n",
    "# x:woo -> y:d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(seq_data):\n",
    "    input_batch=[]\n",
    "    target_batch=[]\n",
    "    for seq in seq_data: # seq = 'word'\n",
    "        myInput = [num_dic[n] for n in seq[:-1]] # wor => 22,14,17\n",
    "#         print(myInput)\n",
    "        target = num_dic[seq[-1]]\n",
    "        #원핫 인코딩\n",
    "        input_batch.append(np.eye(dic_len)[myInput]) #대각 행렬 만드는 함수\n",
    "        target_batch.append(target)\n",
    "        \n",
    "    return input_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch, target_batch = make_batch(seq_data)\n",
    "#  woo           d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.eye(dic_len)) #대각 행렬 만드는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(input_batch) #(10,3,26)\n",
    "#10: 단어 개수, 3:3글자, 26:26가지 종류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax_cross_entropy_with_logits\n",
    "#label값을 one-hot 인코딩으로 넘겨줌\n",
    "#sparse_softmax_cross_entropy_with_logits\n",
    "#label값이 one-hot 인코딩이 안된 경우에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "n_hidden=128  #셀 출력\n",
    "total_epoch=30 #에폭\n",
    "n_step=3  #입력 3글자\n",
    "n_input=n_class=dic_len #26, 입력 크기(n_input), 클래스 종류 개수(n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#신경망 모델 구성\n",
    "x = tf.placeholder(tf.float32, [None, n_step, n_input])\n",
    "# None:전체 단어수, n_step:3글자 입력, n_input: 26개 종류\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "# y가 원핫 인코딩 되어 있다면 -> [None, n_class]\n",
    "w = tf.Variable(tf.random_normal([n_hidden,n_class]))\n",
    "b = tf.Variable(tf.random_normal([n_class]))\n",
    "cell1 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "cell1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=0.5)\n",
    "cell2 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "multi_cell = tf.nn.rnn_cell.MultiRNNCell([cell1,cell2])\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_cell,x, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs shape : (10, 3, 128)\n",
    "tf.transpose(outputs, [1,0,2])\n",
    "# (10, 3, 128) => (3, 10, 128)\n",
    "outputs = outputs[-1] #(10, 128)\n",
    "model = tf.matmul(outputs, w) + b\n",
    "# tf.matmul([10, 128],[128, 26]) => [10,26]     #[n_hidden, n_class] => [128, 26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model, labels=y))\n",
    "opt = tf.train.AdamOptimizer(lr).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs을 실행하여 outputs의 shape 출력?\n",
    "print(sess.run(outputs, feed_dict={x:input_batch}).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(total_epoch):\n",
    "    _, cv = sess.run([opt,cost], feed_dict={x:input_batch, y:target_batch})\n",
    "    print(\"에폭:\", \"%04d\" %(epoch+1),\"비용:\",\"{:.5f}\".format(cv))\n",
    "print(\"모델 작성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.cast(tf.argmax(model,1), tf.int32)\n",
    "predCheck = tf.equal(pred, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(predCheck, tf.float32))\n",
    "\n",
    "input_batch, target_batch = make_batch(seq_data)\n",
    "pv, av = sess.run([pred, accuracy], feed_dict={x:input_batch, y:target_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_words=[]\n",
    "for i,v in enumerate(seq_data):\n",
    "    last_char = char_arr[pv[i]]\n",
    "    predict_words.append(v[:3]+last_char)\n",
    "print(\"예측결과\\n\")\n",
    "print(\"입력값:\", [w[:3] for w in seq_data])\n",
    "print(\"예측값:\", predict_words)\n",
    "pint(\"정확도:\", av)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq: 기계번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력신경망(인코더)/출력신경망(디코더)\n",
    "# 나는 학교에 간다 -> I go to school\n",
    "\n",
    "#seq2seq: 챗봇, 번역, 이미지 캡셔닝\n",
    "#영어 단어 -> 한국어 단어 번역기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\"\"\"\n",
    "S: 디코딩 입력의 시작\n",
    "E: 디코딩 출력의 끝\n",
    "P: 현재 배치되는 데이터의 time step 크기보다 작은 경우, 빈 시퀀스를 채우는 심볼\n",
    "\n",
    "배치 데이터의 최대 크기 4인 경우\n",
    "word=> ['w','o','r','d']\n",
    "to=> ['t','o', 'P', 'P']\n",
    "\"\"\"\n",
    "char_arr = [c for c in \"SEPabcdefghijklmnopqrstuvwxyz단어나무놀이소녀키스사랑\"]\n",
    "num_dic = {n:i for i,n in enumerate(char_arr)}\n",
    "dic_len = len(num_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = [['word','단어'],['wood','나무'],\n",
    "            ['game','놀이'],['girl','소녀'],\n",
    "            ['love','사랑'],['kiss','키스']]\n",
    "#영어 -> 한글"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(seq_date):\n",
    "    input_batch=[]\n",
    "    output_batch=[]\n",
    "    target_batch=[]\n",
    "    for seq in seq_data:\n",
    "#         print(np.shape(seq_data)) #(6, 2)\n",
    "        inputdata = [num_dic[n] for n in seq[0]] #word -> [25, 17, 20, 6]....\n",
    "#         print(inputdata)\n",
    "        outputdata = [num_dic[n] for n in ('S'+seq[1])] #한국어 단어에 대한 인덱스\n",
    "        targetdata = [num_dic[n] for n in (seq[1]+'E')]\n",
    "        \n",
    "        input_batch.append(np.eye(dic_len)[inputdata])\n",
    "        output_batch.append(np.eye(dic_len)[outputdata])\n",
    "        target_batch.append(targetdata) #출력값만 원핫이 아님(sparse_ 사용)\n",
    "    return input_batch, output_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch, output_batch, target_batch = make_batch(seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 옵션 설정\n",
    "lr=0.01\n",
    "n_hidden=128\n",
    "total_epoch=100\n",
    "n_class=n_input=dic_len #41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#신경망 구성 = [배치사이즈, 단계, 입력크기]\n",
    "encInput = tf.placeholder(tf.float32, [None,None,n_input])  # 영어단어 (word)\n",
    "decInput = tf.placeholder(tf.float32, [None,None,n_input]) # <S>단어\n",
    "targets = tf.placeholder(tf.int64, [None,None])   # 단어<E>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#인코더 셀을 구성\n",
    "with tf.variable_scope(\"encode\"):\n",
    "    enc_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob=0.5)\n",
    "    outputs, enc_states = tf.nn.dynamic_rnn(enc_cell, encInput, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#디코더 셀 구성\n",
    "with tf.variable_scope(\"decode\"):\n",
    "    dec_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, output_keep_prob=0.5)\n",
    "    outputs, dec_states = tf.nn.dynamic_rnn(dec_cell, decInput, initial_state=enc_states, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.layers.dense(outputs, n_class, activation=None)\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model, labels=targets))\n",
    "opt = tf.train.AdamOptimizer(lr).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#신경망 모델 학습\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch, output_batch, target_batch = make_batch(seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(total_epoch):\n",
    "    _, cv = sess.run([opt,cost], feed_dict={encInput:input_batch, decInput:output_batch, \n",
    "                                            targets:target_batch})\n",
    "    print(\"에폭:\", \"%04d\" %(epoch+1),\n",
    "         \"비용:\", \"{:.5f}\".format(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(w):\n",
    "    seq_data = [w, 'P'*len(w)]\n",
    "    #seq_data = ['love', 'PPPP']\n",
    "    input_batch, output_batch, target_batch = make_batch([seq_data])\n",
    "    #input_batch=['w','o','r','d']\n",
    "    #output_batch=['P','P','P','P']\n",
    "    #target_batch=[2,2,2,2]\n",
    "    \n",
    "    #model 실행 결과: [배치사이즈, 스텝, 입력크기]\n",
    "    #2번째 차원인 입력 차원을 argmax 적용 -> 확률이 가장 높은 글자 예측\n",
    "    \n",
    "    prediction = tf.argmax(model,2)\n",
    "    #[[[0,0,0.9.....0.1]]]\n",
    "    # => [[[2],[3]....]]  #글자 인덱스\n",
    "    #['단','어','E','E']\n",
    "    \n",
    "    res = sess.run(prediction, feed_dict={encInput:input_batch, decInput:output_batch, \n",
    "                                          targets:target_batch})\n",
    "#     res에는 숫자 인덱스\n",
    "    decoded = [char_arr[i] for i in res[0]]\n",
    "    end = decoded.index(\"E\")\n",
    "    translated = \"\".join(decoded[:end])\n",
    "    return translated\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"word?\", translate(\"word\"))\n",
    "print(\"wodr?\", translate(\"wodr\"))\n",
    "print(\"love?\", translate(\"love\"))\n",
    "print(\"loev?\", translate(\"loev\"))\n",
    "print(\"like?\", translate(\"like\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
