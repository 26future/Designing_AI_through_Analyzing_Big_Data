{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-a839aeb82f4b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None,784])\n",
    "y = tf.placeholder(tf.float32, [None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([784,10])) \n",
    "b = tf.Variable(tf.random_normal([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = tf.nn.softmax(tf.matmul(x,w)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(hf), axis=1))\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "isCorrect = tf.equal(tf.argmax(hf,1), tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(isCorrect, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 15\n",
    "batchSize = 100\n",
    "numIter = int(mnist.train.num_examples / batchSize)\n",
    "# 60000 / 100 = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에폭:0001, cost:2.826302752\n",
      "에폭:0002, cost:1.061668976\n",
      "에폭:0003, cost:0.838061328\n",
      "에폭:0004, cost:0.733232746\n",
      "에폭:0005, cost:0.669279894\n",
      "에폭:0006, cost:0.624611839\n",
      "에폭:0007, cost:0.591160358\n",
      "에폭:0008, cost:0.563868996\n",
      "에폭:0009, cost:0.541745189\n",
      "에폭:0010, cost:0.522673595\n",
      "에폭:0011, cost:0.506782334\n",
      "에폭:0012, cost:0.492447652\n",
      "에폭:0013, cost:0.479955845\n",
      "에폭:0014, cost:0.468893677\n",
      "에폭:0015, cost:0.458703488\n",
      "정확도: 0.8951\n",
      "레이블: [1]\n",
      "예측: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #트레이닝\n",
    "    for epoch in range(numEpochs): #15에폭만큼 반복\n",
    "        avgCv = 0\n",
    "        for i in range(numIter): #반복 횟수: 600\n",
    "            batchX, batchY = mnist.train.next_batch(batchSize)\n",
    "            _, cv = sess.run([train, cost], feed_dict={x:batchX, y:batchY})\n",
    "            avgCv+=cv/numIter\n",
    "        print(\"에폭:{:04d}, cost:{:.9f}\" .format(epoch+1, avgCv))\n",
    "    print(\"정확도:\", accuracy.eval(session=sess, feed_dict={x:mnist.test.images, y:mnist.test.labels}))\n",
    "    r = random.randint(0,mnist.test.num_examples-1)\n",
    "    print(\"레이블:\",sess.run(tf.argmax(mnist.test.labels[r:r+1],1)))\n",
    "    print(\"예측:\", sess.run(tf.argmax(tf.argmax(hf,1)), feed_dict={x:mnist.test.images[r:r+1]}))\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28,28),\n",
    "              cmap='Greys')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 모델 저장/불러오기 (keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다층 퍼셉트론 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 훈련셋,검증셋,시험셋\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리(스케일링)\n",
    "xTrain = xTrain.reshape(60000,784).astype(\"float32\")/255.0\n",
    "xTest = xTest.reshape(10000,784).astype(\"float32\")/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#원핫인코딩\n",
    "yTrain = np_utils.to_categorical(yTrain)\n",
    "yTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTest = np_utils.to_categorical(yTest)\n",
    "yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xVal = xTrain[42000:]\n",
    "xTrain = xTrain[:42000]\n",
    "yVal = yTrain[42000:]\n",
    "yTrain = yTrain[:42000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "#모델 구성\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=28*28, activation=\"relu\"))\n",
    "model.add(Dense(units=10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/5\n",
      "42000/42000 [==============================] - 1s 29us/step - loss: 1.0003 - accuracy: 0.7444 - val_loss: 0.5205 - val_accuracy: 0.8702\n",
      "Epoch 2/5\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.4540 - accuracy: 0.8806 - val_loss: 0.3925 - val_accuracy: 0.8926\n",
      "Epoch 3/5\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.3753 - accuracy: 0.8965 - val_loss: 0.3477 - val_accuracy: 0.9027\n",
      "Epoch 4/5\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.3393 - accuracy: 0.9045 - val_loss: 0.3233 - val_accuracy: 0.9099\n",
      "Epoch 5/5\n",
      "42000/42000 [==============================] - 1s 27us/step - loss: 0.3167 - accuracy: 0.9106 - val_loss: 0.3074 - val_accuracy: 0.9123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2985bde09c8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#학습 환경 설정(compile)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=['accuracy'])\n",
    "#학습(fit)\n",
    "model.fit(xTrain ,yTrain, epochs=5, batch_size=50, validation_data=(xVal, yVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 13us/step\n",
      "평가 결과:[0.2958790455106646, 0.9162999987602234]\n"
     ]
    }
   ],
   "source": [
    "#모델 평가하기(test data)\n",
    "metrics = model.evaluate(xTest, yTest, batch_size=50)\n",
    "print(\"평가 결과:\"+str(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(xTest.shape[0],5)\n",
    "xHat = xTest[idx]\n",
    "yHat = model.predict_classes(xHat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: 9 실제값: 9\n",
      "예측값: 0 실제값: 0\n",
      "예측값: 5 실제값: 5\n",
      "예측값: 3 실제값: 3\n",
      "예측값: 4 실제값: 4\n"
     ]
    }
   ],
   "source": [
    "# print(\"예측값:\", yHat) \n",
    "\n",
    "for i in range(5):\n",
    "    print(\"예측값:\", yHat[i], \"실제값:\",np.argmax(yTest[idx[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "모델: 모델 아키텍처와 모델 가중치로 구성\n",
    "모델 아키텍처: 모델이 어떤 층으로 구성\n",
    "모델 가중치: weight, bias\n",
    "\n",
    "save(): 케라스 모델 저장 함수(아키텍처+가중치)\n",
    "파일 형식: \"h5\"로 저장\n",
    "\"\"\"\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: 1 실제값: 8\n",
      "예측값: 8 실제값: 8\n",
      "예측값: 4 실제값: 4\n",
      "예측값: 2 실제값: 2\n",
      "예측값: 0 실제값: 0\n",
      "예측값: 0 실제값: 0\n",
      "예측값: 1 실제값: 1\n",
      "예측값: 1 실제값: 1\n",
      "예측값: 3 실제값: 3\n",
      "예측값: 7 실제값: 7\n"
     ]
    }
   ],
   "source": [
    "#실제 데이터 사용\n",
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "xTest = xTest.reshape(10000,784).astype(\"float32\")/255.0\n",
    "yTest = np_utils.to_categorical(yTest)\n",
    "idx = np.random.choice(xTest.shape[0], 10)\n",
    "xhat = xTest[idx]\n",
    "\n",
    "#모델 불러오기\n",
    "from keras.models import load_model\n",
    "model = load_model(\"mnist_model.h5\")\n",
    "yhat = model.predict_classes(xhat)\n",
    "for i in range(10):\n",
    "    print(\"예측값:\", yhat[i], \"실제값:\",np.argmax(yTest[idx[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = xy[:,0:-1]\n",
    "ydata = xy[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,4])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([4,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = tf.matmul(x,w)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(hf-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(1e-5).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 2805202400000.0 \n",
      "Prediction: [[1181228.4]\n",
      " [2380427.5]\n",
      " [1872087.9]\n",
      " [1311611.6]\n",
      " [1546225.9]\n",
      " [1559265.9]\n",
      " [1428939.6]\n",
      " [1819987. ]]\n",
      "1 cost: 3.0820206e+27 \n",
      "Prediction: [[-3.9160576e+13]\n",
      " [-7.8834251e+13]\n",
      " [-6.2016065e+13]\n",
      " [-4.3472929e+13]\n",
      " [-5.1235172e+13]\n",
      " [-5.1666410e+13]\n",
      " [-4.7354049e+13]\n",
      " [-6.0291119e+13]]\n",
      "2 cost: inf \n",
      "Prediction: [[1.2980300e+21]\n",
      " [2.6130676e+21]\n",
      " [2.0556058e+21]\n",
      " [1.4409688e+21]\n",
      " [1.6982587e+21]\n",
      " [1.7125526e+21]\n",
      " [1.5696137e+21]\n",
      " [1.9984303e+21]]\n",
      "3 cost: inf \n",
      "Prediction: [[-4.3024952e+28]\n",
      " [-8.6613651e+28]\n",
      " [-6.8135829e+28]\n",
      " [-4.7762850e+28]\n",
      " [-5.6291076e+28]\n",
      " [-5.6764866e+28]\n",
      " [-5.2026963e+28]\n",
      " [-6.6240668e+28]]\n",
      "4 cost: inf \n",
      "Prediction: [[1.4261201e+36]\n",
      " [2.8709260e+36]\n",
      " [2.2584539e+36]\n",
      " [1.5831641e+36]\n",
      " [1.8658435e+36]\n",
      " [1.8815480e+36]\n",
      " [1.7245038e+36]\n",
      " [2.1956361e+36]]\n",
      "5 cost: inf \n",
      "Prediction: [[-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]]\n",
      "6 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "7 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "8 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "9 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "10 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "11 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "12 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "13 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "14 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "15 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "16 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "17 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "18 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "19 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "20 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "21 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "22 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "23 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "24 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "25 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "26 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "27 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "28 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "29 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "30 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "31 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "32 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "33 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "34 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "35 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "36 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "37 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "38 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "39 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "40 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "41 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "42 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "43 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "44 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "45 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "46 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "47 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "48 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "49 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "50 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "51 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "52 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "53 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "54 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "55 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "56 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "57 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "58 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "59 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "60 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "61 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "62 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "63 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "64 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "65 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "66 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "67 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "68 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "69 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "70 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "71 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "72 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "73 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "74 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "75 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "76 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "77 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "78 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "79 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "80 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "81 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "82 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "83 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "84 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "85 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "86 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "87 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "88 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "89 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "90 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "91 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "92 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "93 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "94 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "95 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "96 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "97 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "98 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "99 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "100 cost: nan \n",
      "Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "for step in range(101):\n",
    "    cv, hv, _ = sess.run([cost, hf, train], feed_dict={x:xdata, y:ydata})\n",
    "    print(step, \"cost:\", cv, \"\\nPrediction:\", hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myMinMax(data):\n",
    "#     print(np.min(data)) #전체에서 최소값\n",
    "#     print(np.min(data, axis=1)) #행 단위로 최소값\n",
    "#     print(np.min(data, axis=0)) #열 단위로 최소값\n",
    "    \n",
    "    bj = data-np.min(data,0)\n",
    "    bm = np.max(data,0)-np.min(data,0)\n",
    "    \n",
    "    return bj/bm\n",
    "    \n",
    "xy = myMinMax(xy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = xy[:,0:-1]\n",
    "ydata = xy[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,4])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "w = tf.Variable(tf.random_normal([4,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hf = tf.matmul(x,w)+b\n",
    "cost = tf.reduce_mean(tf.square(hf-y))\n",
    "train = tf.train.GradientDescentOptimizer(1e-5).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 2.8398445 \n",
      "Prediction: [[-1.1070918 ]\n",
      " [-1.9613767 ]\n",
      " [-1.3061585 ]\n",
      " [-0.6469848 ]\n",
      " [-0.91904765]\n",
      " [-0.9656548 ]\n",
      " [-0.4581895 ]\n",
      " [-1.0235589 ]]\n",
      "1 cost: 2.8396354 \n",
      "Prediction: [[-1.1070079 ]\n",
      " [-1.961294  ]\n",
      " [-1.3060904 ]\n",
      " [-0.6469325 ]\n",
      " [-0.91898537]\n",
      " [-0.96559453]\n",
      " [-0.45814943]\n",
      " [-1.023519  ]]\n",
      "2 cost: 2.839426 \n",
      "Prediction: [[-1.106924  ]\n",
      " [-1.9612117 ]\n",
      " [-1.306022  ]\n",
      " [-0.64688015]\n",
      " [-0.91892296]\n",
      " [-0.96553427]\n",
      " [-0.45810938]\n",
      " [-1.0234792 ]]\n",
      "3 cost: 2.839217 \n",
      "Prediction: [[-1.1068401 ]\n",
      " [-1.9611291 ]\n",
      " [-1.3059537 ]\n",
      " [-0.6468278 ]\n",
      " [-0.9188607 ]\n",
      " [-0.9654741 ]\n",
      " [-0.45806932]\n",
      " [-1.0234394 ]]\n",
      "4 cost: 2.8390074 \n",
      "Prediction: [[-1.1067562 ]\n",
      " [-1.9610466 ]\n",
      " [-1.3058853 ]\n",
      " [-0.6467755 ]\n",
      " [-0.9187984 ]\n",
      " [-0.9654138 ]\n",
      " [-0.45802927]\n",
      " [-1.0233996 ]]\n",
      "5 cost: 2.8387983 \n",
      "Prediction: [[-1.1066723 ]\n",
      " [-1.9609642 ]\n",
      " [-1.3058171 ]\n",
      " [-0.6467233 ]\n",
      " [-0.91873604]\n",
      " [-0.96535355]\n",
      " [-0.45798925]\n",
      " [-1.0233598 ]]\n",
      "6 cost: 2.8385892 \n",
      "Prediction: [[-1.1065885 ]\n",
      " [-1.9608817 ]\n",
      " [-1.3057487 ]\n",
      " [-0.64667094]\n",
      " [-0.91867375]\n",
      " [-0.96529347]\n",
      " [-0.4579492 ]\n",
      " [-1.0233201 ]]\n",
      "7 cost: 2.8383803 \n",
      "Prediction: [[-1.1065047 ]\n",
      " [-1.9607992 ]\n",
      " [-1.3056805 ]\n",
      " [-0.6466186 ]\n",
      " [-0.91861147]\n",
      " [-0.96523327]\n",
      " [-0.45790917]\n",
      " [-1.0232804 ]]\n",
      "8 cost: 2.838171 \n",
      "Prediction: [[-1.1064208 ]\n",
      " [-1.9607166 ]\n",
      " [-1.3056122 ]\n",
      " [-0.64656633]\n",
      " [-0.9185491 ]\n",
      " [-0.9651731 ]\n",
      " [-0.45786914]\n",
      " [-1.0232406 ]]\n",
      "9 cost: 2.8379617 \n",
      "Prediction: [[-1.1063368 ]\n",
      " [-1.9606342 ]\n",
      " [-1.3055439 ]\n",
      " [-0.64651406]\n",
      " [-0.9184869 ]\n",
      " [-0.96511286]\n",
      " [-0.45782912]\n",
      " [-1.0232008 ]]\n",
      "10 cost: 2.8377528 \n",
      "Prediction: [[-1.106253  ]\n",
      " [-1.9605516 ]\n",
      " [-1.3054756 ]\n",
      " [-0.6464617 ]\n",
      " [-0.9184245 ]\n",
      " [-0.96505266]\n",
      " [-0.45778906]\n",
      " [-1.0231609 ]]\n",
      "11 cost: 2.8375437 \n",
      "Prediction: [[-1.1061692 ]\n",
      " [-1.9604692 ]\n",
      " [-1.3054073 ]\n",
      " [-0.64640945]\n",
      " [-0.91836226]\n",
      " [-0.96499246]\n",
      " [-0.45774907]\n",
      " [-1.0231211 ]]\n",
      "12 cost: 2.8373346 \n",
      "Prediction: [[-1.1060853]\n",
      " [-1.9603868]\n",
      " [-1.3053391]\n",
      " [-0.6463571]\n",
      " [-0.9183   ]\n",
      " [-0.9649323]\n",
      " [-0.457709 ]\n",
      " [-1.0230814]]\n",
      "13 cost: 2.8371253 \n",
      "Prediction: [[-1.1060014 ]\n",
      " [-1.9603043 ]\n",
      " [-1.3052707 ]\n",
      " [-0.64630485]\n",
      " [-0.9182376 ]\n",
      " [-0.9648721 ]\n",
      " [-0.457669  ]\n",
      " [-1.0230417 ]]\n",
      "14 cost: 2.8369162 \n",
      "Prediction: [[-1.1059176 ]\n",
      " [-1.9602218 ]\n",
      " [-1.3052024 ]\n",
      " [-0.6462525 ]\n",
      " [-0.91817534]\n",
      " [-0.9648118 ]\n",
      " [-0.45762897]\n",
      " [-1.0230019 ]]\n",
      "15 cost: 2.836707 \n",
      "Prediction: [[-1.1058338 ]\n",
      " [-1.9601393 ]\n",
      " [-1.305134  ]\n",
      " [-0.64620024]\n",
      " [-0.918113  ]\n",
      " [-0.96475166]\n",
      " [-0.4575889 ]\n",
      " [-1.0229621 ]]\n",
      "16 cost: 2.8364983 \n",
      "Prediction: [[-1.1057498 ]\n",
      " [-1.9600567 ]\n",
      " [-1.3050658 ]\n",
      " [-0.6461479 ]\n",
      " [-0.91805077]\n",
      " [-0.9646915 ]\n",
      " [-0.4575489 ]\n",
      " [-1.0229223 ]]\n",
      "17 cost: 2.8362892 \n",
      "Prediction: [[-1.1056659 ]\n",
      " [-1.9599743 ]\n",
      " [-1.3049976 ]\n",
      " [-0.64609563]\n",
      " [-0.9179885 ]\n",
      " [-0.9646314 ]\n",
      " [-0.45750886]\n",
      " [-1.0228826 ]]\n",
      "18 cost: 2.83608 \n",
      "Prediction: [[-1.1055821 ]\n",
      " [-1.9598918 ]\n",
      " [-1.3049293 ]\n",
      " [-0.6460434 ]\n",
      " [-0.9179262 ]\n",
      " [-0.9645711 ]\n",
      " [-0.45746884]\n",
      " [-1.0228428 ]]\n",
      "19 cost: 2.8358712 \n",
      "Prediction: [[-1.1054983 ]\n",
      " [-1.9598093 ]\n",
      " [-1.3048611 ]\n",
      " [-0.6459911 ]\n",
      " [-0.91786385]\n",
      " [-0.964511  ]\n",
      " [-0.4574288 ]\n",
      " [-1.022803  ]]\n",
      "20 cost: 2.8356624 \n",
      "Prediction: [[-1.1054145 ]\n",
      " [-1.9597269 ]\n",
      " [-1.3047926 ]\n",
      " [-0.64593875]\n",
      " [-0.9178016 ]\n",
      " [-0.96445084]\n",
      " [-0.45738876]\n",
      " [-1.0227633 ]]\n",
      "21 cost: 2.8354533 \n",
      "Prediction: [[-1.1053307 ]\n",
      " [-1.9596443 ]\n",
      " [-1.3047245 ]\n",
      " [-0.64588654]\n",
      " [-0.91773933]\n",
      " [-0.96439064]\n",
      " [-0.45734876]\n",
      " [-1.0227234 ]]\n",
      "22 cost: 2.8352442 \n",
      "Prediction: [[-1.1052469 ]\n",
      " [-1.9595618 ]\n",
      " [-1.3046563 ]\n",
      " [-0.6458342 ]\n",
      " [-0.91767704]\n",
      " [-0.9643305 ]\n",
      " [-0.45730874]\n",
      " [-1.0226836 ]]\n",
      "23 cost: 2.8350353 \n",
      "Prediction: [[-1.1051631 ]\n",
      " [-1.9594793 ]\n",
      " [-1.3045878 ]\n",
      " [-0.64578193]\n",
      " [-0.9176147 ]\n",
      " [-0.96427023]\n",
      " [-0.4572687 ]\n",
      " [-1.0226439 ]]\n",
      "24 cost: 2.8348265 \n",
      "Prediction: [[-1.1050792 ]\n",
      " [-1.959397  ]\n",
      " [-1.3045197 ]\n",
      " [-0.64572966]\n",
      " [-0.9175524 ]\n",
      " [-0.9642101 ]\n",
      " [-0.45722866]\n",
      " [-1.0226041 ]]\n",
      "25 cost: 2.8346176 \n",
      "Prediction: [[-1.1049953 ]\n",
      " [-1.9593146 ]\n",
      " [-1.3044513 ]\n",
      " [-0.6456773 ]\n",
      " [-0.9174902 ]\n",
      " [-0.96414995]\n",
      " [-0.45718864]\n",
      " [-1.0225644 ]]\n",
      "26 cost: 2.8344085 \n",
      "Prediction: [[-1.1049114 ]\n",
      " [-1.959232  ]\n",
      " [-1.304383  ]\n",
      " [-0.6456251 ]\n",
      " [-0.9174279 ]\n",
      " [-0.96408975]\n",
      " [-0.4571486 ]\n",
      " [-1.0225246 ]]\n",
      "27 cost: 2.8341997 \n",
      "Prediction: [[-1.1048276 ]\n",
      " [-1.9591496 ]\n",
      " [-1.3043147 ]\n",
      " [-0.6455728 ]\n",
      " [-0.9173656 ]\n",
      " [-0.9640295 ]\n",
      " [-0.45710856]\n",
      " [-1.0224848 ]]\n",
      "28 cost: 2.8339906 \n",
      "Prediction: [[-1.1047438 ]\n",
      " [-1.9590671 ]\n",
      " [-1.3042465 ]\n",
      " [-0.64552045]\n",
      " [-0.9173033 ]\n",
      " [-0.96396935]\n",
      " [-0.45706856]\n",
      " [-1.022445  ]]\n",
      "29 cost: 2.833782 \n",
      "Prediction: [[-1.10466   ]\n",
      " [-1.9589847 ]\n",
      " [-1.3041782 ]\n",
      " [-0.64546824]\n",
      " [-0.9172411 ]\n",
      " [-0.96390927]\n",
      " [-0.45702857]\n",
      " [-1.0224053 ]]\n",
      "30 cost: 2.833573 \n",
      "Prediction: [[-1.1045763 ]\n",
      " [-1.9589021 ]\n",
      " [-1.30411   ]\n",
      " [-0.64541596]\n",
      " [-0.91717887]\n",
      " [-0.9638491 ]\n",
      " [-0.45698857]\n",
      " [-1.0223656 ]]\n",
      "31 cost: 2.833364 \n",
      "Prediction: [[-1.1044924 ]\n",
      " [-1.9588197 ]\n",
      " [-1.3040417 ]\n",
      " [-0.6453637 ]\n",
      " [-0.9171165 ]\n",
      " [-0.963789  ]\n",
      " [-0.45694855]\n",
      " [-1.0223258 ]]\n",
      "32 cost: 2.8331556 \n",
      "Prediction: [[-1.1044086 ]\n",
      " [-1.9587374 ]\n",
      " [-1.3039737 ]\n",
      " [-0.6453115 ]\n",
      " [-0.9170543 ]\n",
      " [-0.9637288 ]\n",
      " [-0.45690858]\n",
      " [-1.0222859 ]]\n",
      "33 cost: 2.8329468 \n",
      "Prediction: [[-1.1043248 ]\n",
      " [-1.958655  ]\n",
      " [-1.3039054 ]\n",
      " [-0.64525926]\n",
      " [-0.91699207]\n",
      " [-0.9636687 ]\n",
      " [-0.4568686 ]\n",
      " [-1.0222464 ]]\n",
      "34 cost: 2.832738 \n",
      "Prediction: [[-1.104241  ]\n",
      " [-1.9585724 ]\n",
      " [-1.3038371 ]\n",
      " [-0.645207  ]\n",
      " [-0.9169299 ]\n",
      " [-0.96360856]\n",
      " [-0.4568286 ]\n",
      " [-1.0222065 ]]\n",
      "35 cost: 2.8325295 \n",
      "Prediction: [[-1.1041573]\n",
      " [-1.95849  ]\n",
      " [-1.3037689]\n",
      " [-0.6451548]\n",
      " [-0.9168676]\n",
      " [-0.9635484]\n",
      " [-0.4567886]\n",
      " [-1.0221667]]\n",
      "36 cost: 2.8323207 \n",
      "Prediction: [[-1.1040735]\n",
      " [-1.9584076]\n",
      " [-1.3037007]\n",
      " [-0.6451025]\n",
      " [-0.9168053]\n",
      " [-0.9634882]\n",
      " [-0.4567486]\n",
      " [-1.0221272]]\n",
      "37 cost: 2.8321118 \n",
      "Prediction: [[-1.1039897 ]\n",
      " [-1.9583253 ]\n",
      " [-1.3036324 ]\n",
      " [-0.6450503 ]\n",
      " [-0.91674316]\n",
      " [-0.96342814]\n",
      " [-0.4567086 ]\n",
      " [-1.0220873 ]]\n",
      "38 cost: 2.8319035 \n",
      "Prediction: [[-1.103906  ]\n",
      " [-1.9582429 ]\n",
      " [-1.3035641 ]\n",
      " [-0.644998  ]\n",
      " [-0.91668093]\n",
      " [-0.963368  ]\n",
      " [-0.45666862]\n",
      " [-1.0220475 ]]\n",
      "39 cost: 2.8316946 \n",
      "Prediction: [[-1.1038222 ]\n",
      " [-1.9581604 ]\n",
      " [-1.3034959 ]\n",
      " [-0.6449458 ]\n",
      " [-0.9166187 ]\n",
      " [-0.96330786]\n",
      " [-0.45662862]\n",
      " [-1.0220078 ]]\n",
      "40 cost: 2.8314862 \n",
      "Prediction: [[-1.1037384 ]\n",
      " [-1.9580781 ]\n",
      " [-1.3034277 ]\n",
      " [-0.6448935 ]\n",
      " [-0.91655636]\n",
      " [-0.9632477 ]\n",
      " [-0.45658863]\n",
      " [-1.0219681 ]]\n",
      "41 cost: 2.8312774 \n",
      "Prediction: [[-1.1036546 ]\n",
      " [-1.9579957 ]\n",
      " [-1.3033595 ]\n",
      " [-0.6448413 ]\n",
      " [-0.91649425]\n",
      " [-0.9631876 ]\n",
      " [-0.45654863]\n",
      " [-1.0219283 ]]\n",
      "42 cost: 2.8310685 \n",
      "Prediction: [[-1.1035708 ]\n",
      " [-1.9579132 ]\n",
      " [-1.3032913 ]\n",
      " [-0.64478904]\n",
      " [-0.91643196]\n",
      " [-0.96312743]\n",
      " [-0.45650867]\n",
      " [-1.0218885 ]]\n",
      "43 cost: 2.83086 \n",
      "Prediction: [[-1.1034871 ]\n",
      " [-1.9578308 ]\n",
      " [-1.3032229 ]\n",
      " [-0.64473677]\n",
      " [-0.9163697 ]\n",
      " [-0.9630673 ]\n",
      " [-0.45646864]\n",
      " [-1.0218488 ]]\n",
      "44 cost: 2.8306513 \n",
      "Prediction: [[-1.1034033 ]\n",
      " [-1.9577484 ]\n",
      " [-1.3031547 ]\n",
      " [-0.64468455]\n",
      " [-0.91630745]\n",
      " [-0.96300715]\n",
      " [-0.45642865]\n",
      " [-1.0218091 ]]\n",
      "45 cost: 2.830443 \n",
      "Prediction: [[-1.1033195 ]\n",
      " [-1.957666  ]\n",
      " [-1.3030866 ]\n",
      " [-0.64463234]\n",
      " [-0.9162452 ]\n",
      " [-0.962947  ]\n",
      " [-0.45638868]\n",
      " [-1.0217693 ]]\n",
      "46 cost: 2.830234 \n",
      "Prediction: [[-1.1032358 ]\n",
      " [-1.9575837 ]\n",
      " [-1.3030183 ]\n",
      " [-0.64458   ]\n",
      " [-0.916183  ]\n",
      " [-0.96288687]\n",
      " [-0.45634866]\n",
      " [-1.0217296 ]]\n",
      "47 cost: 2.8300254 \n",
      "Prediction: [[-1.103152  ]\n",
      " [-1.957501  ]\n",
      " [-1.3029501 ]\n",
      " [-0.64452785]\n",
      " [-0.91612077]\n",
      " [-0.9628267 ]\n",
      " [-0.4563087 ]\n",
      " [-1.0216899 ]]\n",
      "48 cost: 2.8298168 \n",
      "Prediction: [[-1.1030682 ]\n",
      " [-1.9574188 ]\n",
      " [-1.3028818 ]\n",
      " [-0.6444756 ]\n",
      " [-0.91605854]\n",
      " [-0.96276665]\n",
      " [-0.4562687 ]\n",
      " [-1.0216501 ]]\n",
      "49 cost: 2.8296084 \n",
      "Prediction: [[-1.1029844 ]\n",
      " [-1.9573363 ]\n",
      " [-1.3028135 ]\n",
      " [-0.64442337]\n",
      " [-0.9159963 ]\n",
      " [-0.96270657]\n",
      " [-0.4562287 ]\n",
      " [-1.0216104 ]]\n",
      "50 cost: 2.8293996 \n",
      "Prediction: [[-1.1029006 ]\n",
      " [-1.9572539 ]\n",
      " [-1.3027453 ]\n",
      " [-0.6443711 ]\n",
      " [-0.915934  ]\n",
      " [-0.96264637]\n",
      " [-0.4561887 ]\n",
      " [-1.0215707 ]]\n",
      "51 cost: 2.8291912 \n",
      "Prediction: [[-1.1028169 ]\n",
      " [-1.9571714 ]\n",
      " [-1.3026772 ]\n",
      " [-0.6443189 ]\n",
      " [-0.91587186]\n",
      " [-0.9625863 ]\n",
      " [-0.45614874]\n",
      " [-1.0215309 ]]\n",
      "52 cost: 2.8289826 \n",
      "Prediction: [[-1.1027331 ]\n",
      " [-1.9570891 ]\n",
      " [-1.302609  ]\n",
      " [-0.6442666 ]\n",
      " [-0.9158096 ]\n",
      " [-0.96252614]\n",
      " [-0.45610872]\n",
      " [-1.0214912 ]]\n",
      "53 cost: 2.828774 \n",
      "Prediction: [[-1.1026493 ]\n",
      " [-1.9570067 ]\n",
      " [-1.3025408 ]\n",
      " [-0.6442144 ]\n",
      " [-0.9157473 ]\n",
      " [-0.962466  ]\n",
      " [-0.45606875]\n",
      " [-1.0214514 ]]\n",
      "54 cost: 2.8285656 \n",
      "Prediction: [[-1.1025656 ]\n",
      " [-1.9569243 ]\n",
      " [-1.3024725 ]\n",
      " [-0.6441622 ]\n",
      " [-0.91568506]\n",
      " [-0.9624059 ]\n",
      " [-0.45602876]\n",
      " [-1.0214117 ]]\n",
      "55 cost: 2.8283567 \n",
      "Prediction: [[-1.102482  ]\n",
      " [-1.9568418 ]\n",
      " [-1.3024043 ]\n",
      " [-0.64410996]\n",
      " [-0.91562295]\n",
      " [-0.9623457 ]\n",
      " [-0.45598882]\n",
      " [-1.021372  ]]\n",
      "56 cost: 2.8281484 \n",
      "Prediction: [[-1.1023982 ]\n",
      " [-1.9567595 ]\n",
      " [-1.3023361 ]\n",
      " [-0.64405775]\n",
      " [-0.9155607 ]\n",
      " [-0.96228564]\n",
      " [-0.45594886]\n",
      " [-1.0213323 ]]\n",
      "57 cost: 2.82794 \n",
      "Prediction: [[-1.1023144 ]\n",
      " [-1.9566771 ]\n",
      " [-1.3022679 ]\n",
      " [-0.64400554]\n",
      " [-0.9154985 ]\n",
      " [-0.96222556]\n",
      " [-0.4559089 ]\n",
      " [-1.0212924 ]]\n",
      "58 cost: 2.8277316 \n",
      "Prediction: [[-1.1022305 ]\n",
      " [-1.9565947 ]\n",
      " [-1.3021997 ]\n",
      " [-0.6439533 ]\n",
      " [-0.9154364 ]\n",
      " [-0.9621655 ]\n",
      " [-0.45586893]\n",
      " [-1.0212528 ]]\n",
      "59 cost: 2.8275232 \n",
      "Prediction: [[-1.102147  ]\n",
      " [-1.9565123 ]\n",
      " [-1.3021315 ]\n",
      " [-0.6439011 ]\n",
      " [-0.91537416]\n",
      " [-0.9621054 ]\n",
      " [-0.45582896]\n",
      " [-1.021213  ]]\n",
      "60 cost: 2.8273149 \n",
      "Prediction: [[-1.1020632 ]\n",
      " [-1.95643   ]\n",
      " [-1.3020632 ]\n",
      " [-0.6438489 ]\n",
      " [-0.91531193]\n",
      " [-0.9620453 ]\n",
      " [-0.45578903]\n",
      " [-1.0211734 ]]\n",
      "61 cost: 2.8271065 \n",
      "Prediction: [[-1.1019794 ]\n",
      " [-1.9563476 ]\n",
      " [-1.301995  ]\n",
      " [-0.6437967 ]\n",
      " [-0.9152497 ]\n",
      " [-0.96198523]\n",
      " [-0.45574906]\n",
      " [-1.0211337 ]]\n",
      "62 cost: 2.826898 \n",
      "Prediction: [[-1.1018957 ]\n",
      " [-1.9562653 ]\n",
      " [-1.3019267 ]\n",
      " [-0.64374447]\n",
      " [-0.9151875 ]\n",
      " [-0.961925  ]\n",
      " [-0.45570907]\n",
      " [-1.021094  ]]\n",
      "63 cost: 2.8266897 \n",
      "Prediction: [[-1.101812  ]\n",
      " [-1.9561828 ]\n",
      " [-1.3018588 ]\n",
      " [-0.64369226]\n",
      " [-0.91512525]\n",
      " [-0.96186495]\n",
      " [-0.4556691 ]\n",
      " [-1.0210543 ]]\n",
      "64 cost: 2.8264813 \n",
      "Prediction: [[-1.1017282 ]\n",
      " [-1.9561005 ]\n",
      " [-1.3017905 ]\n",
      " [-0.64364004]\n",
      " [-0.91506314]\n",
      " [-0.96180487]\n",
      " [-0.45562917]\n",
      " [-1.0210145 ]]\n",
      "65 cost: 2.826273 \n",
      "Prediction: [[-1.1016445 ]\n",
      " [-1.9560181 ]\n",
      " [-1.3017223 ]\n",
      " [-0.6435878 ]\n",
      " [-0.9150009 ]\n",
      " [-0.9617448 ]\n",
      " [-0.45558923]\n",
      " [-1.0209748 ]]\n",
      "66 cost: 2.8260646 \n",
      "Prediction: [[-1.1015607 ]\n",
      " [-1.9559358 ]\n",
      " [-1.3016542 ]\n",
      " [-0.6435356 ]\n",
      " [-0.9149387 ]\n",
      " [-0.9616847 ]\n",
      " [-0.45554924]\n",
      " [-1.020935  ]]\n",
      "67 cost: 2.8258564 \n",
      "Prediction: [[-1.1014771]\n",
      " [-1.9558533]\n",
      " [-1.301586 ]\n",
      " [-0.6434834]\n",
      " [-0.9148766]\n",
      " [-0.9616246]\n",
      " [-0.4555093]\n",
      " [-1.0208954]]\n",
      "68 cost: 2.825648 \n",
      "Prediction: [[-1.1013933 ]\n",
      " [-1.955771  ]\n",
      " [-1.3015178 ]\n",
      " [-0.64343125]\n",
      " [-0.91481423]\n",
      " [-0.96156454]\n",
      " [-0.45546934]\n",
      " [-1.0208557 ]]\n",
      "69 cost: 2.8254397 \n",
      "Prediction: [[-1.1013097 ]\n",
      " [-1.9556886 ]\n",
      " [-1.3014495 ]\n",
      " [-0.643379  ]\n",
      " [-0.9147521 ]\n",
      " [-0.96150446]\n",
      " [-0.45542938]\n",
      " [-1.020816  ]]\n",
      "70 cost: 2.8252316 \n",
      "Prediction: [[-1.1012259 ]\n",
      " [-1.9556063 ]\n",
      " [-1.3013815 ]\n",
      " [-0.6433268 ]\n",
      " [-0.9146899 ]\n",
      " [-0.96144426]\n",
      " [-0.45538944]\n",
      " [-1.0207762 ]]\n",
      "71 cost: 2.8250232 \n",
      "Prediction: [[-1.1011423 ]\n",
      " [-1.955524  ]\n",
      " [-1.3013133 ]\n",
      " [-0.64327455]\n",
      " [-0.9146278 ]\n",
      " [-0.9613843 ]\n",
      " [-0.45534948]\n",
      " [-1.0207365 ]]\n",
      "72 cost: 2.824815 \n",
      "Prediction: [[-1.1010585 ]\n",
      " [-1.9554416 ]\n",
      " [-1.3012451 ]\n",
      " [-0.64322245]\n",
      " [-0.91456556]\n",
      " [-0.9613242 ]\n",
      " [-0.4553095 ]\n",
      " [-1.0206968 ]]\n",
      "73 cost: 2.8246067 \n",
      "Prediction: [[-1.1009748 ]\n",
      " [-1.9553591 ]\n",
      " [-1.3011768 ]\n",
      " [-0.64317024]\n",
      " [-0.91450334]\n",
      " [-0.96126413]\n",
      " [-0.45526955]\n",
      " [-1.0206571 ]]\n",
      "74 cost: 2.8243985 \n",
      "Prediction: [[-1.100891  ]\n",
      " [-1.9552768 ]\n",
      " [-1.3011087 ]\n",
      " [-0.643118  ]\n",
      " [-0.9144412 ]\n",
      " [-0.96120405]\n",
      " [-0.45522958]\n",
      " [-1.0206174 ]]\n",
      "75 cost: 2.8241901 \n",
      "Prediction: [[-1.1008074 ]\n",
      " [-1.9551945 ]\n",
      " [-1.3010406 ]\n",
      " [-0.6430658 ]\n",
      " [-0.914379  ]\n",
      " [-0.96114385]\n",
      " [-0.45518965]\n",
      " [-1.0205777 ]]\n",
      "76 cost: 2.8239822 \n",
      "Prediction: [[-1.1007236 ]\n",
      " [-1.9551121 ]\n",
      " [-1.3009723 ]\n",
      " [-0.64301366]\n",
      " [-0.9143169 ]\n",
      " [-0.96108377]\n",
      " [-0.45514965]\n",
      " [-1.020538  ]]\n",
      "77 cost: 2.8237739 \n",
      "Prediction: [[-1.10064   ]\n",
      " [-1.9550297 ]\n",
      " [-1.3009042 ]\n",
      " [-0.64296144]\n",
      " [-0.91425467]\n",
      " [-0.9610238 ]\n",
      " [-0.45510975]\n",
      " [-1.0204982 ]]\n",
      "78 cost: 2.8235657 \n",
      "Prediction: [[-1.1005564 ]\n",
      " [-1.9549475 ]\n",
      " [-1.3008361 ]\n",
      " [-0.6429093 ]\n",
      " [-0.91419256]\n",
      " [-0.9609637 ]\n",
      " [-0.4550698 ]\n",
      " [-1.0204585 ]]\n",
      "79 cost: 2.8233576 \n",
      "Prediction: [[-1.1004727 ]\n",
      " [-1.9548651 ]\n",
      " [-1.300768  ]\n",
      " [-0.64285713]\n",
      " [-0.91413033]\n",
      " [-0.96090364]\n",
      " [-0.45502988]\n",
      " [-1.0204189 ]]\n",
      "80 cost: 2.8231497 \n",
      "Prediction: [[-1.100389  ]\n",
      " [-1.9547827 ]\n",
      " [-1.3006997 ]\n",
      " [-0.642805  ]\n",
      " [-0.9140682 ]\n",
      " [-0.9608436 ]\n",
      " [-0.45498997]\n",
      " [-1.0203791 ]]\n",
      "81 cost: 2.8229418 \n",
      "Prediction: [[-1.1003054 ]\n",
      " [-1.9547006 ]\n",
      " [-1.3006316 ]\n",
      " [-0.64275277]\n",
      " [-0.9140061 ]\n",
      " [-0.9607836 ]\n",
      " [-0.45495003]\n",
      " [-1.0203395 ]]\n",
      "82 cost: 2.8227334 \n",
      "Prediction: [[-1.1002216]\n",
      " [-1.9546182]\n",
      " [-1.3005633]\n",
      " [-0.6427007]\n",
      " [-0.9139439]\n",
      " [-0.9607236]\n",
      " [-0.4549101]\n",
      " [-1.0202998]]\n",
      "83 cost: 2.8225255 \n",
      "Prediction: [[-1.1001381 ]\n",
      " [-1.9545358 ]\n",
      " [-1.3004955 ]\n",
      " [-0.64264846]\n",
      " [-0.9138818 ]\n",
      " [-0.96066344]\n",
      " [-0.45487022]\n",
      " [-1.0202601 ]]\n",
      "84 cost: 2.8223171 \n",
      "Prediction: [[-1.1000544]\n",
      " [-1.9544535]\n",
      " [-1.3004272]\n",
      " [-0.6425963]\n",
      " [-0.9138196]\n",
      " [-0.9606034]\n",
      " [-0.4548303]\n",
      " [-1.0202203]]\n",
      "85 cost: 2.8221097 \n",
      "Prediction: [[-1.0999708 ]\n",
      " [-1.9543713 ]\n",
      " [-1.3003591 ]\n",
      " [-0.64254415]\n",
      " [-0.91375756]\n",
      " [-0.9605434 ]\n",
      " [-0.45479035]\n",
      " [-1.0201807 ]]\n",
      "86 cost: 2.8219013 \n",
      "Prediction: [[-1.0998871 ]\n",
      " [-1.954289  ]\n",
      " [-1.3002911 ]\n",
      " [-0.642492  ]\n",
      " [-0.91369534]\n",
      " [-0.9604834 ]\n",
      " [-0.45475042]\n",
      " [-1.020141  ]]\n",
      "87 cost: 2.8216934 \n",
      "Prediction: [[-1.0998034 ]\n",
      " [-1.9542066 ]\n",
      " [-1.3002229 ]\n",
      " [-0.64243984]\n",
      " [-0.9136332 ]\n",
      " [-0.96042335]\n",
      " [-0.4547105 ]\n",
      " [-1.0201013 ]]\n",
      "88 cost: 2.8214855 \n",
      "Prediction: [[-1.0997198 ]\n",
      " [-1.9541242 ]\n",
      " [-1.3001547 ]\n",
      " [-0.6423877 ]\n",
      " [-0.91357106]\n",
      " [-0.96036327]\n",
      " [-0.4546706 ]\n",
      " [-1.0200617 ]]\n",
      "89 cost: 2.8212771 \n",
      "Prediction: [[-1.0996362 ]\n",
      " [-1.954042  ]\n",
      " [-1.3000866 ]\n",
      " [-0.64233553]\n",
      " [-0.9135089 ]\n",
      " [-0.9603032 ]\n",
      " [-0.45463067]\n",
      " [-1.0200219 ]]\n",
      "90 cost: 2.8210695 \n",
      "Prediction: [[-1.0995524 ]\n",
      " [-1.9539597 ]\n",
      " [-1.3000184 ]\n",
      " [-0.6422833 ]\n",
      " [-0.91344684]\n",
      " [-0.9602432 ]\n",
      " [-0.45459074]\n",
      " [-1.0199823 ]]\n",
      "91 cost: 2.8208613 \n",
      "Prediction: [[-1.0994688 ]\n",
      " [-1.9538773 ]\n",
      " [-1.2999504 ]\n",
      " [-0.6422312 ]\n",
      " [-0.9133847 ]\n",
      " [-0.96018314]\n",
      " [-0.45455083]\n",
      " [-1.0199425 ]]\n",
      "92 cost: 2.8206534 \n",
      "Prediction: [[-1.0993851 ]\n",
      " [-1.953795  ]\n",
      " [-1.2998822 ]\n",
      " [-0.642179  ]\n",
      " [-0.91332245]\n",
      " [-0.9601231 ]\n",
      " [-0.4545109 ]\n",
      " [-1.019903  ]]\n",
      "93 cost: 2.820446 \n",
      "Prediction: [[-1.0993016 ]\n",
      " [-1.9537128 ]\n",
      " [-1.2998141 ]\n",
      " [-0.6421269 ]\n",
      " [-0.91326034]\n",
      " [-0.9600631 ]\n",
      " [-0.454471  ]\n",
      " [-1.0198632 ]]\n",
      "94 cost: 2.8202376 \n",
      "Prediction: [[-1.0992179 ]\n",
      " [-1.9536303 ]\n",
      " [-1.2997459 ]\n",
      " [-0.64207476]\n",
      " [-0.91319823]\n",
      " [-0.960003  ]\n",
      " [-0.45443106]\n",
      " [-1.0198236 ]]\n",
      "95 cost: 2.8200297 \n",
      "Prediction: [[-1.0991342 ]\n",
      " [-1.9535481 ]\n",
      " [-1.2996778 ]\n",
      " [-0.6420226 ]\n",
      " [-0.9131361 ]\n",
      " [-0.95994294]\n",
      " [-0.45439112]\n",
      " [-1.0197839 ]]\n",
      "96 cost: 2.8198218 \n",
      "Prediction: [[-1.0990505 ]\n",
      " [-1.9534657 ]\n",
      " [-1.2996097 ]\n",
      " [-0.6419704 ]\n",
      " [-0.9130739 ]\n",
      " [-0.95988286]\n",
      " [-0.45435122]\n",
      " [-1.0197442 ]]\n",
      "97 cost: 2.819614 \n",
      "Prediction: [[-1.098967 ]\n",
      " [-1.9533836]\n",
      " [-1.2995415]\n",
      " [-0.6419183]\n",
      " [-0.9130118]\n",
      " [-0.9598229]\n",
      " [-0.4543113]\n",
      " [-1.0197045]]\n",
      "98 cost: 2.819406 \n",
      "Prediction: [[-1.0988832 ]\n",
      " [-1.9533012 ]\n",
      " [-1.2994734 ]\n",
      " [-0.6418661 ]\n",
      " [-0.9129496 ]\n",
      " [-0.9597628 ]\n",
      " [-0.45427138]\n",
      " [-1.0196648 ]]\n",
      "99 cost: 2.8191981 \n",
      "Prediction: [[-1.0987996 ]\n",
      " [-1.9532188 ]\n",
      " [-1.2994053 ]\n",
      " [-0.6418139 ]\n",
      " [-0.91288745]\n",
      " [-0.95970273]\n",
      " [-0.45423144]\n",
      " [-1.0196251 ]]\n",
      "100 cost: 2.8189898 \n",
      "Prediction: [[-1.0987159 ]\n",
      " [-1.9531364 ]\n",
      " [-1.2993371 ]\n",
      " [-0.6417618 ]\n",
      " [-0.91282535]\n",
      " [-0.9596427 ]\n",
      " [-0.45419154]\n",
      " [-1.0195854 ]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(101):\n",
    "    cv, hv, _ = sess.run([cost, hf, train], feed_dict={x:xdata, y:ydata})\n",
    "    print(step, \"cost:\", cv, \"\\nPrediction:\", hv)\n",
    "    \n",
    "# 1. 역정규화를 하여 예측 종가를 출력\n",
    "# 1.874 => xxxx??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xor 문제를 텐서플로우로 구현\n",
    "# 단일, 멀티 퍼셉트론으로 각각 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = np.array([[0,0],\n",
    "                  [0,1],\n",
    "                  [1,0],\n",
    "                  [1,1]])\n",
    "ydata = np.array([[0],\n",
    "                  [1],\n",
    "                  [1],\n",
    "                  [0]])\n",
    "\n",
    "# 트레이닝 횟수: 10000번, lr=0.1\n",
    "# 예측값 출력\n",
    "# 0 0 => 0\n",
    "# 0 1 => 1\n",
    "# 1 0 => 1\n",
    "# 1 1 => 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9704803 [[ 2.6448982]\n",
      " [-0.7425397]]\n",
      "100 0.7636306 [[ 1.4069557]\n",
      " [-0.5645426]]\n",
      "200 0.7167489 [[ 0.8209853 ]\n",
      " [-0.26290193]]\n",
      "300 0.7009397 [[ 0.4813193 ]\n",
      " [-0.10296428]]\n",
      "400 0.6957976 [[ 0.2844251]\n",
      " [-0.0285488]]\n",
      "500 0.694093 [[0.17008142]\n",
      " [0.00275338]]\n",
      "600 0.6935029 [[0.10305049]\n",
      " [0.01364038]]\n",
      "700 0.6932878 [[0.06326947]\n",
      " [0.01550194]]\n",
      "800 0.6932051 [[0.03934456]\n",
      " [0.01382597]]\n",
      "900 0.6931718 [[0.0247607 ]\n",
      " [0.01112823]]\n",
      "1000 0.69315785 [[0.01575332]\n",
      " [0.00847066]]\n",
      "1100 0.69315195 [[0.01012043]\n",
      " [0.00622993]]\n",
      "1200 0.6931493 [[0.00655714]\n",
      " [0.00447879]]\n",
      "1300 0.6931481 [[0.00427958]\n",
      " [0.00316928]]\n",
      "1400 0.69314766 [[0.00281043]\n",
      " [0.00221729]]\n",
      "1500 0.6931473 [[0.00185521]\n",
      " [0.00153836]]\n",
      "1600 0.69314724 [[0.0012299 ]\n",
      " [0.00106064]]\n",
      "1700 0.69314724 [[0.00081822]\n",
      " [0.00072781]]\n",
      "1800 0.6931472 [[0.00054592]\n",
      " [0.00049763]]\n",
      "1900 0.6931472 [[0.00036508]\n",
      " [0.00033929]]\n",
      "2000 0.6931472 [[0.0002446 ]\n",
      " [0.00023082]]\n",
      "2100 0.6931472 [[0.00016411]\n",
      " [0.00015675]]\n",
      "2200 0.6931472 [[0.00011024]\n",
      " [0.00010631]]\n",
      "2300 0.6931472 [[7.412836e-05]\n",
      " [7.202791e-05]]\n",
      "2400 0.6931472 [[4.9876722e-05]\n",
      " [4.8761241e-05]]\n",
      "2500 0.69314724 [[3.3582310e-05]\n",
      " [3.2985376e-05]]\n",
      "2600 0.6931472 [[2.2622513e-05]\n",
      " [2.2295279e-05]]\n",
      "2700 0.6931472 [[1.5238989e-05]\n",
      " [1.5063744e-05]]\n",
      "2800 0.6931472 [[1.0262001e-05]\n",
      " [1.0173181e-05]]\n",
      "2900 0.69314724 [[6.9286152e-06]\n",
      " [6.8740674e-06]]\n",
      "3000 0.6931472 [[4.665129e-06]\n",
      " [4.638892e-06]]\n",
      "3100 0.6931472 [[3.1213654e-06]\n",
      " [3.1174811e-06]]\n",
      "3200 0.6931472 [[2.1229844e-06]\n",
      " [2.1191001e-06]]\n",
      "3300 0.6931472 [[1.4270994e-06]\n",
      " [1.4261954e-06]]\n",
      "3400 0.6931472 [[9.591993e-07]\n",
      " [9.582952e-07]]\n",
      "3500 0.6931471 [[6.2988295e-07]\n",
      " [6.2897891e-07]]\n",
      "3600 0.6931472 [[4.2722723e-07]\n",
      " [4.2632320e-07]]\n",
      "3700 0.6931472 [[2.7821505e-07]\n",
      " [2.7731102e-07]]\n",
      "3800 0.6931472 [[1.8135714e-07]\n",
      " [1.8045310e-07]]\n",
      "3900 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "4000 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "4100 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "4200 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "4300 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "4400 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "4500 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "4600 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "4700 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "4800 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "4900 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "5000 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "5100 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "5200 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "5300 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "5400 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "5500 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "5600 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "5700 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "5800 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "5900 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "6000 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "6100 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "6200 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "6300 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "6400 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "6500 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "6600 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "6700 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "6800 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "6900 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "7000 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "7100 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "7200 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "7300 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "7400 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "7500 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "7600 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "7700 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "7800 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "7900 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "8000 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "8100 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "8200 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "8300 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "8400 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "8500 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "8600 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "8700 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "8800 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "8900 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "9000 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "9100 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "9200 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "9300 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "9400 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "9500 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "9600 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "9700 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "9800 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "9900 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "10000 0.6931472 [[1.3367324e-07]\n",
      " [1.3276920e-07]]\n",
      "\n",
      "Hypothesis:  [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]] \n",
      "Correct:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "#단일 퍼셉트론\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([2, 1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hf= tf.sigmoid(tf.matmul(x, w) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(y * tf.log(hf) + (1 - y) * tf.log(1 - hf))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hf > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cv, wv = sess.run(\n",
    "                  [train, cost, w], feed_dict={x: xdata, y: ydata}\n",
    "        )\n",
    "        if step % 100 == 0:\n",
    "            print(step, cv, wv)\n",
    "\n",
    "    h, c, a = sess.run([hf, predicted, accuracy], feed_dict={x: xdata, y: ydata})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9094985\n",
      "100 0.69084346\n",
      "200 0.6903068\n",
      "300 0.6897783\n",
      "400 0.6892062\n",
      "500 0.6885794\n",
      "600 0.687885\n",
      "700 0.6871079\n",
      "800 0.6862302\n",
      "900 0.68523\n",
      "1000 0.68408096\n",
      "1100 0.68275017\n",
      "1200 0.6811969\n",
      "1300 0.67937136\n",
      "1400 0.6772116\n",
      "1500 0.67464304\n",
      "1600 0.6715776\n",
      "1700 0.66791475\n",
      "1800 0.6635477\n",
      "1900 0.65837276\n",
      "2000 0.65230584\n",
      "2100 0.6453041\n",
      "2200 0.6373872\n",
      "2300 0.62865335\n",
      "2400 0.619282\n",
      "2500 0.60951865\n",
      "2600 0.59964275\n",
      "2700 0.5899286\n",
      "2800 0.5806098\n",
      "2900 0.57185787\n",
      "3000 0.5637762\n",
      "3100 0.55640864\n",
      "3200 0.54975176\n",
      "3300 0.54377174\n",
      "3400 0.53841627\n",
      "3500 0.533625\n",
      "3600 0.5293356\n",
      "3700 0.52548814\n",
      "3800 0.522027\n",
      "3900 0.5189017\n",
      "4000 0.5160675\n",
      "4100 0.5134839\n",
      "4200 0.5111152\n",
      "4300 0.5089297\n",
      "4400 0.50689834\n",
      "4500 0.50499433\n",
      "4600 0.5031921\n",
      "4700 0.5014665\n",
      "4800 0.49979177\n",
      "4900 0.49813908\n",
      "5000 0.49647585\n",
      "5100 0.4947612\n",
      "5200 0.4929419\n",
      "5300 0.49094433\n",
      "5400 0.48866135\n",
      "5500 0.48593122\n",
      "5600 0.48249885\n",
      "5700 0.47795892\n",
      "5800 0.47168112\n",
      "5900 0.46279332\n",
      "6000 0.4504392\n",
      "6100 0.4343348\n",
      "6200 0.41464272\n",
      "6300 0.3910601\n",
      "6400 0.36309463\n",
      "6500 0.33103225\n",
      "6600 0.29626045\n",
      "6700 0.26092663\n",
      "6800 0.2272074\n",
      "6900 0.19665277\n",
      "7000 0.16998677\n",
      "7100 0.14728102\n",
      "7200 0.12822628\n",
      "7300 0.11234775\n",
      "7400 0.099137485\n",
      "7500 0.08812373\n",
      "7600 0.07889953\n",
      "7700 0.07112737\n",
      "7800 0.06453409\n",
      "7900 0.0589012\n",
      "8000 0.0540545\n",
      "8100 0.049855284\n",
      "8200 0.04619293\n",
      "8300 0.042978562\n",
      "8400 0.040140644\n",
      "8500 0.037621133\n",
      "8600 0.035372667\n",
      "8700 0.03335622\n",
      "8800 0.031539705\n",
      "8900 0.029896393\n",
      "9000 0.028403807\n",
      "9100 0.027043186\n",
      "9200 0.02579849\n",
      "9300 0.024656191\n",
      "9400 0.023604684\n",
      "9500 0.022634026\n",
      "9600 0.021735545\n",
      "9700 0.02090181\n",
      "9800 0.020126302\n",
      "9900 0.01940333\n",
      "10000 0.018727958\n",
      "\n",
      "Hypothesis:  [[0.00710241]\n",
      " [0.9838043 ]\n",
      " [0.9838005 ]\n",
      " [0.03448854]] \n",
      "Predicted:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "#멀티레이어 퍼셉트론 기반 \n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "# 1 히든 레이어\n",
    "w1 = tf.Variable(tf.random_normal([2, 2]))\n",
    "b1 = tf.Variable(tf.random_normal([2]))\n",
    "layer1 = tf.sigmoid(tf.matmul(x, w1) + b1)\n",
    "\n",
    "# 2 히든 레이어\n",
    "w2 = tf.Variable(tf.random_normal([2, 2]))\n",
    "b2 = tf.Variable(tf.random_normal([2]))\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, w2) + b2)\n",
    "\n",
    "# 출력 레이어\n",
    "w3 = tf.Variable(tf.random_normal([2, 1]))\n",
    "b3 = tf.Variable(tf.random_normal([1]))\n",
    "hf = tf.sigmoid(tf.matmul(layer2, w3) + b3)\n",
    "\n",
    "cost = -tf.reduce_mean(y * tf.log(hf) + (1 - y) * tf.log(1 - hf))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hf > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cv = sess.run([train, cost], feed_dict={x: xdata, y: ydata})\n",
    "        if step % 100 == 0:\n",
    "            print(step, cv)\n",
    "\n",
    "    h, p, a = sess.run([hf, predicted, accuracy], feed_dict={x: xdata, y: ydata})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nPredicted: \", p, \"\\nAccuracy: \", a)\n",
    "    \n",
    "##Hypothesis:  [[0.01254793]\n",
    "\n",
    "#  [0.9882984 ]\n",
    "#  [0.9834779 ]\n",
    "#  [0.01068014]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hypothesis:  [[1.14172697e-04 2.49445438e-05 1.69277191e-05 2.95937061e-05\n",
      "  3.93390656e-06 1.82390213e-05 5.27501106e-05 1.74045563e-05\n",
      "  9.20891762e-06 6.37769699e-06]\n",
      " [9.99998450e-01 9.99992847e-01 9.99989271e-01 9.99993861e-01\n",
      "  9.99954164e-01 9.99990046e-01 9.99996603e-01 9.99989569e-01\n",
      "  9.99980330e-01 9.99971390e-01]\n",
      " [9.99998271e-01 9.99991775e-01 9.99987900e-01 9.99993205e-01\n",
      "  9.99948263e-01 9.99988735e-01 9.99996185e-01 9.99988198e-01\n",
      "  9.99977827e-01 9.99967635e-01]\n",
      " [8.64267349e-05 1.89244747e-05 1.27851963e-05 2.24411488e-05\n",
      "  2.98023224e-06 1.37984753e-05 3.99649143e-05 1.31726265e-05\n",
      "  7.03334808e-06 4.79817390e-06]] \n",
      "Correct:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# wide & deep\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2, 10]))\n",
    "b1 = tf.Variable(tf.random_normal([10]))\n",
    "layer1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([10, 10]))\n",
    "b2 = tf.Variable(tf.random_normal([10]))\n",
    "layer2 = tf.nn.relu(tf.matmul(layer1, w2) + b2)\n",
    "\n",
    "w3 = tf.Variable(tf.random_normal([10, 10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "layer3 = tf.nn.relu(tf.matmul(layer2, w3) + b3)\n",
    "\n",
    "w4 = tf.Variable(tf.random_normal([10, 1]))\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "hf = tf.sigmoid(tf.matmul(layer3, w4) + b4)\n",
    "# tf.nn.relu\n",
    "\n",
    "cost = -tf.reduce_mean(y * tf.log(hf) + (1 - y) * tf.log(1 - hf))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hf > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cv, wv = sess.run([train, cost, w], feed_dict={x: xdata, y: ydata})\n",
    "#         if step % 100 == 0:\n",
    "#             print(step, cv, wv)\n",
    "\n",
    "    h, c, a = sess.run([hf, predicted, accuracy], feed_dict={x: xdata, y: ydata})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.io\n",
    "# Dense 검색\n",
    "# Dense(8, input_dim=4, init='uniform', activation='relu')\n",
    "# Dense(1, input_dim=3, init='uniform', activation='sigmoid') \n",
    "# Dense(10, input_dim=4, activation='softmax')\n",
    "#...\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(8, input_dim=4, init='uniform', activation='relu'))\n",
    "# model.add(Dense(1, input_dim=3, init='uniform', activation='sigmoid'))\n",
    "# model.add(Dense(10, input_dim=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. mnist - 90% 정확도 넘게... (텐서플로우)\n",
    "# 2. pima indiams diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>763</td>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>764</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765</td>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>766</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1   2   3    4     5      6   7  8\n",
       "0     6  148  72  35    0  33.6  0.627  50  1\n",
       "1     1   85  66  29    0  26.6  0.351  31  0\n",
       "2     8  183  64   0    0  23.3  0.672  32  1\n",
       "3     1   89  66  23   94  28.1  0.167  21  0\n",
       "4     0  137  40  35  168  43.1  2.288  33  1\n",
       "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
       "763  10  101  76  48  180  32.9  0.171  63  0\n",
       "764   2  122  70  27    0  36.8  0.340  27  0\n",
       "765   5  121  72  23  112  26.2  0.245  30  0\n",
       "766   1  126  60   0    0  30.1  0.349  47  1\n",
       "767   1   93  70  31    0  30.4  0.315  23  0\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dataset (1)/pima-indians-diabetes.csv\", header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata = data.loc[:,:7] #(768, 8)\n",
    "ydata = data.loc[:,[8]].values #(768, 1)\n",
    "xdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63994726,  0.84832379,  0.14964075, ...,  0.20401277,\n",
       "         0.46849198,  1.4259954 ],\n",
       "       [-0.84488505, -1.12339636, -0.16054575, ..., -0.68442195,\n",
       "        -0.36506078, -0.19067191],\n",
       "       [ 1.23388019,  1.94372388, -0.26394125, ..., -1.10325546,\n",
       "         0.60439732, -0.10558415],\n",
       "       ...,\n",
       "       [ 0.3429808 ,  0.00330087,  0.14964075, ..., -0.73518964,\n",
       "        -0.68519336, -0.27575966],\n",
       "       [-0.84488505,  0.1597866 , -0.47073225, ..., -0.24020459,\n",
       "        -0.37110101,  1.17073215],\n",
       "       [-0.84488505, -0.8730192 ,  0.04624525, ..., -0.20212881,\n",
       "        -0.47378505, -0.87137393]])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정규화\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(xdata)\n",
    "xdata = scaler.transform(xdata)\n",
    "xdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train/test set 나누기\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(xdata, ydata, random_state=42, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,8])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([8,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = tf.sigmoid(tf.matmul(x,w)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicated = tf.cast(hf>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicated,y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>예측결과</th>\n",
       "      <th>정답</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     예측결과  정답\n",
       "0     0.0   0\n",
       "1     0.0   0\n",
       "2     0.0   0\n",
       "3     0.0   0\n",
       "4     0.0   0\n",
       "..    ...  ..\n",
       "226   1.0   1\n",
       "227   0.0   1\n",
       "228   0.0   0\n",
       "229   0.0   0\n",
       "230   0.0   0\n",
       "\n",
       "[231 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.7619048\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(1001):\n",
    "        _, cv = sess.run([train, cost], feed_dict={x:xtrain, y:ytrain})\n",
    "    \n",
    "    res = sess.run(hf, feed_dict={x:xtest})\n",
    "    \n",
    "    prediction = list(map(lambda x:x.item(),sess.run(tf.cast(res>0.5, dtype=tf.float32))))\n",
    "    label = list(map(lambda x:x.item(), ytest))\n",
    "    \n",
    "    df = pd.DataFrame({\"예측결과\":prediction, \"정답\":label})\n",
    "    display(df)\n",
    "                    \n",
    "#     print(\"예측 결과: \", sess.run(tf.cast(res>0.5, dtype=tf.float32)))\n",
    "#     print(\"정답:\", ytest)\n",
    "    print(\"정확도: \", sess.run(accuracy, feed_dict={x:xtest, y:ytest}))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
